#!/usr/bin/env python3
"""
Fleet Management Dashboard - Complete Version with Date Filters
Dashboard with proper column mapping, date filtering, and all analysis features
"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import subprocess
import os
from dotenv import load_dotenv
import sys
from datetime import datetime
import json
import base64
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        padding: 1rem;
        background: #ffffff;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .metric-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
        margin: 0.5rem 0;
    }

    /* Centered header container and text */
    .header-container {
        text-align: center;
        display: flex;
        flex-direction: row;
        align-items: center;
        justify-content: center;
        margin-bottom: 2rem;
    }

    .header-text {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-top: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# COLUMN MAPPING - Vietnamese to English
COLUMN_MAPPING = {
    # Drop these columns (set to None to ignore)
    'Timestamp': None,  # Ignore timestamp
    'Email Address': None,  # Already converted to driver name
    'Ghi ch√∫': None,  # Notes - not used for KPI
    'Ch·ªâ s·ªë ƒë·ªìng h·ªì sau khi k·∫øt th√∫c chuy·∫øn xe': None,  # Odometer - already processed
    'Ghi nh·∫≠n chi ti·∫øt chuy·∫øn xe': None,  # Trip details - only for reporting
    
    # Core time fields
    'Th·ªùi gian b·∫Øt ƒë·∫ßu': 'start_time',
    'Th·ªùi gian k·∫øt th√∫c': 'end_time', 
    'Th·ªùi gian': 'duration_hours',  # Duration in hours (hh:mm format)
    
    # Location and classification
    'ƒêi·ªÉm ƒë·∫øn': 'destination',
    'Ph√¢n lo·∫°i c√¥ng t√°c': 'work_category',
    'N·ªôi th√†nh/ngo·∫°i th√†nh': 'area_type',  # Urban/suburban
    
    # Date and numeric metrics
    'Ng√†y ghi nh·∫≠n': 'record_date',  # mm/dd/yyyy format
    'Qu√£ng ƒë∆∞·ªùng': 'distance_km',
    'ƒê·ªï nhi√™n li·ªáu': 'fuel_liters',
    
    # Revenue (ambulance only)
    'Doanh thu': 'revenue_vnd',
    'Chi ti·∫øt chuy·∫øn xe': 'trip_details',
    
    # Vehicle and driver info (added during sync)
    'M√£ xe': 'vehicle_id',
    'T√™n t√†i x·∫ø': 'driver_name',
    'Lo·∫°i xe': 'vehicle_type'  # 'H√†nh ch√≠nh' or 'C·ª©u th∆∞∆°ng'
}

def get_github_token():
    """Get GitHub token for private repo access"""
    # Priority 1: Read from sync_config.json
    try:
        import streamlit as st
        if hasattr(st, 'secrets') and 'GITHUB_TOKEN' in st.secrets:
            return st.secrets['GITHUB_TOKEN']
    except:
        pass
    
    # Priority 2: Environment variable (.env file)
    token = os.getenv('GITHUB_TOKEN')
    if token and len(token) > 10:
        return token
    
    # Priority 3: File (backward compatibility)
    if os.path.exists("github_token.txt"):
        try:
            with open("github_token.txt", 'r') as f:
                token = f.read().strip()
            if token and token != "YOUR_TOKEN_HERE" and len(token) > 10:
                return token
        except:
            pass
    
    return None

def parse_duration_to_hours(duration_str):
    """
    Chuy·ªÉn ƒë·ªïi th·ªùi gian t·ª´ format h:mm sang s·ªë gi·ªù (float)
    
    Args:
        duration_str (str): Th·ªùi gian format h:mm ho·∫∑c h:mm:ss
    
    Returns:
        float: S·ªë gi·ªù
    """
    if not duration_str or duration_str == "":
        return 0.0
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng v√† c√°c k√Ω t·ª± kh√¥ng mong mu·ªën
    duration_str = str(duration_str).strip()
    
    # X·ª≠ l√Ω c√°c format kh√°c nhau
    # Format: "2:20:00 AM" -> ch·ªâ l·∫•y ph·∫ßn th·ªùi gian
    if "AM" in duration_str or "PM" in duration_str:
        duration_str = duration_str.split()[0]
    
    try:
        # Split theo d·∫•u ":"
        parts = duration_str.split(":")
        
        if len(parts) == 2:  # h:mm
            hours = int(parts[0])
            minutes = int(parts[1])
            return hours + minutes / 60.0
        elif len(parts) == 3:  # h:mm:ss
            hours = int(parts[0])
            minutes = int(parts[1])
            seconds = int(parts[2])
            return hours + minutes / 60.0 + seconds / 3600.0
        else:
            return 0.0
    except (ValueError, IndexError):
        return 0.0

def ensure_duration_parsed(df):
    """
    ƒê·∫£m b·∫£o c·ªôt duration_hours ƒë∆∞·ª£c parse ƒë√∫ng trong to√†n b·ªô DataFrame
    """
    if 'Th·ªùi gian' not in df.columns:
        return df
    
    # Ki·ªÉm tra xem c·ªôt ƒë√£ l√† numeric ch∆∞a
    if not pd.api.types.is_numeric_dtype(df['Th·ªùi gian']):
        # N·∫øu ch∆∞a, parse t·ª´ string
        df['Th·ªùi gian'] = df['Th·ªùi gian'].apply(parse_duration_to_hours)
    else:
        # N·∫øu ƒë√£ l√† numeric nh∆∞ng c√≥ th·ªÉ c√≥ NaN, fill 0
        df['Th·ªùi gian'] = df['Th·ªùi gian'].fillna(0)
    
    return df

def parse_distance(distance_str):
    """
    Convert various distance inputs to kilometres (float).

    Handles:
    ‚Ä¢ Thousand separators ‚Äú.‚Äù or ‚Äú,‚Äù
    ‚Ä¢ Vietnamese decimal comma
    ‚Ä¢ Values tagged with ‚Äúkm‚Äù or ‚Äúm‚Äù
    ‚Ä¢ Raw metre readings (converts metres ‚Üí km when 1‚ÄØ000¬†<¬†value¬†<¬†1‚ÄØ000‚ÄØ000)
    Filters out clearly impossible per‚Äëtrip values (‚â§‚ÄØ0‚ÄØkm or‚ÄØ>‚ÄØ1‚ÄØ000‚ÄØkm).

    Returns:
        float: distance in km (0.0 if parsing fails or value is out of bounds)
    """
    # Empty / NaN
    if pd.isna(distance_str) or str(distance_str).strip() == "":
        return 0.0

    # Normalise string
    s = str(distance_str).lower().strip()

    # Remove textual units
    for unit in ["km", "kilomet", "kilometer", "kilometre", "m", "meter", "metre"]:
        s = s.replace(unit, "")
    # Handle Vietnamese decimal comma & thousand dots, e.g. "1.234,5"
    if "," in s and "." not in s:
        s = s.replace(".", "")       # remove thousand separators
        s = s.replace(",", ".")      # comma decimal ‚Üí dot
    # Remove any leftover thousand separators
    s = s.replace(",", "").replace(" ", "")

    # Attempt conversion
    try:
        dist = float(s)
    except ValueError:
        return 0.0

    # Convert metres ‚Üí km if it looks like a metre value
    if 1_000 < dist < 1_000_000:
        dist = dist / 1_000.0

    # Guard rails: ignore negative / ridiculous values
    if dist <= 0 or dist > 1_000:
        return 0.0

    return round(dist, 2)

@st.cache_data(ttl=60)
def load_data_from_github():
    """Load data from GitHub repository - Large file support"""
    github_token = get_github_token()
    
    if not github_token:
        st.sidebar.error("‚ùå C·∫ßn GitHub token ƒë·ªÉ truy c·∫≠p private repo")
        return pd.DataFrame()
    
    headers = {
        'Authorization': f'token {github_token}',
        'Accept': 'application/vnd.github.v3+json',
        'User-Agent': 'Fleet-Dashboard-App'
    }
    
    # Try Contents API first
    api_url = "https://api.github.com/repos/corner-25/vehicle-storage/contents/data/latest/fleet_data_latest.json"
    
    try:
        response = requests.get(api_url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            api_response = response.json()
            
            # Check if file is too large for Contents API (>1MB)
            if api_response.get('size', 0) > 1000000:
                return load_large_file_via_git_api(headers)
            
            # Normal Contents API flow
            content = base64.b64decode(api_response['content']).decode('utf-8')
            
            if not content.strip():
                return load_large_file_via_git_api(headers)
            
            data = json.loads(content)
            df = pd.DataFrame(data)
            return process_dataframe(df)
        else:
            return load_large_file_via_git_api(headers)
            
    except Exception:
        return load_large_file_via_git_api(headers)

def load_large_file_via_git_api(headers):
    """Load large file using Git API"""
    try:
        # Get latest commit
        commits_url = "https://api.github.com/repos/corner-25/vehicle-storage/commits/main"
        commits_response = requests.get(commits_url, headers=headers, timeout=30)
        
        if commits_response.status_code != 200:
            return pd.DataFrame()
        
        latest_commit = commits_response.json()
        tree_sha = latest_commit['commit']['tree']['sha']
        
        # Navigate to data/latest/fleet_data_latest.json via tree API
        tree_url = f"https://api.github.com/repos/corner-25/vehicle-storage/git/trees/{tree_sha}"
        tree_response = requests.get(tree_url, headers=headers, timeout=30)
        
        if tree_response.status_code != 200:
            return pd.DataFrame()
        
        # Find data folder
        tree_data = tree_response.json()
        data_folder = None
        for item in tree_data.get('tree', []):
            if item['path'] == 'data' and item['type'] == 'tree':
                data_folder = item['sha']
                break
        
        if not data_folder:
            return pd.DataFrame()
        
        # Get data folder tree
        data_tree_url = f"https://api.github.com/repos/corner-25/vehicle-storage/git/trees/{data_folder}"
        data_tree_response = requests.get(data_tree_url, headers=headers, timeout=30)
        
        if data_tree_response.status_code != 200:
            return pd.DataFrame()
        
        # Find latest folder
        data_tree_data = data_tree_response.json()
        latest_folder = None
        for item in data_tree_data.get('tree', []):
            if item['path'] == 'latest' and item['type'] == 'tree':
                latest_folder = item['sha']
                break
        
        if not latest_folder:
            return pd.DataFrame()
        
        # Get latest folder tree
        latest_tree_url = f"https://api.github.com/repos/corner-25/vehicle-storage/git/trees/{latest_folder}"
        latest_tree_response = requests.get(latest_tree_url, headers=headers, timeout=30)
        
        if latest_tree_response.status_code != 200:
            return pd.DataFrame()
        
        # Find JSON file
        latest_tree_data = latest_tree_response.json()
        file_blob = None
        for item in latest_tree_data.get('tree', []):
            if item['path'] == 'fleet_data_latest.json' and item['type'] == 'blob':
                file_blob = item['sha']
                break
        
        if not file_blob:
            return pd.DataFrame()
        
        # Get file content via blob API
        blob_url = f"https://api.github.com/repos/corner-25/vehicle-storage/git/blobs/{file_blob}"
        blob_response = requests.get(blob_url, headers=headers, timeout=60)
        
        if blob_response.status_code != 200:
            return pd.DataFrame()
        
        blob_data = blob_response.json()
        content = base64.b64decode(blob_data['content']).decode('utf-8')
        
        if not content.strip():
            return pd.DataFrame()
        
        data = json.loads(content)
        df = pd.DataFrame(data)
        return process_dataframe(df)
        
    except Exception:
        return pd.DataFrame()

def parse_revenue(revenue_str):
    """
    Parse revenue string and handle both formats: 600000 and 600,000
    Also handles negative values and various edge cases
    """
    if pd.isna(revenue_str) or revenue_str == '':
        return 0.0
    
    try:
        # Convert to string and clean
        revenue_str = str(revenue_str).strip()
        
        # Remove commas from the string
        revenue_str = revenue_str.replace(',', '')
        
        # Remove any currency symbols (VNƒê, ƒë, etc.)
        revenue_str = revenue_str.replace('VNƒê', '').replace('ƒë', '').replace('VND', '')
        
        # Remove any extra spaces
        revenue_str = revenue_str.strip()
        
        # Convert to float
        revenue = float(revenue_str)
        
        # Handle negative values (convert to positive)
        return abs(revenue) if revenue < 0 else revenue
        
    except (ValueError, TypeError):
        # If conversion fails, return 0
        return 0.0
        
def process_dataframe(df):
    """Process DataFrame - Apply column mapping and clean data"""
    if df.empty:
        return df
    
    try:
        
        # STEP 1: Apply column mapping
        # Create a reverse mapping for flexibility
        reverse_mapping = {}
        for viet_col, eng_col in COLUMN_MAPPING.items():
            if eng_col is not None:  # Only map non-None columns
                # Handle partial matches for long Vietnamese column names
                for col in df.columns:
                    if viet_col in col:
                        reverse_mapping[col] = eng_col
                        break
        
        # Rename columns
        df = df.rename(columns=reverse_mapping)
        
        # STEP 2: Drop unnecessary columns (those mapped to None)
        drop_columns = []
        for viet_col in COLUMN_MAPPING.keys():
            if COLUMN_MAPPING[viet_col] is None:
                # Find columns that contain this Vietnamese text
                for col in df.columns:
                    if viet_col in col:
                        drop_columns.append(col)
        
        df = df.drop(columns=drop_columns, errors='ignore')
        
        # STEP 3: Handle duplicate columns by merging them
        df = df.loc[:, ~df.columns.duplicated()]
        
        # STEP 4: Process data types
        
        # FIXED: Process duration - Convert to decimal hours using correct function name
        if 'Th·ªùi gian' in df.columns:
            df['Th·ªùi gian'] = df['Th·ªùi gian'].apply(parse_duration_to_hours)
        
        # Process distance - Handle negative values but keep all rows
        if 'distance_km' in df.columns:
            df['distance_km'] = df['distance_km'].apply(parse_distance)
        
        # Process revenue - Convert to numeric but keep all rows
        if 'revenue_vnd' in df.columns:
            df['revenue_vnd'] = df['revenue_vnd'].apply(parse_revenue)
        
        # Process fuel consumption
        if 'fuel_liters' in df.columns:
            df['fuel_liters'] = pd.to_numeric(df['fuel_liters'], errors='coerce').fillna(0)
        
        # Process datetime columns - Handle mm/dd/yyyy format
        if 'record_date' in df.columns:
            df['record_date'] = pd.to_datetime(df['record_date'], errors='coerce')  # T·ª± ƒë·ªông detect format
            # Create helper columns
            df['date'] = df['record_date'].dt.date
            df['month'] = df['record_date'].dt.to_period('M').astype(str)
        return df
        
    except Exception as e:
        st.sidebar.error(f"‚ùå Error processing data: {e}")
        return df

def run_sync_script():
    """Execute sync script"""
    try:
        if not os.path.exists("manual_fleet_sync.py"):
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y file manual_fleet_sync.py")
            return False
        
        token = get_github_token()
        if not token:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y GitHub token!")
            return False
        
        with st.spinner("üîÑ ƒêang ch·∫°y sync script..."):
            try:
                if 'manual_fleet_sync' in sys.modules:
                    del sys.modules['manual_fleet_sync']
                
                import manual_fleet_sync
                sync_engine = manual_fleet_sync.ManualFleetSync()
                
                if sync_engine.config['github']['token'] == "YOUR_TOKEN_HERE":
                    st.error("‚ùå GitHub token ch∆∞a ƒë∆∞·ª£c load!")
                    return False
                
                success = sync_engine.sync_now()
                
                if success:
                    st.success("‚úÖ Sync ho√†n th√†nh!")
                    st.session_state.last_sync = datetime.now()
                    return True
                else:
                    st.error("‚ùå Sync th·∫•t b·∫°i!")
                    return False
                    
            except Exception:
                result = subprocess.run([
                    sys.executable, "manual_fleet_sync.py", "--sync-only"
                ], capture_output=True, text=True, timeout=300)
                
                if result.returncode == 0:
                    st.success("‚úÖ Sync ho√†n th√†nh!")
                    st.session_state.last_sync = datetime.now()
                    return True
                else:
                    st.error(f"‚ùå Sync th·∫•t b·∫°i: {result.stderr}")
                    return False
                    
    except Exception as e:
        st.error(f"‚ùå L·ªói ch·∫°y sync: {e}")
        return False

def filter_data_by_date_range(df, start_date, end_date):
    """Filter dataframe by date range - FIXED to not drop invalid dates"""
    if df.empty or 'record_date' not in df.columns:
        return df
    
    try:
        # Ensure record_date is datetime
        df['record_date'] = pd.to_datetime(df['record_date'], format='%m/%d/%Y', errors='coerce')
        
        # Count invalid dates for debugging
        invalid_count = df['record_date'].isna().sum()
        if invalid_count > 0:
            st.sidebar.warning(f"‚ö†Ô∏è Found {invalid_count} records with invalid dates - keeping them!")
        
        # FIXED: Include records with invalid dates in filter
        # For invalid dates, we'll keep them in the result instead of dropping
        valid_mask = (df['record_date'].notna()) & (df['record_date'].dt.date >= start_date) & (df['record_date'].dt.date <= end_date)
        invalid_mask = df['record_date'].isna()
        
        # Keep both valid dates in range AND invalid dates
        combined_mask = valid_mask | invalid_mask
        filtered_df = df[combined_mask].copy()
        
        return filtered_df
        
    except Exception as e:
        st.sidebar.error(f"‚ùå L·ªói l·ªçc d·ªØ li·ªáu: {e}")
        return df

def get_date_range_from_data(df):
    """Get min and max dates from data"""
    if df.empty or 'record_date' not in df.columns:
        return datetime.now().date(), datetime.now().date()
    
    try:
        df['record_date'] = pd.to_datetime(df['record_date'], format='%m/%d/%Y', errors='coerce')
        valid_dates = df[df['record_date'].notna()]
        
        if valid_dates.empty:
            return datetime.now().date(), datetime.now().date()
        
        min_date = valid_dates['record_date'].min().date()
        max_date = valid_dates['record_date'].max().date()
        
        return min_date, max_date
        
    except Exception:
        return datetime.now().date(), datetime.now().date()

def create_date_filter_sidebar(df):
    """Create date range filter in sidebar"""
    st.sidebar.markdown("### üìÖ B·ªô l·ªçc th·ªùi gian")
    
    # Get data date range
    min_date, max_date = get_date_range_from_data(df)
    
    # Show data range info
    st.sidebar.info(f"üìä D·ªØ li·ªáu c√≥: {min_date.strftime('%d/%m/%Y')} - {max_date.strftime('%d/%m/%Y')}")
    
    # FIXED: Reset session state if current values are outside new data range
    reset_needed = False
    if 'date_filter_start' in st.session_state:
        if st.session_state.date_filter_start < min_date or st.session_state.date_filter_start > max_date:
            reset_needed = True
    if 'date_filter_end' in st.session_state:
        if st.session_state.date_filter_end < min_date or st.session_state.date_filter_end > max_date:
            reset_needed = True
    
    if reset_needed:
        st.sidebar.warning("‚ö†Ô∏è ƒê√£ reset b·ªô l·ªçc ng√†y do d·ªØ li·ªáu thay ƒë·ªïi")
        if 'date_filter_start' in st.session_state:
            del st.session_state.date_filter_start
        if 'date_filter_end' in st.session_state:
            del st.session_state.date_filter_end
    
    # Initialize session state for date filters if not exists or after reset
    if 'date_filter_start' not in st.session_state:
        st.session_state.date_filter_start = min_date
    if 'date_filter_end' not in st.session_state:
        st.session_state.date_filter_end = max_date
    
    # Ensure session state values are within valid range
    if st.session_state.date_filter_start < min_date:
        st.session_state.date_filter_start = min_date
    if st.session_state.date_filter_start > max_date:
        st.session_state.date_filter_start = max_date
    if st.session_state.date_filter_end < min_date:
        st.session_state.date_filter_end = min_date
    if st.session_state.date_filter_end > max_date:
        st.session_state.date_filter_end = max_date
    
    # Date range selector
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        start_date = st.date_input(
            "T·ª´ ng√†y:",
            value=st.session_state.date_filter_start,
            min_value=min_date,
            max_value=max_date,
            key="start_date_input"
        )
    
    with col2:
        end_date = st.date_input(
            "ƒê·∫øn ng√†y:",
            value=st.session_state.date_filter_end,
            min_value=min_date,
            max_value=max_date,
            key="end_date_input"
        )
    
    # Update session state when inputs change
    if start_date != st.session_state.date_filter_start:
        st.session_state.date_filter_start = start_date
    if end_date != st.session_state.date_filter_end:
        st.session_state.date_filter_end = end_date
    
    # Validate date range
    if start_date > end_date:
        st.sidebar.error("‚ùå Ng√†y b·∫Øt ƒë·∫ßu ph·∫£i nh·ªè h∆°n ng√†y k·∫øt th√∫c!")
        return df, min_date, max_date
    
    # Quick filter buttons
    st.sidebar.markdown("**üöÄ B·ªô l·ªçc nhanh:**")
    
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        if st.button("üìÖ 7 ng√†y g·∫ßn nh·∫•t", use_container_width=True, key="btn_7_days"):
            st.session_state.date_filter_start = max_date - pd.Timedelta(days=6)
            st.session_state.date_filter_end = max_date
            st.rerun()
        
        if st.button("üìÖ Th√°ng n√†y", use_container_width=True, key="btn_this_month"):
            today = datetime.now().date()
            st.session_state.date_filter_start = today.replace(day=1)
            st.session_state.date_filter_end = min(today, max_date)
            st.rerun()
    
    with col2:
        if st.button("üìÖ 30 ng√†y g·∫ßn nh·∫•t", use_container_width=True, key="btn_30_days"):
            st.session_state.date_filter_start = max_date - pd.Timedelta(days=29)
            st.session_state.date_filter_end = max_date
            st.rerun()
        
        if st.button("üìÖ T·∫•t c·∫£", use_container_width=True, key="btn_all_data"):
            st.session_state.date_filter_start = min_date
            st.session_state.date_filter_end = max_date
            st.rerun()
    
    # Use the session state values for filtering
    filter_start = st.session_state.date_filter_start
    filter_end = st.session_state.date_filter_end
    
    # Filter data
    filtered_df = filter_data_by_date_range(df, filter_start, filter_end)
    
    # Show filtered data info
    if not filtered_df.empty:
        days_selected = (filter_end - filter_start).days + 1
        active_days = filtered_df['record_date'].dt.date.nunique() if 'record_date' in filtered_df.columns else 0
        
        st.sidebar.success(f"‚úÖ ƒê√£ ch·ªçn: {days_selected} ng√†y")

        if len(filtered_df) == 0:
            st.sidebar.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu trong kho·∫£ng th·ªùi gian n√†y")
    
    return filtered_df, filter_start, filter_end

def create_vehicle_filter_sidebar(df):
    """Create vehicle and driver filters in sidebar"""
    st.sidebar.markdown("### üöó B·ªô l·ªçc xe v√† t√†i x·∫ø")
    
    if df.empty:
        return df
    
    # Vehicle type filter
    if 'vehicle_type' in df.columns:
        vehicle_types = ['T·∫•t c·∫£'] + list(df['vehicle_type'].unique())
        selected_type = st.sidebar.selectbox(
            "Lo·∫°i xe:",
            options=vehicle_types,
            index=0
        )
        
        if selected_type != 'T·∫•t c·∫£':
            df = df[df['vehicle_type'] == selected_type]
    
    # Vehicle ID filter (multiselect)
    if 'vehicle_id' in df.columns:
        vehicle_ids = list(df['vehicle_id'].unique())
        selected_vehicles = st.sidebar.multiselect(
            "Ch·ªçn xe (ƒë·ªÉ tr·ªëng = t·∫•t c·∫£):",
            options=vehicle_ids,
            default=[]
        )
        
        if selected_vehicles:
            df = df[df['vehicle_id'].isin(selected_vehicles)]
    
    # Driver filter (multiselect)
    if 'driver_name' in df.columns:
        drivers = list(df['driver_name'].unique())
        selected_drivers = st.sidebar.multiselect(
            "Ch·ªçn t√†i x·∫ø (ƒë·ªÉ tr·ªëng = t·∫•t c·∫£):",
            options=drivers,
            default=[]
        )
        
        if selected_drivers:
            df = df[df['driver_name'].isin(selected_drivers)]
    
    # Work category filter
    if 'work_category' in df.columns:
        work_categories = ['T·∫•t c·∫£'] + list(df['work_category'].dropna().unique())
        selected_category = st.sidebar.selectbox(
            "Ph√¢n lo·∫°i c√¥ng t√°c:",
            options=work_categories,
            index=0
        )
        
        if selected_category != 'T·∫•t c·∫£':
            df = df[df['work_category'] == selected_category]
    
    # Area type filter
    if 'area_type' in df.columns:
        area_types = ['T·∫•t c·∫£'] + list(df['area_type'].dropna().unique())
        selected_area = st.sidebar.selectbox(
            "Khu v·ª±c:",
            options=area_types,
            index=0
        )
        
        if selected_area != 'T·∫•t c·∫£':
            df = df[df['area_type'] == selected_area]
    
    return df

# FIXED: create_metrics_overview() - ensure duration is parsed
def create_metrics_overview(df):
    """Create overview metrics using English column names"""
    if df.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã")
        return
    
    st.markdown("## üìä T·ªïng quan ho·∫°t ƒë·ªông")
    
    # FIXED: Ensure duration is properly parsed
    df = ensure_duration_parsed(df)
    
    # Use ALL data without any filtering
    total_trips = len(df)
    total_vehicles = df['vehicle_id'].nunique() if 'vehicle_id' in df.columns else 0
    
    # Driver count
    total_drivers = df['driver_name'].nunique() if 'driver_name' in df.columns else 0
    
    # Revenue calculation
    if 'revenue_vnd' in df.columns:
        df['revenue_vnd'] = pd.to_numeric(df['revenue_vnd'], errors='coerce').fillna(0)
        total_revenue = df['revenue_vnd'].sum()
        revenue_records = df[df['revenue_vnd'] > 0]
        avg_revenue_per_trip = revenue_records['revenue_vnd'].mean() if len(revenue_records) > 0 else 0
    else:
        total_revenue = 0
        avg_revenue_per_trip = 0
    
    # FIXED: Time calculation - ensure proper parsing
    if 'Th·ªùi gian' in df.columns:
        # Filter out invalid time data (negative or extremely large values)
        valid_time_data = df[
            df['Th·ªùi gian'].notna() & 
            (df['Th·ªùi gian'] >= 0) & 
            (df['Th·ªùi gian'] <= 24)  # Reasonable daily limit
        ]
        total_hours = valid_time_data['Th·ªùi gian'].sum()
        avg_hours_per_trip = valid_time_data['Th·ªùi gian'].mean() if len(valid_time_data) > 0 else 0
    else:
        total_hours = 0
        avg_hours_per_trip = 0
    
    # Distance calculation
    if 'distance_km' in df.columns:
        df['distance_km'] = df['distance_km'].apply(parse_distance)
        valid_distance_data = df[df['distance_km'].notna() & (df['distance_km'] >= 0)]
        total_distance = valid_distance_data['distance_km'].sum()
        avg_distance = valid_distance_data['distance_km'].mean() if len(valid_distance_data) > 0 else 0
    else:
        total_distance = 0
        avg_distance = 0
    
    # Display metrics in 4-4 layout
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="üöó T·ªïng chuy·∫øn",
            value=f"{total_trips:,}",
            help="T·ªïng s·ªë chuy·∫øn ƒë√£ th·ª±c hi·ªán"
        )
    
    with col2:
        st.metric(
            label="üè• S·ªë xe ho·∫°t ƒë·ªông", 
            value=f"{total_vehicles}",
            help="S·ªë xe ƒëang ho·∫°t ƒë·ªông"
        )
    
    with col3:
        st.metric(
            label="üë®‚Äçüíº S·ªë t√†i x·∫ø",
            value=f"{total_drivers}",
            help="S·ªë t√†i x·∫ø ƒëang l√†m vi·ªác"
        )
    
    with col4:
        st.metric(
            label="üí∞ T·ªïng doanh thu",
            value=f"{total_revenue:,.0f} VNƒê",
            help="T·ªïng doanh thu t·ª´ xe c·ª©u th∆∞∆°ng"
        )
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        st.metric(
            label="‚è±Ô∏è T·ªïng gi·ªù ch·∫°y",
            value=f"{total_hours:,.1f} gi·ªù",
            help="T·ªïng th·ªùi gian v·∫≠n h√†nh"
        )
    
    with col6:
        st.metric(
            label="üõ£Ô∏è T·ªïng qu√£ng ƒë∆∞·ªùng",
            value=f"{total_distance:,.1f} km",
            help="T·ªïng qu√£ng ƒë∆∞·ªùng ƒë√£ di chuy·ªÉn"
        )
    
    with col7:
        st.metric(
            label="üíµ TB doanh thu/chuy·∫øn",
            value=f"{avg_revenue_per_trip:,.0f} VNƒê",
            help="Doanh thu trung b√¨nh m·ªói chuy·∫øn (xe c·ª©u th∆∞∆°ng)"
        )
    
    with col8:
        st.metric(
            label="‚è∞ TB gi·ªù/chuy·∫øn", 
            value=f"{avg_hours_per_trip:.1f} gi·ªù",
            help="Th·ªùi gian trung b√¨nh m·ªói chuy·∫øn"
        )


def create_frequency_metrics(df):
    """Create frequency and activity metrics using English columns"""
    st.markdown("## üéØ Ch·ªâ s·ªë t·∫ßn su·∫•t ho·∫°t ƒë·ªông")
    
    if df.empty or 'record_date' not in df.columns:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu th·ªùi gian")
        return
    
    try:
        df['record_date'] = pd.to_datetime(df['record_date'], format='%m/%d/%Y', errors='coerce')
        df['date'] = df['record_date'].dt.date
        
        # Filter out invalid dates
        valid_dates = df[df['record_date'].notna()]
        invalid_count = df['record_date'].isna().sum()
        
        if invalid_count > 0:
            st.sidebar.info(f"‚ÑπÔ∏è {invalid_count} records c√≥ ng√†y kh√¥ng h·ª£p l·ªá (v·∫´n t√≠nh trong t·ªïng)")
        
        if valid_dates.empty:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ng√†y h·ª£p l·ªá")
            return
        
        # FIXED: Calculate actual active days (only days with trips)
        active_days = valid_dates['date'].nunique()  # Only days with actual trips
        total_date_range = (valid_dates['record_date'].max() - valid_dates['record_date'].min()).days + 1
        
        # Daily trip counts
        daily_trips = valid_dates.groupby('date')['vehicle_id'].count()
        
        # Vehicle utilization
        total_vehicles = df['vehicle_id'].nunique() if 'vehicle_id' in df.columns else 1
        daily_active_vehicles = valid_dates.groupby('date')['vehicle_id'].nunique()
        
        
    except Exception as e:
        st.error(f"‚ùå L·ªói x·ª≠ l√Ω ng√†y th√°ng: {e}")
        return
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # FIXED: Use actual active days instead of total date range
        avg_trips_per_day = len(valid_dates) / active_days if active_days > 0 else 0
        st.metric(
            label="üìà Chuy·∫øn TB/ng√†y",
            value=f"{avg_trips_per_day:.1f}",
            help=f"S·ªë chuy·∫øn trung b√¨nh m·ªói ng√†y ho·∫°t ƒë·ªông ({active_days} ng√†y c√≥ chuy·∫øn)"
        )
    
    with col2:
        # FIXED: Use active days for utilization calculation too
        avg_utilization = (daily_active_vehicles.mean() / total_vehicles * 100) if total_vehicles > 0 else 0
        st.metric(
            label="üöó T·ª∑ l·ªá s·ª≠ d·ª•ng xe TB",
            value=f"{avg_utilization:.1f}%",
            help=f"T·ª∑ l·ªá xe ho·∫°t ƒë·ªông trung b√¨nh ({total_vehicles} xe t·ªïng)"
        )
    
    with col3:
        peak_day_trips = daily_trips.max() if not daily_trips.empty else 0
        peak_date = daily_trips.idxmax() if not daily_trips.empty else None
        st.metric(
            label="‚¨ÜÔ∏è Ng√†y cao ƒëi·ªÉm",
            value=f"{peak_day_trips} chuy·∫øn",
            help=f"Ng√†y c√≥ nhi·ªÅu chuy·∫øn nh·∫•t: {peak_date}" if peak_date else "Ng√†y c√≥ nhi·ªÅu chuy·∫øn nh·∫•t"
        )
    
    with col4:
        low_day_trips = daily_trips.min() if not daily_trips.empty else 0
        low_date = daily_trips.idxmin() if not daily_trips.empty else None
        st.metric(
            label="‚¨áÔ∏è Ng√†y th·∫•p ƒëi·ªÉm",
            value=f"{low_day_trips} chuy·∫øn",
            help=f"Ng√†y c√≥ √≠t chuy·∫øn nh·∫•t: {low_date}" if low_date else "Ng√†y c√≥ √≠t chuy·∫øn nh·∫•t"
        )
    
    # Additional metrics row - NEW
    st.markdown("<br>", unsafe_allow_html=True)
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        utilization_rate = (active_days / total_date_range * 100) if total_date_range > 0 else 0
        st.metric(
            label="üìÖ T·ª∑ l·ªá ng√†y ho·∫°t ƒë·ªông",
            value=f"{utilization_rate:.1f}%",
            help=f"{active_days}/{total_date_range} ng√†y c√≥ ho·∫°t ƒë·ªông"
        )
    
    with col6:
        avg_trips_per_active_day = daily_trips.mean() if not daily_trips.empty else 0
        st.metric(
            label="üìä TB chuy·∫øn/ng√†y ho·∫°t ƒë·ªông",
            value=f"{avg_trips_per_active_day:.1f}",
            help="Trung b√¨nh s·ªë chuy·∫øn trong nh·ªØng ng√†y c√≥ ho·∫°t ƒë·ªông"
        )
    
    with col7:
        max_vehicles_per_day = daily_active_vehicles.max() if not daily_active_vehicles.empty else 0
        st.metric(
            label="üöõ Max xe/ng√†y",
            value=f"{max_vehicles_per_day}",
            help="S·ªë xe t·ªëi ƒëa ho·∫°t ƒë·ªông trong 1 ng√†y"
        )
    
    with col8:
        avg_vehicles_per_day = daily_active_vehicles.mean() if not daily_active_vehicles.empty else 0
        st.metric(
            label="üöó TB xe/ng√†y",
            value=f"{avg_vehicles_per_day:.1f}",
            help="Trung b√¨nh s·ªë xe ho·∫°t ƒë·ªông m·ªói ng√†y"
        )

def create_vehicle_performance_table(df):
    """Create detailed vehicle performance table using English columns"""
    st.markdown("## üìã Hi·ªáu su·∫•t chi ti·∫øt t·ª´ng xe")
    
    if df.empty or 'vehicle_id' not in df.columns:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu xe")
        return
    
    # FIXED: Ensure duration is properly parsed
    df = ensure_duration_parsed(df)
    
    # Ensure datetime conversion
    try:
        if 'record_date' in df.columns:
            df['record_date'] = pd.to_datetime(df['record_date'], format='%m/%d/%Y', errors='coerce')
            df['date'] = df['record_date'].dt.date
            
            valid_dates = df[df['record_date'].notna()]
            if not valid_dates.empty:
                total_days = (valid_dates['record_date'].max() - valid_dates['record_date'].min()).days + 1
            else:
                total_days = 30
        else:
            total_days = 30
    except:
        total_days = 30
    
    # Ensure numeric columns
    if 'revenue_vnd' in df.columns:
        df['revenue_vnd'] = pd.to_numeric(df['revenue_vnd'], errors='coerce').fillna(0)
    else:
        df['revenue_vnd'] = 0
        
    # FIXED: Duration is already parsed by ensure_duration_parsed()
    if 'Th·ªùi gian' not in df.columns:
        df['Th·ªùi gian'] = 0
        
    if 'distance_km' in df.columns:
        df['distance_km'] = df['distance_km'].apply(parse_distance)
    else:
        df['distance_km'] = 0
        
    if 'fuel_liters' in df.columns:
        df['fuel_liters'] = pd.to_numeric(df['fuel_liters'], errors='coerce').fillna(0)
    else:
        df['fuel_liters'] = 0
    
    # Calculate metrics per vehicle
    vehicles = df['vehicle_id'].unique()
    results = []
    
    for vehicle in vehicles:
        vehicle_data = df[df['vehicle_id'] == vehicle]
        
        # Basic metrics
        total_trips = len(vehicle_data)
        total_revenue = float(vehicle_data['revenue_vnd'].sum())
        avg_revenue = float(vehicle_data['revenue_vnd'].mean()) if total_trips > 0 else 0.0
        
        # FIXED: Duration calculation - filter out invalid values
        valid_duration_data = vehicle_data[
            vehicle_data['Th·ªùi gian'].notna() & 
            (vehicle_data['Th·ªùi gian'] >= 0) & 
            (vehicle_data['Th·ªùi gian'] <= 24)
        ]
        total_hours = float(valid_duration_data['Th·ªùi gian'].sum())
        
        total_distance = float(vehicle_data['distance_km'].sum())
        total_fuel = float(vehicle_data['fuel_liters'].sum())
        
        # Days calculation
        if 'date' in vehicle_data.columns:
            active_days = vehicle_data['date'].nunique()
        else:
            active_days = total_days
        
        # Derived metrics
        fuel_per_100km = (total_fuel / total_distance * 100.0) if total_distance > 0 else 0.0
        trips_per_day = (float(total_trips) / float(active_days)) if active_days > 0 else 0.0
        utilization = (float(active_days) / float(total_days) * 100.0) if total_days > 0 else 0.0
        
        # Performance rating
        if trips_per_day >= 2 and utilization >= 70:
            performance = 'Cao'
        elif trips_per_day >= 1 and utilization >= 50:
            performance = 'Trung b√¨nh'
        else:
            performance = 'Th·∫•p'
        
        results.append({
            'M√£ xe': vehicle,
            'T·ªïng chuy·∫øn': total_trips,
            'T·ªïng doanh thu': round(total_revenue, 0),
            'Doanh thu TB/chuy·∫øn': round(avg_revenue, 0),
            'T·ªïng gi·ªù ch·∫°y': round(total_hours, 1),
            'S·ªë ng√†y ho·∫°t ƒë·ªông': active_days,
            'T·ªïng qu√£ng ƒë∆∞·ªùng': round(total_distance, 1),
            'Nhi√™n li·ªáu ti√™u th·ª•': round(total_fuel, 1),
            'Nhi√™n li·ªáu/100km': round(fuel_per_100km, 2),
            'Chuy·∫øn/ng√†y': round(trips_per_day, 1),
            'T·ª∑ l·ªá s·ª≠ d·ª•ng (%)': round(utilization, 1),
            'Hi·ªáu su·∫•t': performance
        })
    
    # Create DataFrame
    vehicle_display = pd.DataFrame(results)
    vehicle_display = vehicle_display.set_index('M√£ xe').sort_values('T·ªïng doanh thu', ascending=False)
    
    # Display table
    st.dataframe(
        vehicle_display.style.format({
            'T·ªïng doanh thu': '{:,.0f}',
            'Doanh thu TB/chuy·∫øn': '{:,.0f}',
            'T·ªïng gi·ªù ch·∫°y': '{:.1f}',
            'T·ªïng qu√£ng ƒë∆∞·ªùng': '{:.1f}',
            'Nhi√™n li·ªáu ti√™u th·ª•': '{:.1f}',
            'Nhi√™n li·ªáu/100km': '{:.2f}',
            'Chuy·∫øn/ng√†y': '{:.1f}',
            'T·ª∑ l·ªá s·ª≠ d·ª•ng (%)': '{:.1f}'
        }),
        use_container_width=True,
        height=400
    )

def create_revenue_analysis_tab(df):
    """Tab 1: Ph√¢n t√≠ch doanh thu"""
    st.markdown("### üí∞ Ph√¢n t√≠ch doanh thu chi ti·∫øt")
    
    if df.empty or 'revenue_vnd' not in df.columns:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu doanh thu")
        return
    
    # Ensure proper data types
    df['revenue_vnd'] = pd.to_numeric(df['revenue_vnd'], errors='coerce').fillna(0)
    revenue_data = df[df['revenue_vnd'] > 0].copy()
    
    if revenue_data.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ chuy·∫øn xe c√≥ doanh thu")
        return
    
    # Revenue by vehicle chart
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä Doanh thu theo xe")
        vehicle_revenue = revenue_data.groupby('vehicle_id')['revenue_vnd'].agg(['sum', 'count', 'mean']).reset_index()
        vehicle_revenue.columns = ['vehicle_id', 'total_revenue', 'trip_count', 'avg_revenue']
        vehicle_revenue = vehicle_revenue.sort_values('total_revenue', ascending=False)
        
        fig_vehicle = px.bar(
            vehicle_revenue.head(10),
            x='vehicle_id',
            y='total_revenue',
            title="Top 10 xe c√≥ doanh thu cao nh·∫•t",
            labels={'total_revenue': 'Doanh thu (VNƒê)', 'vehicle_id': 'M√£ xe'},
            color='total_revenue',
            color_continuous_scale='Blues'
        )
        fig_vehicle.update_layout(height=400)
        st.plotly_chart(fig_vehicle, use_container_width=True)
    
    with col2:
        st.markdown("#### üìà Doanh thu theo th·ªùi gian")
        if 'record_date' in revenue_data.columns:
            daily_revenue = revenue_data.groupby('date')['revenue_vnd'].sum().reset_index()
            daily_revenue = daily_revenue.sort_values('date')
            
            fig_time = px.line(
                daily_revenue,
                x='date',
                y='revenue_vnd',
                title="Xu h∆∞·ªõng doanh thu theo ng√†y",
                labels={'revenue_vnd': 'Doanh thu (VNƒê)', 'date': 'Ng√†y'}
            )
            fig_time.update_layout(height=400)
            st.plotly_chart(fig_time, use_container_width=True)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu th·ªùi gian ƒë·ªÉ hi·ªÉn th·ªã xu h∆∞·ªõng")
    
    # Revenue distribution
    col3, col4 = st.columns(2)
    
    with col3:
        st.markdown("#### üìä Ph√¢n b·ªë doanh thu m·ªói chuy·∫øn")
        fig_dist = px.histogram(
            revenue_data,
            x='revenue_vnd',
            nbins=20,
            title="Ph√¢n b·ªë doanh thu m·ªói chuy·∫øn",
            labels={'revenue_vnd': 'Doanh thu (VNƒê)', 'count': 'S·ªë chuy·∫øn'}
        )
        fig_dist.update_layout(height=400)
        st.plotly_chart(fig_dist, use_container_width=True)
    
    with col4:
        st.markdown("#### üë®‚Äçüíº Doanh thu theo t√†i x·∫ø")
        if 'driver_name' in revenue_data.columns:
            driver_revenue = revenue_data.groupby('driver_name')['revenue_vnd'].sum().reset_index()
            driver_revenue = driver_revenue.sort_values('revenue_vnd', ascending=False).head(10)
            
            fig_driver = px.pie(
                driver_revenue,
                values='revenue_vnd',
                names='driver_name',
                title="Top 10 t√†i x·∫ø theo doanh thu"
            )
            fig_driver.update_layout(height=400)
            st.plotly_chart(fig_driver, use_container_width=True)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu t√†i x·∫ø")
    
    # Revenue metrics table
    st.markdown("#### üìã B·∫£ng th·ªëng k√™ doanh thu")
    revenue_stats = pd.DataFrame({
        'Ch·ªâ s·ªë': ['T·ªïng doanh thu', 'Doanh thu TB/chuy·∫øn', 'Doanh thu cao nh·∫•t', 'Doanh thu th·∫•p nh·∫•t', 'S·ªë chuy·∫øn c√≥ doanh thu'],
        'Gi√° tr·ªã': [
            f"{revenue_data['revenue_vnd'].sum():,.0f} VNƒê",
            f"{revenue_data['revenue_vnd'].mean():,.0f} VNƒê",
            f"{revenue_data['revenue_vnd'].max():,.0f} VNƒê",
            f"{revenue_data['revenue_vnd'].min():,.0f} VNƒê",
            f"{len(revenue_data):,} chuy·∫øn"
        ]
    })
    st.dataframe(revenue_stats, use_container_width=True, hide_index=True)

def create_vehicle_efficiency_tab(df):
    """Tab 2: Hi·ªáu su·∫•t xe"""
    st.markdown("### üöó Ph√¢n t√≠ch hi·ªáu su·∫•t xe")
    
    if df.empty or 'vehicle_id' not in df.columns:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu xe")
        return
    
    # Calculate efficiency metrics per vehicle
    vehicle_stats = []
    for vehicle in df['vehicle_id'].unique():
        vehicle_data = df[df['vehicle_id'] == vehicle]
        
        # Basic metrics
        total_trips = len(vehicle_data)
        total_hours = vehicle_data['Th·ªùi gian'].sum() if 'Th·ªùi gian' in vehicle_data.columns else 0
        total_distance = vehicle_data['distance_km'].sum() if 'distance_km' in vehicle_data.columns else 0
        total_revenue = vehicle_data['revenue_vnd'].sum() if 'revenue_vnd' in vehicle_data.columns else 0
        
        # Active days
        active_days = vehicle_data['date'].nunique() if 'date' in vehicle_data.columns else 1
        
        # Efficiency metrics
        trips_per_day = total_trips / active_days if active_days > 0 else 0
        hours_per_trip = total_hours / total_trips if total_trips > 0 else 0
        distance_per_trip = total_distance / total_trips if total_trips > 0 else 0
        revenue_per_hour = total_revenue / total_hours if total_hours > 0 else 0
        
        vehicle_stats.append({
            'vehicle_id': vehicle,
            'total_trips': total_trips,
            'active_days': active_days,
            'trips_per_day': trips_per_day,
            'hours_per_trip': hours_per_trip,
            'distance_per_trip': distance_per_trip,
            'revenue_per_hour': revenue_per_hour,
            'total_hours': total_hours,
            'total_distance': total_distance,
            'total_revenue': total_revenue
        })
    
    efficiency_df = pd.DataFrame(vehicle_stats)
    
    # Efficiency charts
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä Chuy·∫øn/ng√†y theo xe")
        fig_trips = px.bar(
            efficiency_df.sort_values('trips_per_day', ascending=False).head(15),
            x='vehicle_id',
            y='trips_per_day',
            title="S·ªë chuy·∫øn trung b√¨nh m·ªói ng√†y",
            labels={'trips_per_day': 'Chuy·∫øn/ng√†y', 'vehicle_id': 'M√£ xe'},
            color='trips_per_day',
            color_continuous_scale='Greens'
        )
        fig_trips.update_layout(height=400)
        st.plotly_chart(fig_trips, use_container_width=True)
    
    with col2:
        st.markdown("#### ‚è±Ô∏è Th·ªùi gian trung b√¨nh m·ªói chuy·∫øn")
        fig_hours = px.bar(
            efficiency_df.sort_values('hours_per_trip', ascending=False).head(15),
            x='vehicle_id',
            y='hours_per_trip',
            title="Gi·ªù trung b√¨nh m·ªói chuy·∫øn",
            labels={'hours_per_trip': 'Gi·ªù/chuy·∫øn', 'vehicle_id': 'M√£ xe'},
            color='hours_per_trip',
            color_continuous_scale='Oranges'
        )
        fig_hours.update_layout(height=400)
        st.plotly_chart(fig_hours, use_container_width=True)
    
    # Scatter plot: Efficiency comparison
    col3, col4 = st.columns(2)
    
    with col3:
        st.markdown("#### üéØ Hi·ªáu su·∫•t: Chuy·∫øn/ng√†y vs Doanh thu/gi·ªù")
        fig_scatter = px.scatter(
            efficiency_df,
            x='trips_per_day',
            y='revenue_per_hour',
            size='total_trips',
            hover_data=['vehicle_id', 'active_days'],
            title="Ma tr·∫≠n hi·ªáu su·∫•t xe",
            labels={'trips_per_day': 'Chuy·∫øn/ng√†y', 'revenue_per_hour': 'Doanh thu/gi·ªù (VNƒê)'}
        )
        fig_scatter.update_layout(height=400)
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    with col4:
        st.markdown("#### üìè Qu√£ng ƒë∆∞·ªùng trung b√¨nh m·ªói chuy·∫øn")
        fig_distance = px.bar(
            efficiency_df.sort_values('distance_per_trip', ascending=False).head(15),
            x='vehicle_id',
            y='distance_per_trip',
            title="Km trung b√¨nh m·ªói chuy·∫øn",
            labels={'distance_per_trip': 'Km/chuy·∫øn', 'vehicle_id': 'M√£ xe'},
            color='distance_per_trip',
            color_continuous_scale='Blues'
        )
        fig_distance.update_layout(height=400)
        st.plotly_chart(fig_distance, use_container_width=True)
    
    # Top performers table
    st.markdown("#### üèÜ Top xe hi·ªáu su·∫•t cao")
    top_performers = efficiency_df.nlargest(10, 'trips_per_day')[['vehicle_id', 'trips_per_day', 'hours_per_trip', 'distance_per_trip', 'revenue_per_hour']]
    top_performers.columns = ['M√£ xe', 'Chuy·∫øn/ng√†y', 'Gi·ªù/chuy·∫øn', 'Km/chuy·∫øn', 'Doanh thu/gi·ªù']
    st.dataframe(top_performers.round(2), use_container_width=True, hide_index=True)

def create_overload_analysis_tab(df):
    """Tab 3: Ph√¢n t√≠ch qu√° t·∫£i"""
    st.markdown("### ‚ö° Ph√¢n t√≠ch qu√° t·∫£i v√† t·ªëi ∆∞u h√≥a")
    
    if df.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch")
        return
    
    # Define overload thresholds
    st.markdown("#### üéØ Thi·∫øt l·∫≠p ng∆∞·ª°ng c·∫£nh b√°o")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        max_hours_per_day = st.number_input("Max gi·ªù/ng√†y", value=10.0, min_value=1.0, max_value=24.0)
    with col2:
        max_trips_per_day = st.number_input("Max chuy·∫øn/ng√†y", value=8, min_value=1, max_value=20)
    with col3:
        max_distance_per_trip = st.number_input("Max km/chuy·∫øn", value=100.0, min_value=1.0, max_value=500.0)
    
    # Calculate daily workload per vehicle and driver
    if 'date' in df.columns:
        # Vehicle daily workload
        vehicle_daily = df.groupby(['vehicle_id', 'date']).agg({
            'Th·ªùi gian': 'sum',
            'distance_km': 'sum',
            'revenue_vnd': 'count'  # count trips - use different column to avoid conflict
        }).reset_index()
        vehicle_daily.columns = ['vehicle_id', 'date', 'daily_hours', 'daily_distance', 'daily_trips']
        
        # Driver daily workload
        if 'driver_name' in df.columns:
            driver_daily = df.groupby(['driver_name', 'date']).agg({
                'Th·ªùi gian': 'sum',
                'distance_km': 'sum',
                'revenue_vnd': 'count'  # count trips - use different column to avoid conflict
            }).reset_index()
            driver_daily.columns = ['driver_name', 'date', 'daily_hours', 'daily_distance', 'daily_trips']
        
        # Identify overloaded days
        vehicle_overload = vehicle_daily[
            (vehicle_daily['daily_hours'] > max_hours_per_day) |
            (vehicle_daily['daily_trips'] > max_trips_per_day)
        ]
        
        # Charts
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üö® Xe v∆∞·ª£t ng∆∞·ª°ng gi·ªù l√†m vi·ªác")
            if not vehicle_overload.empty:
                fig_overload = px.scatter(
                    vehicle_daily,
                    x='daily_trips',
                    y='daily_hours',
                    color='vehicle_id',
                    title="Ph√¢n t√≠ch t·∫£i c√¥ng vi·ªác h√†ng ng√†y",
                    labels={'daily_trips': 'S·ªë chuy·∫øn/ng√†y', 'daily_hours': 'Gi·ªù l√†m vi·ªác/ng√†y'}
                )
                # Add threshold lines
                fig_overload.add_hline(y=max_hours_per_day, line_dash="dash", line_color="red", 
                                     annotation_text=f"Max {max_hours_per_day}h/ng√†y")
                fig_overload.add_vline(x=max_trips_per_day, line_dash="dash", line_color="red",
                                     annotation_text=f"Max {max_trips_per_day} chuy·∫øn/ng√†y")
                fig_overload.update_layout(height=400)
                st.plotly_chart(fig_overload, use_container_width=True)
            else:
                st.success("‚úÖ Kh√¥ng c√≥ xe n√†o v∆∞·ª£t ng∆∞·ª°ng!")
        
        with col2:
            st.markdown("#### üìä Ph√¢n b·ªë t·∫£i c√¥ng vi·ªác")
            # Heatmap of workload by day and vehicle
            if len(vehicle_daily) > 0:
                pivot_hours = vehicle_daily.pivot_table(
                    values='daily_hours', 
                    index='vehicle_id', 
                    columns='date', 
                    aggfunc='mean'
                ).fillna(0)
                
                if not pivot_hours.empty:
                    fig_heatmap = px.imshow(
                        pivot_hours.values,
                        labels=dict(x="Ng√†y", y="Xe", color="Gi·ªù/ng√†y"),
                        y=pivot_hours.index,
                        title="B·∫£n ƒë·ªì nhi·ªát t·∫£i c√¥ng vi·ªác"
                    )
                    fig_heatmap.update_layout(height=400)
                    st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # Distance analysis
        col3, col4 = st.columns(2)
        
        with col3:
            st.markdown("#### üõ£Ô∏è Ph√¢n t√≠ch qu√£ng ƒë∆∞·ªùng nguy hi·ªÉm")
            if 'distance_km' in df.columns:
                long_trips = df[df['distance_km'] > max_distance_per_trip]
                
                if not long_trips.empty:
                    fig_distance = px.histogram(
                        df,
                        x='distance_km',
                        nbins=30,
                        title="Ph√¢n b·ªë qu√£ng ƒë∆∞·ªùng chuy·∫øn xe",
                        labels={'distance_km': 'Qu√£ng ƒë∆∞·ªùng (km)', 'count': 'S·ªë chuy·∫øn'}
                    )
                    fig_distance.add_vline(x=max_distance_per_trip, line_dash="dash", line_color="red",
                                         annotation_text=f"Ng∆∞·ª°ng {max_distance_per_trip}km")
                    fig_distance.update_layout(height=400)
                    st.plotly_chart(fig_distance, use_container_width=True)
                else:
                    st.success("‚úÖ Kh√¥ng c√≥ chuy·∫øn xe n√†o v∆∞·ª£t ng∆∞·ª°ng km!")
        
        with col4:
            st.markdown("#### ‚ö†Ô∏è C·∫£nh b√°o qu√° t·∫£i")
            
            # Overload summary
            overload_summary = []
            
            # Vehicle overload count
            vehicle_overload_count = len(vehicle_overload)
            if vehicle_overload_count > 0:
                overload_summary.append(f"üö® {vehicle_overload_count} l·∫ßn xe v∆∞·ª£t ng∆∞·ª°ng")
            
            # Long distance trips
            if 'distance_km' in df.columns:
                long_trips_count = len(df[df['distance_km'] > max_distance_per_trip])
                if long_trips_count > 0:
                    overload_summary.append(f"üõ£Ô∏è {long_trips_count} chuy·∫øn v∆∞·ª£t ng∆∞·ª°ng km")
            
            if overload_summary:
                for warning in overload_summary:
                    st.warning(warning)
            else:
                st.success("‚úÖ H·ªá th·ªëng ho·∫°t ƒë·ªông trong ng∆∞·ª°ng an to√†n!")
            
            # Top overloaded vehicles
            if not vehicle_overload.empty:
                st.markdown("**Xe hay b·ªã qu√° t·∫£i:**")
                overload_freq = vehicle_overload['vehicle_id'].value_counts().head(5)
                for vehicle, count in overload_freq.items():
                    st.error(f"üöó {vehicle}: {count} l·∫ßn")
    
    else:
        st.info("‚ÑπÔ∏è C·∫ßn d·ªØ li·ªáu ng√†y ƒë·ªÉ ph√¢n t√≠ch qu√° t·∫£i chi ti·∫øt")

def create_distance_analysis_tab(df):
    """Tab 4: Ph√¢n t√≠ch qu√£ng ƒë∆∞·ªùng"""
    st.markdown("### üõ£Ô∏è Ph√¢n t√≠ch qu√£ng ƒë∆∞·ªùng chi ti·∫øt")
    
    if df.empty or 'distance_km' not in df.columns:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu qu√£ng ƒë∆∞·ªùng")
        return
    
    # Ensure proper data types
    df['distance_km'] = df['distance_km'].apply(parse_distance)
    distance_data = df[df['distance_km'] > 0].copy()
    
    if distance_data.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu qu√£ng ƒë∆∞·ªùng h·ª£p l·ªá")
        return
    
    # Distance by vehicle
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä T·ªïng qu√£ng ƒë∆∞·ªùng theo xe")
        vehicle_distance = distance_data.groupby('vehicle_id')['distance_km'].agg(['sum', 'count', 'mean']).reset_index()
        vehicle_distance.columns = ['vehicle_id', 'total_distance', 'trip_count', 'avg_distance']
        vehicle_distance = vehicle_distance.sort_values('total_distance', ascending=False)
        
        fig_vehicle_dist = px.bar(
            vehicle_distance.head(15),
            x='vehicle_id',
            y='total_distance',
            title="Top 15 xe ch·∫°y xa nh·∫•t",
            labels={'total_distance': 'T·ªïng qu√£ng ƒë∆∞·ªùng (km)', 'vehicle_id': 'M√£ xe'},
            color='total_distance',
            color_continuous_scale='Viridis'
        )
        fig_vehicle_dist.update_layout(height=400)
        st.plotly_chart(fig_vehicle_dist, use_container_width=True)
    
    with col2:
        st.markdown("#### üìà Xu h∆∞·ªõng qu√£ng ƒë∆∞·ªùng theo th·ªùi gian")
        if 'date' in distance_data.columns:
            daily_distance = distance_data.groupby('date')['distance_km'].sum().reset_index()
            daily_distance = daily_distance.sort_values('date')
            
            fig_time_dist = px.line(
                daily_distance,
                x='date',
                y='distance_km',
                title="T·ªïng qu√£ng ƒë∆∞·ªùng theo ng√†y",
                labels={'distance_km': 'Qu√£ng ƒë∆∞·ªùng (km)', 'date': 'Ng√†y'}
            )
            fig_time_dist.update_layout(height=400)
            st.plotly_chart(fig_time_dist, use_container_width=True)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu th·ªùi gian")
    
    # Distance distribution and efficiency
    col3, col4 = st.columns(2)
    
    with col3:
        st.markdown("#### üìä Ph√¢n b·ªë qu√£ng ƒë∆∞·ªùng m·ªói chuy·∫øn")
        fig_dist_hist = px.histogram(
            distance_data,
            x='distance_km',
            nbins=25,
            title="Ph√¢n b·ªë qu√£ng ƒë∆∞·ªùng chuy·∫øn xe",
            labels={'distance_km': 'Qu√£ng ƒë∆∞·ªùng (km)', 'count': 'S·ªë chuy·∫øn'}
        )
        
        # Add statistics lines
        mean_distance = distance_data['distance_km'].mean()
        median_distance = distance_data['distance_km'].median()
        
        fig_dist_hist.add_vline(x=mean_distance, line_dash="dash", line_color="red",
                               annotation_text=f"TB: {mean_distance:.1f}km")
        fig_dist_hist.add_vline(x=median_distance, line_dash="dash", line_color="blue",
                               annotation_text=f"Trung v·ªã: {median_distance:.1f}km")
        fig_dist_hist.update_layout(height=400)
        st.plotly_chart(fig_dist_hist, use_container_width=True)
    
    with col4:
        st.markdown("#### üéØ Hi·ªáu su·∫•t qu√£ng ƒë∆∞·ªùng theo xe")
        # Distance efficiency: km per hour
        if 'Th·ªùi gian' in distance_data.columns:
            # Create a copy to avoid modifying original data
            efficiency_data = distance_data.copy()
            efficiency_data['km_per_hour'] = efficiency_data['distance_km'] / efficiency_data['Th·ªùi gian']
            efficiency_data['km_per_hour'] = efficiency_data['km_per_hour'].replace([np.inf, -np.inf], np.nan)
            
            vehicle_efficiency = efficiency_data.groupby('vehicle_id')['km_per_hour'].mean().reset_index()
            vehicle_efficiency = vehicle_efficiency.sort_values('km_per_hour', ascending=False).head(15)
            
            fig_efficiency = px.bar(
                vehicle_efficiency,
                x='vehicle_id',
                y='km_per_hour',
                title="T·ªëc ƒë·ªô trung b√¨nh (km/h)",
                labels={'km_per_hour': 'Km/gi·ªù', 'vehicle_id': 'M√£ xe'},
                color='km_per_hour',
                color_continuous_scale='RdYlGn'
            )
            fig_efficiency.update_layout(height=400)
            st.plotly_chart(fig_efficiency, use_container_width=True)
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu th·ªùi gian ƒë·ªÉ t√≠nh hi·ªáu su·∫•t")
    
    # Area analysis
    if 'area_type' in distance_data.columns:
        col5, col6 = st.columns(2)
        
        with col5:
            st.markdown("#### üèôÔ∏è Ph√¢n t√≠ch theo khu v·ª±c")
            area_stats = distance_data.groupby('area_type').agg({
                'distance_km': ['sum', 'mean', 'count']
            }).round(2)
            area_stats.columns = ['T·ªïng km', 'TB km/chuy·∫øn', 'S·ªë chuy·∫øn']
            area_stats = area_stats.reset_index()
            
            fig_area = px.pie(
                area_stats,
                values='T·ªïng km',
                names='area_type',
                title="Ph√¢n b·ªë qu√£ng ƒë∆∞·ªùng theo khu v·ª±c"
            )
            fig_area.update_layout(height=400)
            st.plotly_chart(fig_area, use_container_width=True)
        
        with col6:
            st.markdown("#### üìã Th·ªëng k√™ theo khu v·ª±c")
            st.dataframe(area_stats, use_container_width=True, hide_index=True)
    
    # Distance statistics summary
    st.markdown("#### üìä T·ªïng quan th·ªëng k√™ qu√£ng ƒë∆∞·ªùng")
    distance_stats = pd.DataFrame({
        'Ch·ªâ s·ªë': [
            'T·ªïng qu√£ng ƒë∆∞·ªùng',
            'Qu√£ng ƒë∆∞·ªùng TB/chuy·∫øn',
            'Qu√£ng ƒë∆∞·ªùng d√†i nh·∫•t',
            'Qu√£ng ƒë∆∞·ªùng ng·∫Øn nh·∫•t',
            'S·ªë chuy·∫øn c√≥ d·ªØ li·ªáu km'
        ],
        'Gi√° tr·ªã': [
            f"{distance_data['distance_km'].sum():,.1f} km",
            f"{distance_data['distance_km'].mean():,.1f} km",
            f"{distance_data['distance_km'].max():,.1f} km",
            f"{distance_data['distance_km'].min():,.1f} km",
            f"{len(distance_data):,} chuy·∫øn"
        ]
    })
    st.dataframe(distance_stats, use_container_width=True, hide_index=True)
    
def create_fuel_analysis_tab(df):
    """Tab 5: Ph√¢n t√≠ch nhi√™n li·ªáu chi ti·∫øt - FIXED VERSION"""
    st.markdown("### ‚õΩ Ph√¢n t√≠ch nhi√™n li·ªáu v√† ƒë·ªãnh m·ª©c ti√™u th·ª•")
    
    if df.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch")
        return
    
    # ƒê·ªãnh m·ª©c nhi√™n li·ªáu theo xe (l√≠t/100km)
    FUEL_STANDARDS = {
        "50M-004.37": 18,
        "50M-002.19": 18,
        "50A-009.44": 16,
        "50A-007.39": 16,
        "50A-010.67": 17,
        "50A-018.35": 15,
        "51B-509.51": 17,
        "50A-019.90": 13,
        "50A-007.20": 20,
        "50A-004.55": 22,
        "50A-012.59": 10,
        "51B-330.67": 29
    }
    
    # ƒê·∫£m b·∫£o d·ªØ li·ªáu nhi√™n li·ªáu v√† qu√£ng ƒë∆∞·ªùng h·ª£p l·ªá
    if 'fuel_liters' not in df.columns or 'distance_km' not in df.columns:
        st.error("‚ùå Thi·∫øu d·ªØ li·ªáu nhi√™n li·ªáu ho·∫∑c qu√£ng ƒë∆∞·ªùng")
        return
    
    # FIXED: L√†m s·∫°ch d·ªØ li·ªáu - d·ªØ li·ªáu ƒë√£ l√† float64, ch·ªâ c·∫ßn x·ª≠ l√Ω NaN v√† outliers
    df = df.copy()  # T·∫°o copy ƒë·ªÉ tr√°nh thay ƒë·ªïi d·ªØ li·ªáu g·ªëc
    
    # Clean fuel_liters
    df['fuel_liters'] = pd.to_numeric(df['fuel_liters'], errors='coerce').fillna(0)
    # Remove unrealistic values
    df['fuel_liters'] = df['fuel_liters'].apply(lambda x: x if (x >= 0 and x <= 500) else 0)
    
    # FIXED: Clean distance_km - kh√¥ng d√πng parse_distance n·ªØa v√¨ ƒë√£ l√† float64
    df['distance_km'] = pd.to_numeric(df['distance_km'], errors='coerce').fillna(0)
    # Remove unrealistic values
    df['distance_km'] = df['distance_km'].apply(lambda x: x if (x >= 0 and x <= 2000) else 0)
    
    # FIXED: L·ªçc d·ªØ li·ªáu h·ª£p l·ªá (c√≥ c·∫£ nhi√™n li·ªáu v√† qu√£ng ƒë∆∞·ªùng > 0)
    fuel_data = df[
        (df['fuel_liters'] > 0) & 
        (df['distance_km'] > 0) &
        (df['fuel_liters'] <= 1000) &  # Reasonable fuel limit
        (df['distance_km'] <= 2000)   # Reasonable distance limit
    ].copy()
    
    if fuel_data.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu nhi√™n li·ªáu h·ª£p l·ªá")
        st.info("Ki·ªÉm tra xem c√≥ chuy·∫øn n√†o c√≥ c·∫£ d·ªØ li·ªáu nhi√™n li·ªáu V√Ä qu√£ng ƒë∆∞·ªùng > 0 kh√¥ng")
        return
    
    # FIXED: T√≠nh m·ª©c ti√™u th·ª• nhi√™n li·ªáu (l√≠t/100km) - c√¥ng th·ª©c ƒë√∫ng
    fuel_data['fuel_consumption_per_100km'] = (fuel_data['fuel_liters'] / fuel_data['distance_km']) * 100
    
    # FIXED: Lo·∫°i b·ªè outliers (m·ª©c ti√™u th·ª• kh√¥ng h·ª£p l√Ω)
    initial_count = len(fuel_data)
    fuel_data = fuel_data[
        (fuel_data['fuel_consumption_per_100km'] >= 5) &    # Minimum reasonable consumption
        (fuel_data['fuel_consumption_per_100km'] <= 100)     # Maximum reasonable consumption
    ]
    
    removed_outliers = initial_count - len(fuel_data)
    if removed_outliers > 0:
        st.sidebar.info(f"‚ÑπÔ∏è ƒê√£ lo·∫°i b·ªè {removed_outliers} chuy·∫øn c√≥ m·ª©c ti√™u th·ª• b·∫•t th∆∞·ªùng")
    
    if fuel_data.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu nhi√™n li·ªáu h·ª£p l·ªá sau khi l·ªçc outliers")
        return
    
    # Ph√¢n t√≠ch theo xe (bao g·ªìm c·∫£ xe KH√îNG c√≥ fuel_data h·ª£p l·ªá)
    vehicle_fuel_analysis = []
    all_vehicles = df['vehicle_id'].unique()  # d√πng to√†n b·ªô danh s√°ch xe g·ªëc

    for vehicle in all_vehicles:
        vehicle_data = fuel_data[fuel_data['vehicle_id'] == vehicle]

        if vehicle_data.empty:
            # Kh√¥ng c√≥ chuy·∫øn h·ª£p l·ªá sau khi l·ªçc ‚áí th√™m h√†ng placeholder
            vehicle_fuel_analysis.append({
                'vehicle_id': vehicle,
                'total_fuel': 0.0,
                'total_distance': 0.0,
                'avg_consumption': 0.0,
                'standard': FUEL_STANDARDS.get(vehicle, 0),
                'deviation': 0.0,
                'deviation_percent': 0.0,
                'trips_count': 0,
                'status': '‚ö™ Thi·∫øu d·ªØ li·ªáu',
                'status_color': 'gray'
            })
            continue

        # ---- C√≥ d·ªØ li·ªáu h·ª£p l·ªá: t√≠nh ch·ªâ s·ªë nh∆∞ c≈© ----
        total_fuel = float(vehicle_data['fuel_liters'].sum())
        total_distance = float(vehicle_data['distance_km'].sum())
        trips_count = len(vehicle_data)
        avg_consumption = float(vehicle_data['fuel_consumption_per_100km'].mean())

        standard = FUEL_STANDARDS.get(vehicle, None)
        if standard:
            deviation = avg_consumption - standard
            deviation_percent = (deviation / standard) * 100
            if deviation > 2:
                status = "üî¥ V∆∞·ª£t ƒë·ªãnh m·ª©c"
                status_color = "red"
            elif deviation < -1:
                status = "üü¢ Ti·∫øt ki·ªám"
                status_color = "green"
            else:
                status = "üü° Trong ƒë·ªãnh m·ª©c"
                status_color = "orange"
        else:
            status = "‚ö™ Ch∆∞a c√≥ ƒë·ªãnh m·ª©c"
            status_color = "gray"
            deviation = 0
            deviation_percent = 0

        vehicle_fuel_analysis.append({
            'vehicle_id': vehicle,
            'total_fuel': total_fuel,
            'total_distance': total_distance,
            'avg_consumption': avg_consumption,
            'standard': standard if standard else 0,
            'deviation': deviation,
            'deviation_percent': deviation_percent,
            'trips_count': trips_count,
            'status': status,
            'status_color': status_color
        })
    
    vehicle_fuel_df = pd.DataFrame(vehicle_fuel_analysis)
    
    # Overview metrics
    st.markdown("#### üìä T·ªïng quan ti√™u th·ª• nhi√™n li·ªáu")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_fuel_consumed = fuel_data['fuel_liters'].sum()
        st.metric(
            label="‚õΩ T·ªïng nhi√™n li·ªáu",
            value=f"{total_fuel_consumed:,.1f} l√≠t",
            help="T·ªïng l∆∞·ª£ng nhi√™n li·ªáu ti√™u th·ª•"
        )
    
    with col2:
        avg_consumption_fleet = fuel_data['fuel_consumption_per_100km'].mean()
        st.metric(
            label="üìä TB ti√™u th·ª• ƒë·ªôi xe",
            value=f"{avg_consumption_fleet:.1f} L/100km",
            help="M·ª©c ti√™u th·ª• trung b√¨nh c·ªßa to√†n ƒë·ªôi xe"
        )
    
    with col3:
        vehicles_over_standard = len(vehicle_fuel_df[vehicle_fuel_df['deviation'] > 2])
        st.metric(
            label="üî¥ Xe v∆∞·ª£t ƒë·ªãnh m·ª©c",
            value=f"{vehicles_over_standard}",
            help="S·ªë xe ti√™u th·ª• v∆∞·ª£t ƒë·ªãnh m·ª©c > 2L/100km"
        )
    
    with col4:
        vehicles_efficient = len(vehicle_fuel_df[vehicle_fuel_df['deviation'] < -1])
        st.metric(
            label="üü¢ Xe ti·∫øt ki·ªám",
            value=f"{vehicles_efficient}",
            help="S·ªë xe ti√™u th·ª• th·∫•p h∆°n ƒë·ªãnh m·ª©c > 1L/100km"
        )
    
    # Charts
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä So s√°nh ti√™u th·ª• v·ªõi ƒë·ªãnh m·ª©c")
        
        # T·∫°o d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì so s√°nh
        comparison_data = []
        for _, row in vehicle_fuel_df.iterrows():
            if row['standard'] > 0:  # Ch·ªâ hi·ªÉn th·ªã xe c√≥ ƒë·ªãnh m·ª©c
                comparison_data.append({
                    'Xe': row['vehicle_id'],
                    'Th·ª±c t·∫ø': row['avg_consumption'],
                    'ƒê·ªãnh m·ª©c': row['standard'],
                    'Tr·∫°ng th√°i': row['status_color']
                })
        
        if comparison_data:
            comparison_df = pd.DataFrame(comparison_data)
            
            fig_comparison = go.Figure()
            
            # Th√™m c·ªôt ƒë·ªãnh m·ª©c
            fig_comparison.add_trace(go.Bar(
                name='ƒê·ªãnh m·ª©c',
                x=comparison_df['Xe'],
                y=comparison_df['ƒê·ªãnh m·ª©c'],
                marker_color='lightblue',
                opacity=0.7
            ))
            
            # Th√™m c·ªôt th·ª±c t·∫ø v·ªõi m√†u theo tr·∫°ng th√°i
            colors = comparison_df['Tr·∫°ng th√°i'].map({
                'red': 'red',
                'green': 'green', 
                'orange': 'orange',
                'gray': 'gray'
            })
            
            fig_comparison.add_trace(go.Bar(
                name='Th·ª±c t·∫ø',
                x=comparison_df['Xe'],
                y=comparison_df['Th·ª±c t·∫ø'],
                marker_color=colors
            ))
            
            fig_comparison.update_layout(
                title="So s√°nh ti√™u th·ª• th·ª±c t·∫ø vs ƒë·ªãnh m·ª©c (L/100km)",
                xaxis_title="M√£ xe",
                yaxis_title="L√≠t/100km",
                barmode='group',
                height=400
            )
            
            st.plotly_chart(fig_comparison, use_container_width=True)
        else:
            st.info("Kh√¥ng c√≥ xe n√†o c√≥ ƒë·ªãnh m·ª©c ƒë·ªÉ so s√°nh")
    
    with col2:
        st.markdown("#### üìà Xu h∆∞·ªõng ti√™u th·ª• theo th·ªùi gian")
        
        if 'date' in fuel_data.columns:
            daily_consumption = fuel_data.groupby('date').agg({
                'fuel_liters': 'sum',
                'distance_km': 'sum'
            }).reset_index()
            
            # FIXED: Ch·ªâ t√≠nh cho ng√†y c√≥ c·∫£ fuel v√† distance > 0
            daily_consumption = daily_consumption[
                (daily_consumption['fuel_liters'] > 0) & 
                (daily_consumption['distance_km'] > 0)
            ]
            
            if not daily_consumption.empty:
                daily_consumption['daily_consumption'] = (daily_consumption['fuel_liters'] / daily_consumption['distance_km']) * 100
                daily_consumption = daily_consumption.sort_values('date')
                
                fig_trend = px.line(
                    daily_consumption,
                    x='date',
                    y='daily_consumption',
                    title="Xu h∆∞·ªõng ti√™u th·ª• nhi√™n li·ªáu h√†ng ng√†y",
                    labels={'daily_consumption': 'L/100km', 'date': 'Ng√†y'}
                )
                
                # Th√™m ƒë∆∞·ªùng trung b√¨nh
                avg_line = daily_consumption['daily_consumption'].mean()
                fig_trend.add_hline(y=avg_line, line_dash="dash", line_color="red",
                                   annotation_text=f"TB: {avg_line:.1f}L/100km")
                
                fig_trend.update_layout(height=400)
                st.plotly_chart(fig_trend, use_container_width=True)
            else:
                st.info("Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã xu h∆∞·ªõng")
        else:
            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu th·ªùi gian")
    
    # Distribution analysis
    col3, col4 = st.columns(2)
    
    with col3:
        st.markdown("#### üìä Ph√¢n b·ªë m·ª©c ti√™u th·ª•")
        
        fig_dist = px.histogram(
            fuel_data,
            x='fuel_consumption_per_100km',
            nbins=20,
            title="Ph√¢n b·ªë m·ª©c ti√™u th·ª• nhi√™n li·ªáu",
            labels={'fuel_consumption_per_100km': 'L/100km', 'count': 'S·ªë chuy·∫øn'}
        )
        
        # Th√™m c√°c ƒë∆∞·ªùng th·ªëng k√™
        mean_consumption = fuel_data['fuel_consumption_per_100km'].mean()
        median_consumption = fuel_data['fuel_consumption_per_100km'].median()
        
        fig_dist.add_vline(x=mean_consumption, line_dash="dash", line_color="red",
                          annotation_text=f"TB: {mean_consumption:.1f}")
        fig_dist.add_vline(x=median_consumption, line_dash="dash", line_color="blue",
                          annotation_text=f"Trung v·ªã: {median_consumption:.1f}")
        
        fig_dist.update_layout(height=400)
        st.plotly_chart(fig_dist, use_container_width=True)
    
    with col4:
        st.markdown("#### üéØ Top xe ti√™u th·ª• nhi·ªÅu nh·∫•t")
        
        top_consumers = vehicle_fuel_df.nlargest(10, 'avg_consumption')[['vehicle_id', 'avg_consumption', 'standard', 'status']]
        
        fig_top = px.bar(
            top_consumers,
            x='vehicle_id',
            y='avg_consumption',
            title="Top 10 xe ti√™u th·ª• nhi√™n li·ªáu cao",
            labels={'avg_consumption': 'L/100km', 'vehicle_id': 'M√£ xe'},
            color='avg_consumption',
            color_continuous_scale='Reds'
        )
        fig_top.update_layout(height=400)
        st.plotly_chart(fig_top, use_container_width=True)
    
    # Efficiency analysis
    st.markdown("#### ‚ö° Ph√¢n t√≠ch hi·ªáu qu·∫£ nhi√™n li·ªáu")
    
    col5, col6 = st.columns(2)
    
    with col5:
        st.markdown("**üî¥ Xe c·∫ßn c·∫£i thi·ªán (v∆∞·ª£t ƒë·ªãnh m·ª©c > 2L/100km):**")
        
        problematic_vehicles = vehicle_fuel_df[vehicle_fuel_df['deviation'] > 2].sort_values('deviation', ascending=False)
        
        if not problematic_vehicles.empty:
            for _, vehicle in problematic_vehicles.iterrows():
                st.error(
                    f"üöó **{vehicle['vehicle_id']}**: {vehicle['avg_consumption']:.1f}L/100km "
                    f"(ƒë·ªãnh m·ª©c: {vehicle['standard']}L/100km, v∆∞·ª£t: +{vehicle['deviation']:.1f}L)"
                )
        else:
            st.success("‚úÖ Kh√¥ng c√≥ xe n√†o v∆∞·ª£t ƒë·ªãnh m·ª©c ƒë√°ng k·ªÉ!")
    
    with col6:
        st.markdown("**üü¢ Xe ho·∫°t ƒë·ªông hi·ªáu qu·∫£ (th·∫•p h∆°n ƒë·ªãnh m·ª©c > 1L/100km):**")
        
        efficient_vehicles = vehicle_fuel_df[vehicle_fuel_df['deviation'] < -1].sort_values('deviation')
        
        if not efficient_vehicles.empty:
            for _, vehicle in efficient_vehicles.iterrows():
                st.success(
                    f"üöó **{vehicle['vehicle_id']}**: {vehicle['avg_consumption']:.1f}L/100km "
                    f"(ƒë·ªãnh m·ª©c: {vehicle['standard']}L/100km, ti·∫øt ki·ªám: {abs(vehicle['deviation']):.1f}L)"
                )
        else:
            st.info("‚ÑπÔ∏è Ch∆∞a c√≥ xe n√†o ti·∫øt ki·ªám nhi√™n li·ªáu ƒë√°ng k·ªÉ")
    
    # Detailed fuel table
    st.markdown("#### üìã B·∫£ng chi ti·∫øt ti√™u th·ª• nhi√™n li·ªáu")
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu hi·ªÉn th·ªã
    display_df = vehicle_fuel_df.copy()
    display_df = display_df.sort_values('avg_consumption', ascending=False)
    
    # Format cho hi·ªÉn th·ªã
    display_table = pd.DataFrame({
        'M√£ xe': display_df['vehicle_id'],
        'Ti√™u th·ª• th·ª±c t·∫ø (L/100km)': display_df['avg_consumption'].round(1),
        'ƒê·ªãnh m·ª©c (L/100km)': display_df['standard'],
        'Ch√™nh l·ªách (L/100km)': display_df['deviation'].round(1),
        'Ch√™nh l·ªách (%)': display_df['deviation_percent'].round(1),
        'T·ªïng nhi√™n li·ªáu (L)': display_df['total_fuel'].round(1),
        'T·ªïng qu√£ng ƒë∆∞·ªùng (km)': display_df['total_distance'].round(1),
        'S·ªë chuy·∫øn': display_df['trips_count'],
        'Tr·∫°ng th√°i': display_df['status']
    })
    
    # Hi·ªÉn th·ªã b·∫£ng v·ªõi style
    def highlight_fuel_status(val):
        if 'üî¥' in str(val):
            return 'background-color: #ffebee'
        elif 'üü¢' in str(val):
            return 'background-color: #e8f5e8'
        elif 'üü°' in str(val):
            return 'background-color: #fff8e1'
        return ''
    
    st.dataframe(
        display_table.style.applymap(highlight_fuel_status, subset=['Tr·∫°ng th√°i']),
        use_container_width=True,
        height=400
    )
    
    # Fuel cost estimation (optional)
    st.markdown("#### üí∞ ∆Ø·ªõc t√≠nh chi ph√≠ nhi√™n li·ªáu")
    
    fuel_price = st.number_input(
        "Gi√° nhi√™n li·ªáu (VNƒê/l√≠t):",
        value=25000,
        min_value=20000,
        max_value=35000,
        step=1000,
        help="Nh·∫≠p gi√° nhi√™n li·ªáu hi·ªán t·∫°i"
    )
    
    total_fuel_cost = total_fuel_consumed * fuel_price
    
    col7, col8, col9 = st.columns(3)
    
    with col7:
        st.metric(
            label="üí∞ T·ªïng chi ph√≠ nhi√™n li·ªáu",
            value=f"{total_fuel_cost:,.0f} VNƒê",
            help=f"D·ª±a tr√™n gi√° {fuel_price:,} VNƒê/l√≠t"
        )
    
    with col8:
        # T√≠nh chi ph√≠ n·∫øu t·∫•t c·∫£ xe ƒë·∫°t ƒë·ªãnh m·ª©c
        standard_consumption = 0
        actual_consumption = 0
        
        for _, vehicle in vehicle_fuel_df.iterrows():
            if vehicle['standard'] > 0:
                vehicle_distance = vehicle['total_distance']
                standard_consumption += (vehicle['standard'] / 100) * vehicle_distance
                actual_consumption += (vehicle['avg_consumption'] / 100) * vehicle_distance
        
        if standard_consumption > 0:
            potential_savings = (actual_consumption - standard_consumption) * fuel_price
            st.metric(
                label="üí∏ L√£ng ph√≠ do v∆∞·ª£t ƒë·ªãnh m·ª©c",
                value=f"{potential_savings:,.0f} VNƒê",
                delta=f"{potential_savings/total_fuel_cost*100:.1f}% t·ªïng chi ph√≠" if potential_savings > 0 else "Kh√¥ng c√≥ l√£ng ph√≠",
                help="S·ªë ti·ªÅn c√≥ th·ªÉ ti·∫øt ki·ªám n·∫øu t·∫•t c·∫£ xe ƒë·∫°t ƒë·ªãnh m·ª©c"
            )
    
    with col9:
        avg_cost_per_100km = (total_fuel_cost / fuel_data['distance_km'].sum() * 100) if fuel_data['distance_km'].sum() > 0 else 0
        st.metric(
            label="üìä Chi ph√≠ TB/100km",
            value=f"{avg_cost_per_100km:,.0f} VNƒê",
            help="Chi ph√≠ nhi√™n li·ªáu trung b√¨nh cho 100km"
        )
    
    # Recommendations
    st.markdown("#### üí° Khuy·∫øn ngh·ªã")
    
    recommendations = []
    
    # Xe v∆∞·ª£t ƒë·ªãnh m·ª©c
    if vehicles_over_standard > 0:
        recommendations.append(
            f"üîß **B·∫£o d∆∞·ª°ng kh·∫©n c·∫•p**: {vehicles_over_standard} xe v∆∞·ª£t ƒë·ªãnh m·ª©c c·∫ßn ki·ªÉm tra ƒë·ªông c∆°, h·ªá th·ªëng nhi√™n li·ªáu"
        )
    
    # Xe ti·∫øt ki·ªám
    if vehicles_efficient > 0:
        recommendations.append(
            f"üèÜ **H·ªçc h·ªèi kinh nghi·ªám**: {vehicles_efficient} xe ho·∫°t ƒë·ªông hi·ªáu qu·∫£, √°p d·ª•ng c√°ch v·∫≠n h√†nh cho xe kh√°c"
        )
    
    # Ph√¢n t√≠ch xu h∆∞·ªõng
    if 'date' in fuel_data.columns and len(daily_consumption) > 7:
        recent_trend = daily_consumption.tail(7)['daily_consumption'].mean()
        overall_avg = daily_consumption['daily_consumption'].mean()
        
        if recent_trend > overall_avg * 1.1:
            recommendations.append(
                "üìà **C·∫£nh b√°o xu h∆∞·ªõng**: Ti√™u th·ª• nhi√™n li·ªáu tƒÉng trong 7 ng√†y g·∫ßn ƒë√¢y, c·∫ßn ƒëi·ªÅu tra nguy√™n nh√¢n"
            )
        elif recent_trend < overall_avg * 0.9:
            recommendations.append(
                "üìâ **Xu h∆∞·ªõng t√≠ch c·ª±c**: Ti√™u th·ª• nhi√™n li·ªáu gi·∫£m trong 7 ng√†y g·∫ßn ƒë√¢y, duy tr√¨ th√≥i quen t·ªët"
            )
    
    if not recommendations:
        recommendations.append("‚úÖ **T√¨nh h√¨nh ·ªïn ƒë·ªãnh**: ƒê·ªôi xe ƒëang ho·∫°t ƒë·ªông trong m·ª©c b√¨nh th∆∞·ªùng")
    
    for rec in recommendations:
        st.info(rec)
    
    # FIXED: Debug calculation example
    if st.sidebar.checkbox("üîß Debug - V√≠ d·ª• t√≠nh to√°n", help="Hi·ªÉn th·ªã v√≠ d·ª• t√≠nh to√°n chi ti·∫øt"):
        st.markdown("### üîß Debug - V√≠ d·ª• t√≠nh to√°n chi ti·∫øt")
        
        if not vehicle_fuel_df.empty:
            example_vehicle_data = vehicle_fuel_df.iloc[0]
            vehicle_id = example_vehicle_data['vehicle_id']
            
            st.write(f"**V√≠ d·ª• t√≠nh to√°n cho xe {vehicle_id}:**")
            
            sample_trips = fuel_data[fuel_data['vehicle_id'] == vehicle_id].head(3)
            if not sample_trips.empty:
                calc_demo = sample_trips[['distance_km', 'fuel_liters', 'fuel_consumption_per_100km']].copy()
                calc_demo['T√≠nh to√°n check'] = (calc_demo['fuel_liters'] / calc_demo['distance_km']) * 100
                
                st.dataframe(calc_demo)
                st.write(f"**C√¥ng th·ª©c**: (fuel_liters / distance_km) √ó 100")
                st.write(f"**Trung b√¨nh xe {vehicle_id}**: {example_vehicle_data['avg_consumption']:.2f} L/100km")
                if example_vehicle_data['standard'] > 0:
                    st.write(f"**ƒê·ªãnh m·ª©c**: {example_vehicle_data['standard']} L/100km")
                    st.write(f"**Ch√™nh l·ªách**: {example_vehicle_data['deviation']:.2f} L/100km")
                    st.write(f"**Tr·∫°ng th√°i**: {example_vehicle_data['status']}")
            else:
                st.write("Kh√¥ng c√≥ d·ªØ li·ªáu m·∫´u cho xe n√†y")
                
def create_detailed_analysis_section(df):
    """Create detailed analysis section with tabs"""
    st.markdown("---")
    st.markdown("## üìà Ph√¢n t√≠ch chi ti·∫øt v√† Bi·ªÉu ƒë·ªì tr·ª±c quan")
    
    if df.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch")
        return
    
    # Ensure we have required packages
    try:
        import plotly.express as px
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
    except ImportError:
        st.error("‚ùå C·∫ßn c√†i ƒë·∫∑t plotly: pip install plotly")
        st.info("Ch·∫°y l·ªánh: pip install plotly")
        return
    
    # Create tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üí∞ Doanh thu", 
        "üöó Hi·ªáu su·∫•t xe", 
        "‚ö° Ph√¢n t√≠ch qu√° t·∫£i", 
        "üõ£Ô∏è Ph√¢n t√≠ch qu√£ng ƒë∆∞·ªùng",
        "‚õΩ Ph√¢n t√≠ch nhi√™n li·ªáu"
    ])
    
    with tab1:
        create_revenue_analysis_tab(df)
    
    with tab2:
        create_vehicle_efficiency_tab(df)
    
    with tab3:
        create_overload_analysis_tab(df)
    
    with tab4:
        create_distance_analysis_tab(df)

    with tab5:
        create_fuel_analysis_tab(df)

def create_driver_performance_table(df):
    """Create driver performance table using English columns"""
    st.markdown("## üë®‚Äçüíº Hi·ªáu su·∫•t t√†i x·∫ø")
    
    if df.empty or 'driver_name' not in df.columns:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu t√†i x·∫ø")
        return
    
    # FIXED: Ensure duration is properly parsed
    df = ensure_duration_parsed(df)
    
    # Ensure datetime conversion
    try:
        if 'record_date' in df.columns:
            df['record_date'] = pd.to_datetime(df['record_date'], format='%m/%d/%Y', errors='coerce')
            df['date'] = df['record_date'].dt.date
    except:
        pass
    
    # Ensure numeric columns
    if 'revenue_vnd' in df.columns:
        df['revenue_vnd'] = pd.to_numeric(df['revenue_vnd'], errors='coerce').fillna(0)
    else:
        df['revenue_vnd'] = 0

    # FIXED: Duration is already parsed by ensure_duration_parsed()
    # Remove the redundant parsing that was causing issues
    
    # Calculate metrics per driver
    drivers = df['driver_name'].unique()
    results = []
    
    for driver in drivers:
        driver_data = df[df['driver_name'] == driver]
        
        # Basic metrics
        total_trips = len(driver_data)
        total_revenue = float(driver_data['revenue_vnd'].sum())
        
        # FIXED: Duration calculation - filter out invalid values
        valid_duration_data = driver_data[
            driver_data['Th·ªùi gian'].notna() & 
            (driver_data['Th·ªùi gian'] >= 0) & 
            (driver_data['Th·ªùi gian'] <= 24)
        ]
        total_hours = float(valid_duration_data['Th·ªùi gian'].sum())
        
        # Days calculation
        if 'date' in driver_data.columns:
            active_days = driver_data['date'].nunique()
        else:
            active_days = 30  # Default
        
        # Derived metrics
        trips_per_day = (float(total_trips) / float(active_days)) if active_days > 0 else 0.0
        hours_per_day = (total_hours / float(active_days)) if active_days > 0 else 0.0
        
        results.append({
            'T√™n': driver,
            'S·ªë chuy·∫øn': total_trips,
            'T·ªïng doanh thu': round(total_revenue, 0),
            'T·ªïng gi·ªù l√°i': round(total_hours, 1),
            'S·ªë ng√†y l√†m vi·ªác': active_days,
            'Chuy·∫øn/ng√†y': round(trips_per_day, 1),
            'Gi·ªù l√°i/ng√†y': round(hours_per_day, 1)
        })
    
    # Create DataFrame
    driver_display = pd.DataFrame(results)
    driver_display = driver_display.set_index('T√™n').sort_values('T·ªïng doanh thu', ascending=False)
    
    # Display table
    st.dataframe(
        driver_display.style.format({
            'T·ªïng doanh thu': '{:,.0f}',
            'T·ªïng gi·ªù l√°i': '{:.1f}',
            'Chuy·∫øn/ng√†y': '{:.1f}',
            'Gi·ªù l√°i/ng√†y': '{:.1f}'
        }),
        use_container_width=True,
        height=400
    )

def main():
    """Main dashboard function - Complete version with all features"""
    # HEADER: logo + title on one line (flexbox)
    try:
        # Encode logo to base64 for inline <img>
        script_dir = os.path.dirname(os.path.abspath(__file__))
        logo_base64 = ""
        # Check for logo.png in current directory first, then in ./assets/
        for p in [
            os.path.join(script_dir, "logo.png"),                      # 1Ô∏è‚É£ same-level logo
            os.path.join(script_dir, "assets", "logo.png")            # 2Ô∏è‚É£ assets folder
        ]:
            if os.path.exists(p):
                with open(p, "rb") as f:
                    logo_base64 = base64.b64encode(f.read()).decode()
                break
    except Exception:
        logo_base64 = ""

    # Build logo HTML (fallback emoji if logo not found)
    if logo_base64:
        logo_html = f"<img src='data:image/png;base64,{logo_base64}' style='height:150px; width:auto;' />"
    else:
        logo_html = "<div style='font-size:2.5rem; margin-right:12px;'>üè•</div>"

    header_html = f"""
    <div style='
        width:100%;
        display:flex;
        align-items:center;
        justify-content:center;
        gap:12px;
        padding:30px 0;
        background:#ffffff;
        border-radius:15px;
        margin-bottom:30px;
    '>
        <h1 style='
            color:#1f77b4;
            margin:0;
            font-size:3rem;
            font-weight:bold;
            font-family:"Segoe UI", Arial, sans-serif;
            text-shadow:2px 2px 4px rgba(0,0,0,0.1);
            letter-spacing:1px;
            text-align:center;
        '>Dashboard Qu·∫£n l√Ω Ph∆∞∆°ng ti·ªán v·∫≠n chuy·ªÉn t·∫°i B·ªánh vi·ªán ƒê·∫°i h·ªçc Y D∆∞·ª£c TP. H·ªì Ch√≠ Minh</h1>
    </div>
    """
    st.markdown(header_html, unsafe_allow_html=True)
    
    # Load data first
    with st.spinner("üìä ƒêang t·∫£i d·ªØ li·ªáu t·ª´ GitHub..."):
        df_raw = load_data_from_github()
    
    if df_raw.empty:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu t·ª´ GitHub repository")
        st.info("üí° Click 'Sync d·ªØ li·ªáu m·ªõi' ƒë·ªÉ l·∫•y d·ªØ li·ªáu t·ª´ Google Sheets")
        return
    
    # Sidebar controls
    st.sidebar.markdown("## üîß ƒêi·ªÅu khi·ªÉn Dashboard")
    
    # Show column mapping info
    with st.sidebar.expander("üìã Column Mapping Guide"):
        st.write("**Vietnamese ‚Üí English:**")
        for viet, eng in COLUMN_MAPPING.items():
            if eng is not None:
                st.write(f"‚Ä¢ {viet} ‚Üí `{eng}`")
            else:
                st.write(f"‚Ä¢ ~~{viet}~~ ‚Üí Dropped")
    
    # Sync button
    if st.sidebar.button("üîÑ Sync d·ªØ li·ªáu m·ªõi", type="primary", use_container_width=True):
        success = run_sync_script()
        if success:
            st.cache_data.clear()
            st.rerun()
    
    # Last sync info
    if 'last_sync' in st.session_state:
        st.sidebar.success(f"üïê Sync cu·ªëi: {st.session_state.last_sync.strftime('%H:%M:%S %d/%m/%Y')}")
    
    # Manual refresh button
    if st.sidebar.button("üîÑ L√†m m·ªõi Dashboard", help="Reload d·ªØ li·ªáu t·ª´ GitHub"):
        # Clear date filters when refreshing data
        if 'date_filter_start' in st.session_state:
            del st.session_state.date_filter_start
        if 'date_filter_end' in st.session_state:
            del st.session_state.date_filter_end
        st.cache_data.clear()
        st.rerun()
    
    st.sidebar.markdown("---")
    
    # DATE FILTER - Apply first
    df_filtered, start_date, end_date = create_date_filter_sidebar(df_raw)
    
    st.sidebar.markdown("---")
    
    # VEHICLE & DRIVER FILTERS - Apply second
    df_final = create_vehicle_filter_sidebar(df_filtered)
    
    # Show filtered data stats
    st.sidebar.markdown("### üìä K·∫øt qu·∫£ l·ªçc")
    if not df_final.empty:
        vehicles_count = df_final['vehicle_id'].nunique() if 'vehicle_id' in df_final.columns else 0
        drivers_count = df_final['driver_name'].nunique() if 'driver_name' in df_final.columns else 0
        
        st.sidebar.metric("üìà T·ªïng chuy·∫øn", f"{len(df_final):,}")
        st.sidebar.metric("üöó S·ªë xe", f"{vehicles_count}")
        st.sidebar.metric("üë®‚Äçüíº S·ªë t√†i x·∫ø", f"{drivers_count}")
        
        # Show percentage of total data
        percentage = (len(df_final) / len(df_raw) * 100) if len(df_raw) > 0 else 0
        st.sidebar.info(f"üìä {percentage:.1f}% t·ªïng d·ªØ li·ªáu")
    else:
        st.sidebar.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu sau khi l·ªçc")
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi b·ªô l·ªçc hi·ªán t·∫°i")
        return
    
    # Show available columns after filtering
    with st.sidebar.expander("üìã Mapped Columns"):
        for col in df_final.columns:
            non_null_count = df_final[col].notna().sum()
            st.write(f"‚Ä¢ `{col}`: {non_null_count}/{len(df_final)}")
    
    # Reset filters button
    if st.sidebar.button("üîÑ Reset t·∫•t c·∫£ b·ªô l·ªçc", help="Quay v·ªÅ d·ªØ li·ªáu g·ªëc"):
        # Clear session state for filters
        if 'date_filter_start' in st.session_state:
            del st.session_state.date_filter_start
        if 'date_filter_end' in st.session_state:
            del st.session_state.date_filter_end
        st.sidebar.success("‚úÖ ƒê√£ reset b·ªô l·ªçc ng√†y!")
        st.rerun()
    
    # Dashboard sections with filtered data
    st.markdown(f"## üìä B√°o c√°o t·ª´ {start_date.strftime('%d/%m/%Y')} ƒë·∫øn {end_date.strftime('%d/%m/%Y')}")
    
    create_metrics_overview(df_final)
    
    st.markdown("---")
    
    create_frequency_metrics(df_final)
    
    st.markdown("---")
    
    create_vehicle_performance_table(df_final)
    
    st.markdown("---")
    
    create_driver_performance_table(df_final)
    
    # NEW: Detailed Analysis Section with Tabs
    create_detailed_analysis_section(df_final)
    
    # Debug section for development
    with st.sidebar.expander("üîç Debug Info"):
        st.write("**Sample Filtered Data (first 3 rows):**")
        if not df_final.empty:
            st.dataframe(df_final.head(3))
        
        st.write("**Column Data Types:**")
        for col in df_final.columns:
            st.write(f"‚Ä¢ `{col}`: {df_final[col].dtype}")
        
        st.write("**Filter Summary:**")
        st.write(f"‚Ä¢ Raw data: {len(df_raw):,} records")
        st.write(f"‚Ä¢ After filters: {len(df_final):,} records")
        st.write(f"‚Ä¢ Date range: {start_date} to {end_date}")

if __name__ == "__main__":
    main()
