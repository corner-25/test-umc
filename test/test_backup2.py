import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from datetime import datetime, timedelta

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Dashboard Ph√≤ng H√†nh Ch√≠nh",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
.main-header {
    font-size: 2.5rem;
    font-weight: bold;
    color: #1f77b4;
    text-align: center;
    margin-bottom: 2rem;
}
.metric-container {
    background-color: #f0f2f6;
    padding: 1rem;
    border-radius: 10px;
    border-left: 4px solid #1f77b4;
}
.tab-header {
    font-size: 1.8rem;
    font-weight: bold;
    color: #2c3e50;
    margin-bottom: 1rem;
}
</style>
""", unsafe_allow_html=True)

# Header ch√≠nh
st.markdown('<h1 class="main-header">üè¢ Dashboard Ph√≤ng H√†nh Ch√≠nh</h1>', unsafe_allow_html=True)

# Sidebar - B·ªô l·ªçc to√†n c·ª•c
st.sidebar.markdown("## üîç B·ªô l·ªçc to√†n c·ª•c")

# Kh·ªüi t·∫°o bi·∫øn filter m·∫∑c ƒë·ªãnh
global_date_filter = None
global_dept_filter = None

# Checkbox ƒë·ªÉ b·∫≠t/t·∫Øt filter
enable_global_filter = st.sidebar.checkbox("üéØ B·∫≠t b·ªô l·ªçc to√†n c·ª•c", value=False)

if enable_global_filter:
    # Filter ng√†y
    st.sidebar.markdown("### üìÖ Kho·∫£ng th·ªùi gian")
    
    # S·ª≠ d·ª•ng 2 date_input ri√™ng bi·ªát ƒë·ªÉ tr√°nh l·ªói
    col1, col2 = st.sidebar.columns(2)
    with col1:
        start_date = st.date_input(
            "T·ª´ ng√†y:",
            value=None,
            help="Ch·ªçn ng√†y b·∫Øt ƒë·∫ßu"
        )
    with col2:
        end_date = st.date_input(
            "ƒê·∫øn ng√†y:",
            value=None,
            help="Ch·ªçn ng√†y k·∫øt th√∫c"
        )
    
    # T·∫°o global_date_filter t·ª´ 2 ng√†y
    if start_date is not None and end_date is not None:
        global_date_filter = (start_date, end_date)
    elif start_date is not None:
        global_date_filter = start_date
    else:
        global_date_filter = None
    
    # Filter ph√≤ng ban (ch·ªâ hi·ªán khi c√≥ d·ªØ li·ªáu)
    st.sidebar.markdown("### üè¢ Ph√≤ng ban")
    st.sidebar.info("Filter ph√≤ng ban s·∫Ω xu·∫•t hi·ªán khi upload d·ªØ li·ªáu c√≥ th√¥ng tin ph√≤ng ban")

st.sidebar.markdown("---")

# H√†m ti·ªán √≠ch ƒë·ªÉ √°p d·ª•ng filter to√†n c·ª•c
def apply_global_filter(df, date_col='datetime'):
    """√Åp d·ª•ng b·ªô l·ªçc to√†n c·ª•c cho DataFrame"""
    if not enable_global_filter:
        return df
    
    filtered_df = df.copy()
    
    # √Åp d·ª•ng filter ng√†y
    if global_date_filter is not None:
        # Ki·ªÉm tra n·∫øu l√† tuple/list v·ªõi 2 ph·∫ßn t·ª≠
        if isinstance(global_date_filter, (list, tuple)) and len(global_date_filter) == 2:
            filtered_df = filtered_df[
                (filtered_df[date_col] >= pd.to_datetime(global_date_filter[0])) & 
                (filtered_df[date_col] <= pd.to_datetime(global_date_filter[1]))
            ]
        # N·∫øu ch·ªâ l√† 1 ng√†y, filter t·ª´ ng√†y ƒë√≥ tr·ªü ƒëi
        elif hasattr(global_date_filter, '__iter__') == False:  # single date
            filtered_df = filtered_df[filtered_df[date_col] >= pd.to_datetime(global_date_filter)]
    
    return filtered_df

# H√†m x·ª≠ l√Ω d·ªØ li·ªáu vƒÉn b·∫£n ƒë·∫øn
def process_incoming_documents_data(uploaded_file):
    try:
        if uploaded_file.type == "application/json":
            data = json.load(uploaded_file)
            if isinstance(data, dict) and "data" in data:
                df = pd.DataFrame(data["data"])
            else:
                df = pd.DataFrame(data)
        else:
            df = pd.read_csv(uploaded_file)
        
        # T·∫°o c·ªôt datetime (s·ª≠ d·ª•ng 'date' thay v√¨ 'day')
        df['datetime'] = pd.to_datetime(df[['year', 'month', 'date']].rename(columns={'date': 'day'}))
        df['weekday'] = df['datetime'].dt.day_name()
        df['week'] = df['datetime'].dt.isocalendar().week
        
        # ƒê·∫£m b·∫£o c√°c c·ªôt c·∫ßn thi·∫øt t·ªìn t·∫°i, n·∫øu kh√¥ng th√¨ t·∫°o v·ªõi gi√° tr·ªã 0
        required_columns = ['no_response_required', 'response_required', 
                          'response_required_VanBan', 'response_required_Email', 
                          'response_required_DienThoai', 'response_required_PhanMem']
        
        for col in required_columns:
            if col not in df.columns:
                df[col] = 0
        
        # ƒê·∫£m b·∫£o c·ªôt processed_rate_on_time v√† processed_rate_late t·ªìn t·∫°i
        if 'processed_rate_on_time' not in df.columns:
            df['processed_rate_on_time'] = 0
        if 'processed_rate_late' not in df.columns:
            df['processed_rate_late'] = 0
            
        return df
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {str(e)}")
        return None

# H√†m t·∫°o pivot table
def create_pivot_table(df):
    st.markdown("### üìä B·∫£ng Pivot - Ph√¢n t√≠ch theo th·ªùi gian")

    # CSS cho table l·ªõn h∆°n v√† ƒë·∫πp h∆°n
    st.markdown("""
    <style>
    .pivot-table {
        font-size: 16px !important;
        font-weight: 500;
    }
    .pivot-table td {
        padding: 12px 8px !important;
        text-align: center !important;
    }
    .pivot-table th {
        padding: 15px 8px !important;
        text-align: center !important;
        background-color: #f0f2f6 !important;
        font-weight: bold !important;
        font-size: 17px !important;
    }
    .increase { color: #28a745 !important; font-weight: bold; }
    .decrease { color: #dc3545 !important; font-weight: bold; }
    .neutral { color: #6c757d !important; }
    .new-period { color: #007bff !important; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

    # L·ª±a ch·ªçn m·ª©c ƒë·ªô t·ªïng h·ª£p
    col1, col2 = st.columns([1, 3])
    with col1:
        period_type = st.selectbox(
            "üìÖ T·ªïng h·ª£p theo:",
            options=['Ng√†y', 'Tu·∫ßn', 'Th√°ng', 'Qu√Ω', 'NƒÉm'],
            index=1,  # M·∫∑c ƒë·ªãnh l√† Tu·∫ßn
            key="pivot_period_type"
        )

    # Chu·∫©n b·ªã d·ªØ li·ªáu theo lo·∫°i period
    df_period = df.copy()

    if period_type == 'Tu·∫ßn':
        df_period['period'] = 'W' + df_period['week'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['week']
    elif period_type == 'Th√°ng':
        df_period['period'] = 'T' + df_period['month'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['month']
    elif period_type == 'Qu√Ω':
        df_period['quarter'] = ((df_period['month'] - 1) // 3) + 1
        df_period['period'] = 'Q' + df_period['quarter'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['quarter']
    elif period_type == 'NƒÉm':
        df_period['period'] = df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year']
    else:  # Ng√†y
        df_period['period'] = df_period['datetime'].dt.strftime('%d/%m/%Y')
        df_period['period_sort'] = df_period['datetime']

    # T·∫°o pivot table v·ªõi c√°c ch·ªâ s·ªë m·ªõi
    pivot_columns = ['total_incoming', 'no_response_required', 'response_required',
                    'processed_on_time', 'processed_late', 'response_required_VanBan',
                    'response_required_Email', 'response_required_DienThoai', 'response_required_PhanMem']

    # Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng
    available_columns = [col for col in pivot_columns if col in df_period.columns]

    pivot_data = df_period.groupby(['period', 'period_sort'])[available_columns].sum().reset_index()
    pivot_data = pivot_data.sort_values('period_sort')

    # T√≠nh to√°n bi·∫øn ƒë·ªông so v·ªõi k·ª≥ tr∆∞·ªõc
    for col in available_columns:
        pivot_data[f'{col}_prev'] = pivot_data[col].shift(1)
        pivot_data[f'{col}_change'] = pivot_data[col] - pivot_data[f'{col}_prev']
        pivot_data[f'{col}_change_pct'] = ((pivot_data[col] / pivot_data[f'{col}_prev'] - 1) * 100).round(1)
        pivot_data[f'{col}_change_pct'] = pivot_data[f'{col}_change_pct'].fillna(0)

    # T√≠nh t·ª∑ l·ªá x·ª≠ l√Ω ƒë√∫ng h·∫°n
    if 'total_incoming' in available_columns and 'processed_on_time' in available_columns:
        pivot_data['on_time_rate'] = (pivot_data['processed_on_time'] / pivot_data['total_incoming'] * 100).round(1)
        pivot_data['on_time_rate'] = pivot_data['on_time_rate'].fillna(0)

    # T·∫°o DataFrame hi·ªÉn th·ªã v·ªõi bi·∫øn ƒë·ªông trong c√πng cell
    display_data = pivot_data.copy()

    # H√†m t·∫°o cell k·∫øt h·ª£p gi√° tr·ªã v√† bi·∫øn ƒë·ªông
    def format_cell_with_change(row, col):
        current_val = row[col]
        change_val = row[f'{col}_change']
        change_pct = row[f'{col}_change_pct']
        prev_val = row[f'{col}_prev']

        # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu k·ª≥ tr∆∞·ªõc, ch·ªâ hi·ªÉn th·ªã gi√° tr·ªã hi·ªán t·∫°i
        if pd.isna(prev_val) or prev_val == 0:
            return f"{int(current_val)}"

        # ƒê·ªãnh m√†u s·∫Øc theo chi·ªÅu h∆∞·ªõng thay ƒë·ªïi
        if change_val > 0:
            color_class = "increase"
            arrow = "‚Üó"
            sign = "+"
        elif change_val < 0:
            color_class = "decrease"
            arrow = "‚Üò"
            sign = ""
        else:
            color_class = "neutral"
            arrow = "‚Üí"
            sign = ""

        # Tr·∫£ v·ªÅ HTML v·ªõi m√†u s·∫Øc
        return f"""<div style="text-align: center; line-height: 1.2;">
            <div style="font-size: 16px; font-weight: 600;">{int(current_val)}</div>
            <div class="{color_class}" style="font-size: 12px; margin-top: 2px;">
                {arrow} {sign}{int(change_val)} ({change_pct:+.1f}%)
            </div>
        </div>"""

    # T·∫°o c·ªôt hi·ªÉn th·ªã m·ªõi
    display_columns = ['period']
    column_names = {f'period': f'{period_type}'}

    for col in available_columns:
        new_col = f'{col}_display'
        display_data[new_col] = display_data.apply(lambda row: format_cell_with_change(row, col), axis=1)
        display_columns.append(new_col)

        # Mapping t√™n c·ªôt
        if col == 'total_incoming':
            column_names[new_col] = 'T·ªïng VB ƒë·∫øn'
        elif col == 'no_response_required':
            column_names[new_col] = 'Kh√¥ng y√™u c·∫ßu ph·∫£n h·ªìi'
        elif col == 'response_required':
            column_names[new_col] = 'Y√™u c·∫ßu ph·∫£n h·ªìi'
        elif col == 'processed_on_time':
            column_names[new_col] = 'X·ª≠ l√Ω ƒë√∫ng h·∫°n'
        elif col == 'processed_late':
            column_names[new_col] = 'X·ª≠ l√Ω tr·ªÖ h·∫°n'
        elif col == 'response_required_VanBan':
            column_names[new_col] = 'PH - VƒÉn b·∫£n'
        elif col == 'response_required_Email':
            column_names[new_col] = 'PH - Email'
        elif col == 'response_required_DienThoai':
            column_names[new_col] = 'PH - ƒêi·ªán tho·∫°i'
        elif col == 'response_required_PhanMem':
            column_names[new_col] = 'PH - Ph·∫ßn m·ªÅm'

    # B·ªè t·ª∑ l·ªá ƒë√∫ng h·∫°n theo y√™u c·∫ßu

    st.markdown(f"#### üìã T·ªïng h·ª£p theo {period_type} (bao g·ªìm bi·∫øn ƒë·ªông)")

    # Hi·ªÉn th·ªã b·∫£ng v·ªõi HTML ƒë·ªÉ render m√†u s·∫Øc
    df_display = display_data[display_columns].rename(columns=column_names)

    # T·∫°o HTML table v·ªõi sticky header
    html_table = "<div style='max-height: 400px; overflow-y: auto; border: 1px solid #ddd;'><table class='pivot-table' style='width: 100%; border-collapse: collapse; font-size: 16px;'>"

    # Header v·ªõi sticky positioning
    html_table += "<thead><tr>"
    for col in df_display.columns:
        html_table += f"<th style='position: sticky; top: 0; padding: 15px 8px; text-align: center; background-color: #f0f2f6; font-weight: bold; font-size: 17px; border: 1px solid #ddd; z-index: 10;'>{col}</th>"
    html_table += "</tr></thead>"

    # Body
    html_table += "<tbody>"
    for _, row in df_display.iterrows():
        html_table += "<tr>"
        for i, col in enumerate(df_display.columns):
            cell_value = row[col]
            style = "padding: 12px 8px; text-align: center; border: 1px solid #ddd; vertical-align: middle;"
            if i == 0:  # Period column
                style += " font-weight: 600; background-color: #f8f9fa;"
            html_table += f"<td style='{style}'>{cell_value}</td>"
        html_table += "</tr>"
    html_table += "</tbody></table></div>"

    st.markdown(html_table, unsafe_allow_html=True)

    return period_type


# H√†m x·ª≠ l√Ω d·ªØ li·ªáu vƒÉn b·∫£n ƒëi
def process_outgoing_documents_data(uploaded_file):
    try:
        if uploaded_file.type == "application/json":
            data = json.load(uploaded_file)
            if isinstance(data, dict) and "data" in data:
                df = pd.DataFrame(data["data"])
            else:
                df = pd.DataFrame(data)
        else:
            df = pd.read_csv(uploaded_file)
        
        # T·∫°o c·ªôt datetime
        df['datetime'] = pd.to_datetime(df[['year', 'month', 'date']].rename(columns={'date': 'day'}))
        df['weekday'] = df['datetime'].dt.day_name()
        df['week'] = df['datetime'].dt.isocalendar().week
        
        # X·ª≠ l√Ω c√°c c·ªôt nested (contracts, decisions, etc.)
        def extract_total(col_data):
            if pd.isna(col_data):
                return 0
            if isinstance(col_data, dict):
                return col_data.get('total', 0)
            if isinstance(col_data, str):
                try:
                    parsed = json.loads(col_data)
                    return parsed.get('total', 0)
                except:
                    return 0
            return 0
        
        # H√†m tr√≠ch xu·∫•t chi ti·∫øt t·ª´ nested data
        def extract_detail(col_data):
            if pd.isna(col_data):
                return []
            if isinstance(col_data, dict) and 'detail' in col_data:
                return col_data.get('detail', [])
            if isinstance(col_data, str):
                try:
                    parsed = json.loads(col_data)
                    return parsed.get('detail', [])
                except:
                    return []
            return []
        
        # T·∫°o c√°c c·ªôt t·ªïng h·ª£p
        category_columns = ['contracts', 'decisions', 'regulations', 'rules', 'procedures', 'instruct']
        for col in category_columns:
            if col in df.columns:
                df[f'{col}_total'] = df[col].apply(extract_total)
                df[f'{col}_detail'] = df[col].apply(extract_detail)
            else:
                df[f'{col}_total'] = 0
                df[f'{col}_detail'] = []
        
        # ƒê·∫£m b·∫£o c·ªôt documents t·ªìn t·∫°i
        if 'documents' not in df.columns:
            df['documents'] = 0
            
        # T·ªïng vƒÉn b·∫£n ƒëi = documents + t·∫•t c·∫£ c√°c lo·∫°i kh√°c
        df['total_outgoing'] = (
            df['documents'] +
            df.get('contracts_total', 0) + 
            df.get('decisions_total', 0) + 
            df.get('regulations_total', 0) + 
            df.get('rules_total', 0) + 
            df.get('procedures_total', 0) + 
            df.get('instruct_total', 0)
        )
            
        return df
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu vƒÉn b·∫£n ƒëi: {str(e)}")
        return None

# H√†m t·∫°o pivot table cho vƒÉn b·∫£n ƒëi
def create_outgoing_pivot_table(df):
    st.markdown("### üìä B·∫£ng Pivot - Ph√¢n t√≠ch vƒÉn b·∫£n ƒëi theo th·ªùi gian")
    
    # L·ª±a ch·ªçn m·ª©c ƒë·ªô t·ªïng h·ª£p
    col1, col2 = st.columns([1, 3])
    with col1:
        period_type = st.selectbox(
            "üìÖ T·ªïng h·ª£p theo:",
            options=['Ng√†y', 'Tu·∫ßn', 'Th√°ng', 'Qu√Ω', 'NƒÉm'],
            index=1,  # M·∫∑c ƒë·ªãnh l√† Tu·∫ßn
            key="outgoing_period"
        )
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu theo lo·∫°i period
    df_period = df.copy()
    
    if period_type == 'Tu·∫ßn':
        df_period['period'] = 'W' + df_period['week'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['week']
    elif period_type == 'Th√°ng':
        df_period['period'] = 'T' + df_period['month'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['month']
    elif period_type == 'Qu√Ω':
        df_period['quarter'] = ((df_period['month'] - 1) // 3) + 1
        df_period['period'] = 'Q' + df_period['quarter'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['quarter']
    elif period_type == 'NƒÉm':
        df_period['period'] = df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year']
    else:  # Ng√†y
        df_period['period'] = df_period['datetime'].dt.strftime('%d/%m/%Y')
        df_period['period_sort'] = df_period['datetime']
    
    # T·∫°o pivot table v·ªõi c√°c ch·ªâ s·ªë vƒÉn b·∫£n ƒëi
    pivot_columns = ['total_outgoing', 'documents', 'contracts_total', 'decisions_total', 'regulations_total', 
                    'rules_total', 'procedures_total', 'instruct_total']
    
    # Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng
    available_columns = [col for col in pivot_columns if col in df_period.columns]
    
    pivot_data = df_period.groupby(['period', 'period_sort'])[available_columns].sum().reset_index()
    pivot_data = pivot_data.sort_values('period_sort')
    
    # T√≠nh to√°n bi·∫øn ƒë·ªông so v·ªõi k·ª≥ tr∆∞·ªõc
    for col in available_columns:
        pivot_data[f'{col}_prev'] = pivot_data[col].shift(1)
        pivot_data[f'{col}_change'] = pivot_data[col] - pivot_data[f'{col}_prev']
        pivot_data[f'{col}_change_pct'] = ((pivot_data[col] / pivot_data[f'{col}_prev'] - 1) * 100).round(1)
        pivot_data[f'{col}_change_pct'] = pivot_data[f'{col}_change_pct'].fillna(0)
    
    # Hi·ªÉn th·ªã b·∫£ng ch√≠nh
    display_columns = ['period'] + available_columns
    
    st.markdown(f"#### üìã T·ªïng h·ª£p theo {period_type}")
    st.dataframe(
        pivot_data[display_columns].rename(columns={
            'period': f'{period_type}',
            'total_outgoing': 'T·ªïng vƒÉn b·∫£n ƒëi',
            'documents': 'VƒÉn b·∫£n ph√°t h√†nh',
            'contracts_total': 'H·ª£p ƒë·ªìng',
            'decisions_total': 'Quy·∫øt ƒë·ªãnh', 
            'regulations_total': 'Quy ch·∫ø',
            'rules_total': 'Quy ƒë·ªãnh',
            'procedures_total': 'Th·ªß t·ª•c',
            'instruct_total': 'H∆∞·ªõng d·∫´n'
        }),
        use_container_width=True
    )
    
    # Hi·ªÉn th·ªã b·∫£ng bi·∫øn ƒë·ªông
    st.markdown(f"#### üìà Bi·∫øn ƒë·ªông so v·ªõi {period_type.lower()} tr∆∞·ªõc")
    
    # Format hi·ªÉn th·ªã cho c√°c c·ªôt bi·∫øn ƒë·ªông
    change_data = pivot_data[['period']].copy()
    for col in available_columns:
        change_col = f'{col}_change'
        pct_col = f'{col}_change_pct'
        prev_col = f'{col}_prev'
        
        if change_col in pivot_data.columns and pct_col in pivot_data.columns:
            change_data[f'{col}_combined'] = pivot_data.apply(
                lambda row: f"{int(row[change_col]):+} ({row[pct_col]:+.1f}%)" 
                if pd.notna(row[change_col]) and pd.notna(row[prev_col]) and row[prev_col] != 0 else "M·ªõi", axis=1
            )
    
    # T·∫°o b·∫£ng hi·ªÉn th·ªã cu·ªëi c√πng
    final_change_columns = ['period'] + [f'{col}_combined' for col in available_columns if f'{col}_combined' in change_data.columns]
    final_rename = {'period': f'{period_type}'}
    for col in available_columns:
        if f'{col}_combined' in change_data.columns:
            col_name = {
                'total_outgoing': 'T·ªïng vƒÉn b·∫£n ƒëi',
                'documents': 'VƒÉn b·∫£n ph√°t h√†nh',
                'contracts_total': 'H·ª£p ƒë·ªìng',
                'decisions_total': 'Quy·∫øt ƒë·ªãnh',
                'regulations_total': 'Quy ch·∫ø', 
                'rules_total': 'Quy ƒë·ªãnh',
                'procedures_total': 'Th·ªß t·ª•c',
                'instruct_total': 'H∆∞·ªõng d·∫´n'
            }.get(col, col)
            final_rename[f'{col}_combined'] = f'{col_name} (¬±%)'
    
    if len(final_change_columns) > 1:
        st.dataframe(
            change_data[final_change_columns].rename(columns=final_rename),
            use_container_width=True
        )
    
    # Th·ªëng k√™ t√≥m t·∫Øt
    if len(pivot_data) > 0:
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            total_outgoing = pivot_data['total_outgoing'].sum() if 'total_outgoing' in pivot_data.columns else 0
            st.metric("üìÑ T·ªïng vƒÉn b·∫£n ƒëi", f"{total_outgoing:,.0f}")
        with col2:
            total_docs = pivot_data['documents'].sum() if 'documents' in pivot_data.columns else 0
            st.metric("üìù VƒÉn b·∫£n ph√°t h√†nh", f"{total_docs:,.0f}")
        with col3:
            total_contracts = pivot_data['contracts_total'].sum() if 'contracts_total' in pivot_data.columns else 0
            st.metric("üìÅ H·ª£p ƒë·ªìng", f"{total_contracts:,.0f}")
        with col4:
            total_decisions = pivot_data['decisions_total'].sum() if 'decisions_total' in pivot_data.columns else 0
            st.metric("‚öñÔ∏è Quy·∫øt ƒë·ªãnh", f"{total_decisions:,.0f}")
        with col5:
            other_docs = (pivot_data[['regulations_total', 'rules_total', 'procedures_total', 'instruct_total']].sum().sum() 
                         if all(col in pivot_data.columns for col in ['regulations_total', 'rules_total', 'procedures_total', 'instruct_total']) else 0)
            st.metric("üìã Kh√°c", f"{other_docs:,.0f}")

# H√†m t·∫°o bi·ªÉu ƒë·ªì cho vƒÉn b·∫£n ƒëi
def create_outgoing_docs_charts(df):
    # H√†ng 1: Bi·ªÉu ƒë·ªì t·ªïng quan
    col1, col2 = st.columns(2)
    
    with col1:
        # Bi·ªÉu ƒë·ªì so s√°nh t·ªïng vƒÉn b·∫£n ƒëi vs vƒÉn b·∫£n ph√°t h√†nh
        if 'total_outgoing' in df.columns:
            fig_compare = go.Figure()
            fig_compare.add_trace(go.Scatter(x=df['datetime'], y=df['total_outgoing'],
                                           mode='lines+markers', name='T·ªïng vƒÉn b·∫£n ƒëi',
                                           line=dict(color='blue', width=3)))
            fig_compare.add_trace(go.Scatter(x=df['datetime'], y=df['documents'],
                                           mode='lines+markers', name='VƒÉn b·∫£n ph√°t h√†nh',
                                           line=dict(color='orange', width=3)))
            fig_compare.update_layout(title='üìà So s√°nh t·ªïng vƒÉn b·∫£n ƒëi vs ph√°t h√†nh',
                                    xaxis_title="Ng√†y", yaxis_title="S·ªë l∆∞·ª£ng")
            st.plotly_chart(fig_compare, use_container_width=True)
        else:
            # Fallback n·∫øu ch∆∞a c√≥ total_outgoing
            fig_daily = px.line(df, x='datetime', y='documents', 
                               title='üìà S·ªë l∆∞·ª£ng vƒÉn b·∫£n ph√°t h√†nh theo ng√†y',
                               markers=True)
            fig_daily.update_layout(xaxis_title="Ng√†y", yaxis_title="S·ªë l∆∞·ª£ng vƒÉn b·∫£n")
            fig_daily.update_traces(line_color='#1f77b4', line_width=3)
            st.plotly_chart(fig_daily, use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì ph√¢n b·ªë theo lo·∫°i vƒÉn b·∫£n
        categories = ['contracts_total', 'decisions_total', 'regulations_total', 
                     'rules_total', 'procedures_total', 'instruct_total']
        category_names = ['H·ª£p ƒë·ªìng', 'Quy·∫øt ƒë·ªãnh', 'Quy ch·∫ø', 'Quy ƒë·ªãnh', 'Th·ªß t·ª•c', 'H∆∞·ªõng d·∫´n']
        
        category_sums = []
        available_names = []
        for i, cat in enumerate(categories):
            if cat in df.columns:
                total = df[cat].sum()
                if total > 0:
                    category_sums.append(total)
                    available_names.append(category_names[i])
        
        if category_sums:
            fig_pie = px.pie(values=category_sums, names=available_names,
                           title='üìä Ph√¢n b·ªë theo lo·∫°i vƒÉn b·∫£n')
            st.plotly_chart(fig_pie, use_container_width=True)
    
    with col2:
        # Bi·ªÉu ƒë·ªì xu h∆∞·ªõng c√°c lo·∫°i vƒÉn b·∫£n ch√≠nh
        fig_trend = go.Figure()
        
        if 'contracts_total' in df.columns:
            fig_trend.add_trace(go.Scatter(x=df['datetime'], y=df['contracts_total'],
                                         mode='lines+markers', name='H·ª£p ƒë·ªìng',
                                         line=dict(color='blue')))
        
        if 'decisions_total' in df.columns:
            fig_trend.add_trace(go.Scatter(x=df['datetime'], y=df['decisions_total'],
                                         mode='lines+markers', name='Quy·∫øt ƒë·ªãnh',
                                         line=dict(color='red')))
        
        if 'regulations_total' in df.columns:
            fig_trend.add_trace(go.Scatter(x=df['datetime'], y=df['regulations_total'],
                                         mode='lines+markers', name='Quy ch·∫ø',
                                         line=dict(color='green')))
        
        fig_trend.update_layout(title='üìà Xu h∆∞·ªõng c√°c lo·∫°i vƒÉn b·∫£n ch√≠nh',
                              xaxis_title="Ng√†y", yaxis_title="S·ªë l∆∞·ª£ng")
        st.plotly_chart(fig_trend, use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì theo tu·∫ßn
        if 'week' in df.columns:
            weekly_data = df.groupby('week')['documents'].sum()
            fig_weekly = px.bar(x=weekly_data.index, y=weekly_data.values,
                               title='üìÖ S·ªë l∆∞·ª£ng vƒÉn b·∫£n theo tu·∫ßn')
            fig_weekly.update_layout(xaxis_title="Tu·∫ßn", yaxis_title="S·ªë l∆∞·ª£ng vƒÉn b·∫£n")
            st.plotly_chart(fig_weekly, use_container_width=True)
    
    # H√†ng 2: Bi·ªÉu ƒë·ªì chi ti·∫øt h·ª£p ƒë·ªìng v√† ngu·ªìn g·ªëc
    st.markdown("#### üìÅ Ph√¢n t√≠ch chi ti·∫øt c√°c lo·∫°i h·ª£p ƒë·ªìng")
    
    # T·ªïng h·ª£p t·∫•t c·∫£ lo·∫°i h·ª£p ƒë·ªìng t·ª´ to√†n b·ªô d·ªØ li·ªáu
    contract_types = {}
    decision_types = {}
    
    for _, row in df.iterrows():
        # X·ª≠ l√Ω h·ª£p ƒë·ªìng
        if 'contracts_detail' in df.columns and isinstance(row['contracts_detail'], list):
            for contract in row['contracts_detail']:
                if isinstance(contract, dict) and 'name' in contract and 'count' in contract:
                    contract_name = contract['name']
                    contract_count = contract['count']
                    if contract_name in contract_types:
                        contract_types[contract_name] += contract_count
                    else:
                        contract_types[contract_name] = contract_count
        
        # X·ª≠ l√Ω quy·∫øt ƒë·ªãnh
        if 'decisions_detail' in df.columns and isinstance(row['decisions_detail'], list):
            for decision in row['decisions_detail']:
                if isinstance(decision, dict) and 'name' in decision and 'count' in decision:
                    decision_name = decision['name']
                    decision_count = decision['count']
                    if decision_name in decision_types:
                        decision_types[decision_name] += decision_count
                    else:
                        decision_types[decision_name] = decision_count
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Bi·ªÉu ƒë·ªì ph√¢n lo·∫°i h·ª£p ƒë·ªìng
        if contract_types:
            contract_names = list(contract_types.keys())
            contract_counts = list(contract_types.values())
            
            fig_contract_types = px.pie(values=contract_counts, names=contract_names,
                                      title='üìÑ Ph√¢n lo·∫°i h·ª£p ƒë·ªìng theo lo·∫°i',
                                      hole=0.3)
            st.plotly_chart(fig_contract_types, use_container_width=True)
            
            # B·∫£ng chi ti·∫øt
            st.markdown("**üìã Chi ti·∫øt c√°c lo·∫°i h·ª£p ƒë·ªìng:**")
            contract_df = pd.DataFrame(list(contract_types.items()), 
                                     columns=['Lo·∫°i h·ª£p ƒë·ªìng', 'S·ªë l∆∞·ª£ng'])
            contract_df = contract_df.sort_values('S·ªë l∆∞·ª£ng', ascending=False)
            st.dataframe(contract_df, use_container_width=True)
        else:
            st.info("üìÑ Kh√¥ng c√≥ d·ªØ li·ªáu chi ti·∫øt h·ª£p ƒë·ªìng")
    
    with col2:
        # Bi·ªÉu ƒë·ªì ph√¢n lo·∫°i quy·∫øt ƒë·ªãnh
        if decision_types:
            decision_names = list(decision_types.keys())
            decision_counts = list(decision_types.values())
            
            fig_decision_types = px.bar(x=decision_names, y=decision_counts,
                                      title='‚öñÔ∏è Ph√¢n lo·∫°i quy·∫øt ƒë·ªãnh theo lo·∫°i')
            fig_decision_types.update_layout(xaxis_title="Lo·∫°i quy·∫øt ƒë·ªãnh", 
                                           yaxis_title="S·ªë l∆∞·ª£ng",
                                           xaxis_tickangle=-45)
            st.plotly_chart(fig_decision_types, use_container_width=True)
            
            # B·∫£ng chi ti·∫øt
            st.markdown("**‚öñÔ∏è Chi ti·∫øt c√°c lo·∫°i quy·∫øt ƒë·ªãnh:**")
            decision_df = pd.DataFrame(list(decision_types.items()), 
                                     columns=['Lo·∫°i quy·∫øt ƒë·ªãnh', 'S·ªë l∆∞·ª£ng'])
            decision_df = decision_df.sort_values('S·ªë l∆∞·ª£ng', ascending=False)
            st.dataframe(decision_df, use_container_width=True)
        else:
            st.info("‚öñÔ∏è Kh√¥ng c√≥ d·ªØ li·ªáu chi ti·∫øt quy·∫øt ƒë·ªãnh")

# H√†m x·ª≠ l√Ω d·ªØ li·ªáu qu·∫£n l√Ω c√¥ng vi·ªác
def process_task_management_data(uploaded_file):
    try:
        if uploaded_file.type == "application/json":
            data = json.load(uploaded_file)
            if isinstance(data, dict) and "data" in data:
                data_list = data["data"]
            else:
                data_list = data
        else:
            df_temp = pd.read_csv(uploaded_file)
            data_list = df_temp.to_dict('records')
        
        # T·∫°o DataFrame t·ª´ all_departments
        all_dept_records = []
        dept_detail_records = []
        
        for record in data_list:
            # X·ª≠ l√Ω Date -> date ƒë·ªÉ consistent v·ªõi c√°c tab kh√°c
            if 'Date' in record:
                record['date'] = record['Date']
            if 'Month' in record:
                record['month'] = record['Month'] 
            if 'Year' in record:
                record['year'] = record['Year']
            
            # T·∫°o record cho t·ªïng h·ª£p all_departments
            all_dept_data = record.get('all_departments', {})
            all_dept_record = {
                'date': record.get('date', record.get('Date', 1)),
                'month': record.get('month', record.get('Month', 1)),
                'year': record.get('year', record.get('Year', 2025)),
                'department': 'T·∫•t c·∫£ ph√≤ng ban',
                'tasks_assigned': all_dept_data.get('tasks_assigned', 0),
                'tasks_completed_on_time': all_dept_data.get('tasks_completed_on_time', 0),
                'tasks_completed_on_time_rate': all_dept_data.get('tasks_completed_on_time_rate', 0),
                'tasks_new': all_dept_data.get('tasks_new', 0),
                'tasks_new_rate': all_dept_data.get('tasks_new_rate', 0),
                'tasks_processing': all_dept_data.get('tasks_processing', 0),
                'tasks_processing_rate': all_dept_data.get('tasks_processing_rate', 0)
            }
            all_dept_records.append(all_dept_record)
            
            # T·∫°o records cho t·ª´ng ph√≤ng ban
            detail_depts = record.get('detail_departments', [])
            for dept in detail_depts:
                dept_record = {
                    'date': record.get('date', record.get('Date', 1)),
                    'month': record.get('month', record.get('Month', 1)),
                    'year': record.get('year', record.get('Year', 2025)),
                    'department': dept.get('Name', 'Kh√¥ng x√°c ƒë·ªãnh'),
                    'tasks_assigned': dept.get('tasks_assigned', 0),
                    'tasks_completed_on_time': dept.get('tasks_completed_on_time', 0),
                    'tasks_completed_on_time_rate': dept.get('tasks_completed_on_time_rate', 0),
                    'tasks_new': dept.get('tasks_new', 0),
                    'tasks_new_rate': dept.get('tasks_new_rate', 0),
                    'tasks_processing': dept.get('tasks_processing', 0),
                    'tasks_processing_rate': dept.get('tasks_processing_rate', 0)
                }
                dept_detail_records.append(dept_record)
        
        # T·∫°o DataFrame t·ªïng h·ª£p
        df_all = pd.DataFrame(all_dept_records)
        df_detail = pd.DataFrame(dept_detail_records)
        
        # T·∫°o datetime v√† week
        for df in [df_all, df_detail]:
            df['datetime'] = pd.to_datetime(df[['year', 'month', 'date']].rename(columns={'date': 'day'}))
            df['weekday'] = df['datetime'].dt.day_name()
            df['week'] = df['datetime'].dt.isocalendar().week
            
            # T√≠nh c√°c ch·ªâ s·ªë ph·ª•
            df['completion_rate'] = (df['tasks_completed_on_time'] / df['tasks_assigned'] * 100).fillna(0)
            df['processing_rate'] = (df['tasks_processing'] / df['tasks_assigned'] * 100).fillna(0)
            df['new_rate'] = (df['tasks_new'] / df['tasks_assigned'] * 100).fillna(0)
        
        return df_all, df_detail
        
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu qu·∫£n l√Ω c√¥ng vi·ªác: {str(e)}")
        return None, None

# H√†m x·ª≠ l√Ω d·ªØ li·ªáu l·ªãch h·ªçp
def process_meeting_data(uploaded_file):
    try:
        if uploaded_file.type == "application/json":
            data = json.load(uploaded_file)
            if isinstance(data, dict) and "data" in data:
                df = pd.DataFrame(data["data"])
            else:
                df = pd.DataFrame(data)
        else:
            df = pd.read_csv(uploaded_file)
        
        # Chu·∫©n h√≥a t√™n c·ªôt
        if 'Date' in df.columns:
            df['date'] = df['Date']
        if 'Month' in df.columns:
            df['month'] = df['Month']
        if 'Year' in df.columns:
            df['year'] = df['Year']
            
        # T·∫°o c·ªôt datetime
        df['datetime'] = pd.to_datetime(df[['year', 'month', 'date']].rename(columns={'date': 'day'}))
        df['weekday'] = df['datetime'].dt.day_name()
        df['weekday_vi'] = df['weekday'].map({
            'Monday': 'Th·ª© 2', 'Tuesday': 'Th·ª© 3', 'Wednesday': 'Th·ª© 4',
            'Thursday': 'Th·ª© 5', 'Friday': 'Th·ª© 6', 'Saturday': 'Th·ª© 7', 'Sunday': 'Ch·ªß nh·∫≠t'
        })
        df['week'] = df['datetime'].dt.isocalendar().week
        
        # ƒê·∫£m b·∫£o c·ªôt meeting_schedules t·ªìn t·∫°i
        if 'meeting_schedules' not in df.columns:
            df['meeting_schedules'] = 0
            
        # Ph√¢n lo·∫°i m·ª©c ƒë·ªô b·∫≠n r·ªôn
        df['meeting_level'] = df['meeting_schedules'].apply(lambda x: 
            'R·∫•t √≠t' if x <= 2 else
            '√çt' if x <= 5 else
            'Trung b√¨nh' if x <= 10 else
            'Nhi·ªÅu' if x <= 20 else
            'R·∫•t nhi·ªÅu'
        )
        
        # T√≠nh s·ªë ng√†y l√†m vi·ªác/cu·ªëi tu·∫ßn
        df['is_weekend'] = df['weekday'].isin(['Saturday', 'Sunday'])
        df['day_type'] = df['is_weekend'].map({False: 'Ng√†y l√†m vi·ªác', True: 'Cu·ªëi tu·∫ßn'})
        
        return df
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu l·ªãch h·ªçp: {str(e)}")
        return None

# H√†m t·∫°o pivot table cho qu·∫£n l√Ω c√¥ng vi·ªác
def create_task_pivot_table(df_all, df_detail):
    st.markdown("### üìä B·∫£ng Pivot - Ph√¢n t√≠ch c√¥ng vi·ªác theo th·ªùi gian")
    
    # L·ª±a ch·ªçn m·ª©c ƒë·ªô t·ªïng h·ª£p v√† lo·∫°i d·ªØ li·ªáu
    col1, col2 = st.columns(2)
    with col1:
        period_type = st.selectbox(
            "üìÖ T·ªïng h·ª£p theo:",
            options=['Ng√†y', 'Tu·∫ßn', 'Th√°ng', 'Qu√Ω', 'NƒÉm'],
            index=1,  # M·∫∑c ƒë·ªãnh l√† Tu·∫ßn
            key="task_period"
        )
    
    with col2:
        data_type = st.selectbox(
            "üìã D·ªØ li·ªáu:",
            options=['T·ªïng h·ª£p', 'Chi ti·∫øt ph√≤ng ban'],
            index=0,
            key="task_data_type"
        )
    
    # Ch·ªçn DataFrame ph√π h·ª£p
    df = df_all if data_type == 'T·ªïng h·ª£p' else df_detail
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu theo lo·∫°i period
    df_period = df.copy()
    
    if period_type == 'Tu·∫ßn':
        df_period['period'] = 'W' + df_period['week'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['week']
    elif period_type == 'Th√°ng':
        df_period['period'] = 'T' + df_period['month'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['month']
    elif period_type == 'Qu√Ω':
        df_period['quarter'] = ((df_period['month'] - 1) // 3) + 1
        df_period['period'] = 'Q' + df_period['quarter'].astype(str) + '-' + df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year'] * 100 + df_period['quarter']
    elif period_type == 'NƒÉm':
        df_period['period'] = df_period['year'].astype(str)
        df_period['period_sort'] = df_period['year']
    else:  # Ng√†y
        df_period['period'] = df_period['datetime'].dt.strftime('%d/%m/%Y')
        df_period['period_sort'] = df_period['datetime']
    
    # Groupby columns
    group_cols = ['period', 'period_sort']
    if data_type == 'Chi ti·∫øt ph√≤ng ban':
        group_cols.append('department')
    
    # T·∫°o pivot table
    pivot_columns = ['tasks_assigned', 'tasks_completed_on_time', 'tasks_new', 'tasks_processing']
    
    pivot_data = df_period.groupby(group_cols)[pivot_columns].sum().reset_index()
    pivot_data = pivot_data.sort_values('period_sort')
    
    # T√≠nh l·∫°i c√°c t·ª∑ l·ªá sau khi group
    pivot_data['completion_rate'] = (pivot_data['tasks_completed_on_time'] / pivot_data['tasks_assigned'] * 100).fillna(0)
    pivot_data['processing_rate'] = (pivot_data['tasks_processing'] / pivot_data['tasks_assigned'] * 100).fillna(0)
    pivot_data['new_rate'] = (pivot_data['tasks_new'] / pivot_data['tasks_assigned'] * 100).fillna(0)
    
    # T√≠nh to√°n bi·∫øn ƒë·ªông so v·ªõi k·ª≥ tr∆∞·ªõc
    if data_type == 'T·ªïng h·ª£p':
        for col in pivot_columns + ['completion_rate']:
            pivot_data[f'{col}_prev'] = pivot_data[col].shift(1)
            pivot_data[f'{col}_change'] = pivot_data[col] - pivot_data[f'{col}_prev']
            if col != 'completion_rate':
                pivot_data[f'{col}_change_pct'] = ((pivot_data[col] / pivot_data[f'{col}_prev'] - 1) * 100).round(1)
            else:
                pivot_data[f'{col}_change_pct'] = (pivot_data[col] - pivot_data[f'{col}_prev']).round(1)
            pivot_data[f'{col}_change_pct'] = pivot_data[f'{col}_change_pct'].fillna(0)
    
    # Hi·ªÉn th·ªã b·∫£ng ch√≠nh
    display_columns = group_cols + pivot_columns + ['completion_rate', 'processing_rate', 'new_rate']
    
    rename_dict = {
        'period': f'{period_type}',
        'department': 'Ph√≤ng ban',
        'tasks_assigned': 'Giao vi·ªác',
        'tasks_completed_on_time': 'Ho√†n th√†nh ƒë√∫ng h·∫°n',
        'tasks_new': 'Vi·ªác m·ªõi',
        'tasks_processing': 'ƒêang x·ª≠ l√Ω',
        'completion_rate': 'T·ª∑ l·ªá ho√†n th√†nh (%)',
        'processing_rate': 'T·ª∑ l·ªá ƒëang x·ª≠ l√Ω (%)',
        'new_rate': 'T·ª∑ l·ªá vi·ªác m·ªõi (%)'
    }
    
    st.markdown(f"#### üìã T·ªïng h·ª£p theo {period_type} - {data_type}")
    display_df = pivot_data[display_columns].copy()
    for col in ['completion_rate', 'processing_rate', 'new_rate']:
        if col in display_df.columns:
            display_df[col] = display_df[col].round(1)
    
    st.dataframe(display_df.rename(columns=rename_dict), use_container_width=True)
    
    # Hi·ªÉn th·ªã b·∫£ng bi·∫øn ƒë·ªông (ch·ªâ cho t·ªïng h·ª£p)
    if data_type == 'T·ªïng h·ª£p' and len(pivot_data) > 1:
        st.markdown(f"#### üìà Bi·∫øn ƒë·ªông so v·ªõi {period_type.lower()} tr∆∞·ªõc")
        
        change_data = pivot_data[['period']].copy()
        for col in pivot_columns + ['completion_rate']:
            change_col = f'{col}_change'
            pct_col = f'{col}_change_pct'
            prev_col = f'{col}_prev'
            
            if change_col in pivot_data.columns and pct_col in pivot_data.columns:
                if col == 'completion_rate':
                    change_data[f'{col}_combined'] = pivot_data.apply(
                        lambda row: f"{row[change_col]:+.1f}%" 
                        if pd.notna(row[change_col]) and pd.notna(row[prev_col]) else "M·ªõi", axis=1
                    )
                else:
                    change_data[f'{col}_combined'] = pivot_data.apply(
                        lambda row: f"{int(row[change_col]):+} ({row[pct_col]:+.1f}%)" 
                        if pd.notna(row[change_col]) and pd.notna(row[prev_col]) and row[prev_col] != 0 else "M·ªõi", axis=1
                    )
        
        # T·∫°o b·∫£ng hi·ªÉn th·ªã cu·ªëi c√πng
        final_change_columns = ['period'] + [f'{col}_combined' for col in pivot_columns + ['completion_rate'] if f'{col}_combined' in change_data.columns]
        final_rename = {'period': f'{period_type}'}
        for col in pivot_columns + ['completion_rate']:
            if f'{col}_combined' in change_data.columns:
                col_name = rename_dict.get(col, col)
                final_rename[f'{col}_combined'] = f'{col_name} (¬±%)'
        
        if len(final_change_columns) > 1:
            st.dataframe(
                change_data[final_change_columns].rename(columns=final_rename),
                use_container_width=True
            )
    
    # Th·ªëng k√™ t√≥m t·∫Øt
    if len(pivot_data) > 0:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_assigned = pivot_data['tasks_assigned'].sum()
            st.metric("üìã T·ªïng giao vi·ªác", f"{total_assigned:,.0f}")
        with col2:
            total_completed = pivot_data['tasks_completed_on_time'].sum()
            st.metric("‚úÖ Ho√†n th√†nh", f"{total_completed:,.0f}")
        with col3:
            total_processing = pivot_data['tasks_processing'].sum()
            st.metric("üîÑ ƒêang x·ª≠ l√Ω", f"{total_processing:,.0f}")
        with col4:
            avg_completion = pivot_data['completion_rate'].mean()
            st.metric("üìä T·ª∑ l·ªá TB", f"{avg_completion:.1f}%")

# H√†m t·∫°o bi·ªÉu ƒë·ªì cho qu·∫£n l√Ω c√¥ng vi·ªác
def create_task_management_charts(df_all, df_detail):
    col1, col2 = st.columns(2)
    
    with col1:
        # S·∫Øp x·∫øp df_all theo th·ªùi gian tr∆∞·ªõc khi v·∫Ω bi·ªÉu ƒë·ªì
        df_all_sorted = df_all.sort_values('datetime').reset_index(drop=True)
        
        # T√≠nh to√°n c·ªông d·ªìn
        df_all_sorted['cumulative_assigned'] = df_all_sorted['tasks_assigned'].cumsum()
        df_all_sorted['cumulative_completed'] = df_all_sorted['tasks_completed_on_time'].cumsum()
        df_all_sorted['cumulative_processing'] = df_all_sorted['tasks_processing'].cumsum()
        df_all_sorted['cumulative_new'] = df_all_sorted['tasks_new'].cumsum()
        
        # Bi·ªÉu ƒë·ªì xu h∆∞·ªõng c·ªông d·ªìn
        fig_trend = go.Figure()
        fig_trend.add_trace(go.Scatter(x=df_all_sorted['datetime'], y=df_all_sorted['cumulative_assigned'],
                                     mode='lines+markers', name='T·ªïng giao vi·ªác',
                                     line=dict(color='blue', width=3)))
        fig_trend.add_trace(go.Scatter(x=df_all_sorted['datetime'], y=df_all_sorted['cumulative_completed'],
                                     mode='lines+markers', name='T·ªïng ƒë√£ ho√†n th√†nh',
                                     line=dict(color='green', width=3)))
        fig_trend.add_trace(go.Scatter(x=df_all_sorted['datetime'], y=df_all_sorted['cumulative_processing'],
                                     mode='lines+markers', name='T·ªïng ƒëang x·ª≠ l√Ω',
                                     line=dict(color='orange', width=2)))
        fig_trend.add_trace(go.Scatter(x=df_all_sorted['datetime'], y=df_all_sorted['cumulative_new'],
                                     mode='lines+markers', name='T·ªïng vi·ªác m·ªõi',
                                     line=dict(color='red', width=2)))
        
        fig_trend.update_layout(title='üìà Xu h∆∞·ªõng c√¥ng vi·ªác c·ªông d·ªìn',
                              xaxis_title="Ng√†y", yaxis_title="S·ªë l∆∞·ª£ng c·ªông d·ªìn")
        st.plotly_chart(fig_trend, use_container_width=True)
        
        # T√≠nh t·ª∑ l·ªá ho√†n th√†nh c·ªông d·ªìn
        df_all_sorted['cumulative_completion_rate'] = (df_all_sorted['cumulative_completed'] / df_all_sorted['cumulative_assigned'] * 100).fillna(0)
        
        # Bi·ªÉu ƒë·ªì t·ª∑ l·ªá ho√†n th√†nh c·ªông d·ªìn
        fig_completion = px.line(df_all_sorted, x='datetime', y='cumulative_completion_rate',
                               title='üìä T·ª∑ l·ªá ho√†n th√†nh c·ªông d·ªìn (%)',
                               markers=True)
        fig_completion.update_layout(xaxis_title="Ng√†y", yaxis_title="T·ª∑ l·ªá c·ªông d·ªìn (%)")
        fig_completion.update_traces(line_color='purple', line_width=3)
        st.plotly_chart(fig_completion, use_container_width=True)
    
    with col2:
        # Th·ªëng k√™ ph√≤ng ban theo s·ªë l∆∞·ª£ng c√¥ng vi·ªác
        if len(df_detail) > 0:
            dept_summary = df_detail.groupby('department').agg({
                'tasks_assigned': 'sum',
                'tasks_completed_on_time': 'sum',
                'tasks_processing': 'sum',
                'tasks_new': 'sum'
            }).reset_index()
            
            # T√≠nh s·ªë c√¥ng vi·ªác ch∆∞a ho√†n th√†nh (bao g·ªìm ƒëang x·ª≠ l√Ω + m·ªõi)
            dept_summary['tasks_incomplete'] = dept_summary['tasks_processing'] + dept_summary['tasks_new']
            
            # S·∫Øp x·∫øp theo t·ªïng s·ªë c√¥ng vi·ªác
            dept_summary = dept_summary.sort_values('tasks_assigned', ascending=True)
            
            # Bi·ªÉu ƒë·ªì stacked bar h√†ng ngang
            fig_dept = go.Figure()
            
            # Th√™m c·ªôt ho√†n th√†nh (xanh)
            fig_dept.add_trace(go.Bar(
                name='Ho√†n th√†nh',
                y=dept_summary['department'],
                x=dept_summary['tasks_completed_on_time'],
                orientation='h',
                marker_color='#28a745'
            ))
            
            # Th√™m c·ªôt ch∆∞a ho√†n th√†nh (ƒë·ªè)
            fig_dept.add_trace(go.Bar(
                name='Ch∆∞a ho√†n th√†nh',
                y=dept_summary['department'],
                x=dept_summary['tasks_incomplete'],
                orientation='h',
                marker_color='#dc3545'
            ))
            
            # C·∫•u h√¨nh layout nh·ªè g·ªçn
            fig_dept.update_layout(
                title='üìä S·ªë l∆∞·ª£ng c√¥ng vi·ªác theo ph√≤ng ban',
                xaxis_title="S·ªë l∆∞·ª£ng",
                yaxis_title="",
                barmode='stack',
                showlegend=True,
                height=max(150, len(dept_summary) * 20),
                margin=dict(l=80, r=30, t=40, b=30)
            )
            st.plotly_chart(fig_dept, use_container_width=True)
            
            # Metrics ng·∫Øn g·ªçn
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                total_completed_all = dept_summary['tasks_completed_on_time'].sum()
                st.metric("‚úÖ T·ªïng ho√†n th√†nh", f"{total_completed_all:,}")
            with col_b:
                total_incomplete_all = dept_summary['tasks_incomplete'].sum()  
                st.metric("‚ùå T·ªïng ch∆∞a xong", f"{total_incomplete_all:,}")
            with col_c:
                avg_rate = (total_completed_all / (total_completed_all + total_incomplete_all) * 100) if (total_completed_all + total_incomplete_all) > 0 else 0
                st.metric("üìä T·ª∑ l·ªá TB", f"{avg_rate:.1f}%")
            
            # Bi·ªÉu ƒë·ªì ph√¢n b·ªë tr·∫°ng th√°i c√¥ng vi·ªác
            total_completed = df_detail['tasks_completed_on_time'].sum()
            total_processing = df_detail['tasks_processing'].sum()
            total_new = df_detail['tasks_new'].sum()
            
            # Ch·ªâ hi·ªÉn th·ªã c√°c tr·∫°ng th√°i c√≥ gi√° tr·ªã > 0
            status_data = []
            status_values = []
            status_colors = []
            
            if total_completed > 0:
                status_data.append('Ho√†n th√†nh')
                status_values.append(total_completed)
                status_colors.append('#28a745')  # Xanh
                
            if total_processing > 0:
                status_data.append('ƒêang x·ª≠ l√Ω')
                status_values.append(total_processing)
                status_colors.append('#ffc107')  # V√†ng
                
            if total_new > 0:
                status_data.append('Vi·ªác m·ªõi')
                status_values.append(total_new)
                status_colors.append('#dc3545')  # ƒê·ªè
            
            if status_values:  # Ch·ªâ v·∫Ω n·∫øu c√≥ d·ªØ li·ªáu
                fig_status = go.Figure(data=[go.Pie(
                    labels=status_data, 
                    values=status_values,
                    hole=0.4,
                    marker_colors=status_colors,
                    textinfo='label+value+percent',
                    textposition='auto'
                )])
                
                fig_status.update_layout(
                    title='üìã Ph√¢n b·ªë tr·∫°ng th√°i c√¥ng vi·ªác',
                    showlegend=True,
                    legend=dict(orientation="v", yanchor="middle", y=0.5)
                )
                
                st.plotly_chart(fig_status, use_container_width=True)
                
                # Th√™m th·ªëng k√™ t·ªïng quan
                total_all = total_completed + total_processing + total_new
                st.markdown(f"**üìä T·ªïng quan tr·∫°ng th√°i:**")
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("‚úÖ Ho√†n th√†nh", f"{total_completed:,}", f"{total_completed/total_all*100:.1f}%" if total_all > 0 else "0%")
                with col_b:
                    st.metric("üîÑ ƒêang x·ª≠ l√Ω", f"{total_processing:,}", f"{total_processing/total_all*100:.1f}%" if total_all > 0 else "0%")
                with col_c:
                    st.metric("üÜï Vi·ªác m·ªõi", f"{total_new:,}", f"{total_new/total_all*100:.1f}%" if total_all > 0 else "0%")
            else:
                st.info("üìã Kh√¥ng c√≥ d·ªØ li·ªáu tr·∫°ng th√°i c√¥ng vi·ªác")

# H√†m t·∫°o bi·ªÉu ƒë·ªì cho l·ªãch h·ªçp
def create_meeting_charts(df):
    col1, col2 = st.columns(2)
    
    with col1:
        # Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng cu·ªôc h·ªçp theo ng√†y
        fig_daily = px.line(df, x='datetime', y='meeting_schedules',
                           title='üìÖ S·ªë l∆∞·ª£ng cu·ªôc h·ªçp theo ng√†y',
                           markers=True)
        fig_daily.update_traces(line_color='#007bff', line_width=3)
        fig_daily.update_layout(xaxis_title="Ng√†y", yaxis_title="S·ªë cu·ªôc h·ªçp")
        st.plotly_chart(fig_daily, use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì ph√¢n b·ªë theo ng√†y trong tu·∫ßn
        weekday_summary = df.groupby('weekday_vi')['meeting_schedules'].sum().reindex([
            'Th·ª© 2', 'Th·ª© 3', 'Th·ª© 4', 'Th·ª© 5', 'Th·ª© 6', 'Th·ª© 7', 'Ch·ªß nh·∫≠t'
        ]).fillna(0)
        
        colors = ['#28a745' if day in ['Th·ª© 7', 'Ch·ªß nh·∫≠t'] else '#007bff' for day in weekday_summary.index]
        
        fig_weekday = px.bar(x=weekday_summary.index, y=weekday_summary.values,
                            title='üìÖ Ph√¢n b·ªë cu·ªôc h·ªçp theo ng√†y trong tu·∫ßn',
                            color=weekday_summary.index,
                            color_discrete_sequence=colors)
        fig_weekday.update_layout(xaxis_title="Ng√†y trong tu·∫ßn", yaxis_title="T·ªïng s·ªë cu·ªôc h·ªçp", showlegend=False)
        st.plotly_chart(fig_weekday, use_container_width=True)
    
    with col2:
        # Bi·ªÉu ƒë·ªì m·ª©c ƒë·ªô b·∫≠n r·ªôn
        level_counts = df['meeting_level'].value_counts()
        level_order = ['R·∫•t √≠t', '√çt', 'Trung b√¨nh', 'Nhi·ªÅu', 'R·∫•t nhi·ªÅu']
        level_counts = level_counts.reindex(level_order).fillna(0)
        
        colors_level = {'R·∫•t √≠t': '#28a745', '√çt': '#6c757d', 'Trung b√¨nh': '#ffc107', 
                       'Nhi·ªÅu': '#fd7e14', 'R·∫•t nhi·ªÅu': '#dc3545'}
        
        fig_level = px.pie(values=level_counts.values, names=level_counts.index,
                          title='üìä Ph√¢n b·ªë m·ª©c ƒë·ªô b·∫≠n r·ªôn',
                          color=level_counts.index,
                          color_discrete_map=colors_level,
                          hole=0.4)
        st.plotly_chart(fig_level, use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì so s√°nh ng√†y l√†m vi·ªác vs cu·ªëi tu·∫ßn
        day_type_summary = df.groupby('day_type')['meeting_schedules'].agg(['count', 'sum', 'mean']).round(1)
        
        fig_daytype = go.Figure()
        fig_daytype.add_trace(go.Bar(
            name='S·ªë ng√†y',
            x=day_type_summary.index,
            y=day_type_summary['count'],
            marker_color='#17a2b8',
            text=day_type_summary['count'],
            textposition='inside'
        ))
        
        fig_daytype.update_layout(
            title='üìã S·ªë ng√†y h·ªçp: L√†m vi·ªác vs Cu·ªëi tu·∫ßn',
            xaxis_title="Lo·∫°i ng√†y",
            yaxis_title="S·ªë ng√†y",
            showlegend=False
        )
        st.plotly_chart(fig_daytype, use_container_width=True)
        
        # Th·ªëng k√™ ng·∫Øn g·ªçn
        st.markdown("**üìä Th·ªëng k√™ chi ti·∫øt:**")
        col_a, col_b = st.columns(2)
        with col_a:
            workday_avg = day_type_summary.loc['Ng√†y l√†m vi·ªác', 'mean'] if 'Ng√†y l√†m vi·ªác' in day_type_summary.index else 0
            st.metric("üíº TB Ng√†y LV", f"{workday_avg:.1f} cu·ªôc")
        with col_b:
            weekend_avg = day_type_summary.loc['Cu·ªëi tu·∫ßn', 'mean'] if 'Cu·ªëi tu·∫ßn' in day_type_summary.index else 0
            st.metric("üè° TB Cu·ªëi tu·∫ßn", f"{weekend_avg:.1f} cu·ªôc")

# H√†m t·∫°o bi·ªÉu ƒë·ªì cho vƒÉn b·∫£n ƒë·∫øn
def create_incoming_docs_charts(df, period_type='Tu·∫ßn'):
    col1, col2 = st.columns(2)
    
    with col1:
        # Bi·ªÉu ƒë·ªì theo period_type ƒë∆∞·ª£c ch·ªçn
        df_chart = df.copy()

        # T·∫°o period theo l·ª±a ch·ªçn
        if period_type == 'Tu·∫ßn':
            df_chart['period'] = 'W' + df_chart['week'].astype(str) + '-' + df_chart['year'].astype(str)
            df_chart['period_sort'] = df_chart['year'] * 100 + df_chart['week']
            chart_title = 'üìà S·ªë l∆∞·ª£ng vƒÉn b·∫£n ƒë·∫øn theo tu·∫ßn'
            x_title = "Tu·∫ßn"
        elif period_type == 'Th√°ng':
            df_chart['period'] = 'T' + df_chart['month'].astype(str) + '-' + df_chart['year'].astype(str)
            df_chart['period_sort'] = df_chart['year'] * 100 + df_chart['month']
            chart_title = 'üìà S·ªë l∆∞·ª£ng vƒÉn b·∫£n ƒë·∫øn theo th√°ng'
            x_title = "Th√°ng"
        elif period_type == 'Qu√Ω':
            df_chart['quarter'] = ((df_chart['month'] - 1) // 3) + 1
            df_chart['period'] = 'Q' + df_chart['quarter'].astype(str) + '-' + df_chart['year'].astype(str)
            df_chart['period_sort'] = df_chart['year'] * 100 + df_chart['quarter']
            chart_title = 'üìà S·ªë l∆∞·ª£ng vƒÉn b·∫£n ƒë·∫øn theo qu√Ω'
            x_title = "Qu√Ω"
        elif period_type == 'NƒÉm':
            df_chart['period'] = df_chart['year'].astype(str)
            df_chart['period_sort'] = df_chart['year']
            chart_title = 'üìà S·ªë l∆∞·ª£ng vƒÉn b·∫£n ƒë·∫øn theo nƒÉm'
            x_title = "NƒÉm"
        else:  # Ng√†y
            df_chart['period'] = df_chart['datetime'].dt.strftime('%d/%m/%Y')
            df_chart['period_sort'] = df_chart['datetime']
            chart_title = 'üìà S·ªë l∆∞·ª£ng vƒÉn b·∫£n ƒë·∫øn theo ng√†y'
            x_title = "Ng√†y"

        # Group data theo period
        period_data = df_chart.groupby(['period', 'period_sort'])['total_incoming'].sum().reset_index()
        period_data = period_data.sort_values('period_sort')

        # T·∫°o bi·ªÉu ƒë·ªì
        fig_period = go.Figure()

        # ƒê∆∞·ªùng bi·ªÉu ƒë·ªì ch√≠nh
        fig_period.add_trace(go.Scatter(
            x=period_data['period'],
            y=period_data['total_incoming'],
            mode='lines+markers',
            name='VƒÉn b·∫£n ƒë·∫øn',
            line=dict(color='#1f77b4', width=2),
            marker=dict(size=8)
        ))

        # ƒê∆∞·ªùng xu h∆∞·ªõng (n·∫øu ƒë·ªß d·ªØ li·ªáu)
        if len(period_data) >= 3:
            ma_window = min(3, len(period_data)//2)
            ma_trend = period_data['total_incoming'].rolling(window=ma_window, center=True).mean()
            fig_period.add_trace(go.Scatter(
                x=period_data['period'],
                y=ma_trend,
                mode='lines',
                name=f'Xu h∆∞·ªõng ({ma_window} {period_type.lower()})',
                line=dict(color='red', width=3, dash='dash'),
                opacity=0.8
            ))

        fig_period.update_layout(
            title=f'{chart_title} (c√≥ xu h∆∞·ªõng)',
            xaxis_title=x_title,
            yaxis_title="S·ªë l∆∞·ª£ng vƒÉn b·∫£n",
            hovermode='x unified'
        )
        st.plotly_chart(fig_period, use_container_width=True)
        
        # Bi·ªÉu ƒë·ªì t·ª∑ l·ªá x·ª≠ l√Ω ƒë√∫ng h·∫°n vs tr·ªÖ h·∫°n theo period_type
        # T√≠nh l·∫°i processed data theo period
        processed_summary = df_chart.groupby(['period', 'period_sort']).agg({
            'processed_on_time': 'sum',
            'processed_late': 'sum'
        }).reset_index()
        processed_summary = processed_summary.sort_values('period_sort')

        fig_processed = go.Figure()
        fig_processed.add_trace(go.Scatter(x=processed_summary['period'],
                                         y=processed_summary['processed_on_time'],
                                         mode='lines+markers', name='ƒê√∫ng h·∫°n',
                                         line=dict(color='green')))
        fig_processed.add_trace(go.Scatter(x=processed_summary['period'],
                                         y=processed_summary['processed_late'],
                                         mode='lines+markers', name='Tr·ªÖ h·∫°n',
                                         line=dict(color='red')))
        fig_processed.update_layout(title=f'‚è∞ T√¨nh h√¨nh x·ª≠ l√Ω vƒÉn b·∫£n theo {period_type.lower()}',
                                  xaxis_title=x_title, yaxis_title="S·ªë l∆∞·ª£ng")
        st.plotly_chart(fig_processed, use_container_width=True)
    
    with col2:
        # Bi·ªÉu ƒë·ªì ph√¢n b·ªë theo ƒë∆°n v·ªã g·ª≠i
        def extract_sender_name(x):
            try:
                if isinstance(x, dict):
                    return x.get('send_name', 'Kh√°c')
                elif isinstance(x, str):
                    import json
                    parsed = json.loads(x)
                    return parsed.get('send_name', 'Kh√°c')
                else:
                    return 'Kh√°c'
            except:
                return 'Kh√°c'

        sender_data = df['total_incoming_detail'].apply(extract_sender_name).value_counts()
        fig_sender = px.pie(values=sender_data.values, names=sender_data.index,
                           title='üèõÔ∏è Ph√¢n b·ªë theo ƒë∆°n v·ªã g·ª≠i')
        st.plotly_chart(fig_sender, use_container_width=True)

        # Bi·ªÉu ƒë·ªì top ƒë∆°n v·ªã g·ª≠i theo period_type
        try:
            # T·∫°o DataFrame v·ªõi sender cho t·ª´ng period
            df_chart['sender'] = df_chart['total_incoming_detail'].apply(extract_sender_name)

            # T√¨m top 5 senders t·ªïng th·ªÉ
            top_senders = df_chart['sender'].value_counts().head(5).index.tolist()

            if len(top_senders) > 0:
                fig_sender_trend = go.Figure()

                for sender in top_senders:
                    # ƒê·∫øm s·ªë vƒÉn b·∫£n t·ª´ sender n√†y theo period
                    sender_data = df_chart[df_chart['sender'] == sender].groupby(['period', 'period_sort']).size().reset_index(name='count')
                    sender_data = sender_data.sort_values('period_sort')

                    # ƒê·∫£m b·∫£o t·∫•t c·∫£ periods ƒë·ªÅu c√≥ d·ªØ li·ªáu (fill missing v·ªõi 0)
                    all_periods = period_data[['period', 'period_sort']].drop_duplicates()
                    sender_data = all_periods.merge(sender_data, on=['period', 'period_sort'], how='left')
                    sender_data['count'] = sender_data['count'].fillna(0)

                    fig_sender_trend.add_trace(go.Bar(
                        name=sender,
                        x=sender_data['period'],
                        y=sender_data['count']
                    ))

                fig_sender_trend.update_layout(
                    title=f'üìä Top 5 ƒë∆°n v·ªã g·ª≠i theo {period_type.lower()}',
                    xaxis_title=x_title,
                    yaxis_title="S·ªë l∆∞·ª£ng vƒÉn b·∫£n",
                    barmode='stack'
                )
                st.plotly_chart(fig_sender_trend, use_container_width=True)
            else:
                st.info(f"Kh√¥ng c√≥ d·ªØ li·ªáu ƒë∆°n v·ªã g·ª≠i theo {period_type.lower()}")
        except Exception as e:
            st.error(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì ƒë∆°n v·ªã g·ª≠i: {str(e)}")
            st.info("Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì ƒë∆°n v·ªã g·ª≠i ƒë∆°n gi·∫£n thay th·∫ø")

            # Fallback - bi·ªÉu ƒë·ªì ƒë∆°n gi·∫£n h∆°n
            if 'total_incoming_detail' in df.columns:
                simple_sender_data = df['total_incoming_detail'].apply(extract_sender_name).value_counts().head(5)
                fig_simple = px.bar(
                    x=simple_sender_data.index,
                    y=simple_sender_data.values,
                    title='üìä Top 5 ƒë∆°n v·ªã g·ª≠i (t·ªïng h·ª£p)',
                    labels={'x': 'ƒê∆°n v·ªã', 'y': 'S·ªë l∆∞·ª£ng vƒÉn b·∫£n'}
                )
                st.plotly_chart(fig_simple, use_container_width=True)

# T·∫°o tabs
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üè† T·ªïng quan", 
    "üì• VƒÉn b·∫£n ƒë·∫øn", 
    "üì§ VƒÉn b·∫£n ƒëi", 
    "üìã Qu·∫£n l√Ω c√¥ng vi·ªác", 
    "üìÖ Qu·∫£n l√Ω l·ªãch h·ªçp", 
    "üè¢ Qu·∫£n l√Ω ph√≤ng h·ªçp"
])

# Tab 1: T·ªïng quan
with tab1:
    st.markdown('<div class="tab-header">üìä T·ªïng quan Ph√≤ng H√†nh Ch√≠nh</div>', unsafe_allow_html=True)
    
    def load_summary_data():
        """Load d·ªØ li·ªáu t·ªïng h·ª£p t·ª´ tonghop.json"""
        try:
            with open('tonghop.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                df = pd.DataFrame(data['data'])
                
                # T·∫°o c·ªôt datetime
                df['datetime'] = pd.to_datetime(df[['year', 'month', 'date']].rename(columns={'date': 'day'}))
                
                # Chu·∫©n h√≥a category names
                df['category_clean'] = df['category'].str.replace(' ', '_').str.lower()
                df['category_vi'] = df['category'].map({
                    'Van ban den': 'üì• VƒÉn b·∫£n ƒë·∫øn',
                    'Van ban phat hanh di': 'üì§ VƒÉn b·∫£n ƒëi', 
                    'Van ban phat hanh quyet dinh': 'üìú Quy·∫øt ƒë·ªãnh',
                    'Van ban phat hanhquy dinh': 'üìã Quy ƒë·ªãnh',
                    'Van ban phat hanhquy trinh': 'üìã Quy tr√¨nh',
                    'Van ban phat hanh hop dong': 'üìù H·ª£p ƒë·ªìng',
                    'Quan ly phong hop': 'üè¢ Ph√≤ng h·ªçp',
                    'Quan ly cong viec': 'üíº C√¥ng vi·ªác'
                }).fillna('üî∏ ' + df['category'])
                
                return df
        except Exception as e:
            st.error(f"L·ªói khi load d·ªØ li·ªáu t·ªïng h·ª£p: {e}")
            return None
    
    # Load d·ªØ li·ªáu
    df_summary = load_summary_data()
    
    if df_summary is not None:
        # √Åp d·ª•ng global filter
        df_summary = apply_global_filter(df_summary)
        
        # T√≠nh to√°n metrics t·ªïng quan
        categories_summary = df_summary.groupby('category_vi')['count'].sum().sort_values(ascending=False)
        total_items = df_summary['count'].sum()
        
        # Metrics t·ªïng quan
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            vb_den = categories_summary.get('üì• VƒÉn b·∫£n ƒë·∫øn', 0)
            st.metric("üì• VƒÉn b·∫£n ƒë·∫øn", f"{vb_den:,}")
        
        with col2:
            vb_di = categories_summary.get('üì§ VƒÉn b·∫£n ƒëi', 0)
            st.metric("üì§ VƒÉn b·∫£n ƒëi", f"{vb_di:,}")
        
        with col3:
            phong_hop = categories_summary.get('üè¢ Ph√≤ng h·ªçp', 0)
            st.metric("üè¢ Cu·ªôc h·ªçp", f"{phong_hop:,}")
        
        with col4:
            hop_dong = categories_summary.get('üìù H·ª£p ƒë·ªìng', 0)
            quyet_dinh = categories_summary.get('üìú Quy·∫øt ƒë·ªãnh', 0)
            st.metric("üìú Qƒê + Hƒê", f"{hop_dong + quyet_dinh:,}")
        
        st.markdown("---")
        
        # Bi·ªÉu ƒë·ªì t·ªïng quan
        col1, col2 = st.columns(2)
        
        with col1:
            # Bi·ªÉu ƒë·ªì xu h∆∞·ªõng theo th·ªùi gian
            daily_summary = df_summary.groupby(['datetime', 'category_vi'])['count'].sum().reset_index()
            
            fig_trend = px.line(daily_summary, x='datetime', y='count', color='category_vi',
                               title='üìà Xu h∆∞·ªõng ho·∫°t ƒë·ªông theo th·ªùi gian',
                               labels={'count': 'S·ªë l∆∞·ª£ng', 'datetime': 'Ng√†y', 'category_vi': 'Lo·∫°i ho·∫°t ƒë·ªông'})
            fig_trend.update_layout(height=400, hovermode='x unified')
            st.plotly_chart(fig_trend, use_container_width=True)
        
        with col2:
            # Bi·ªÉu ƒë·ªì ph√¢n b·ªë theo lo·∫°i ho·∫°t ƒë·ªông
            fig_pie = px.pie(values=categories_summary.values, names=categories_summary.index,
                           title='üìä Ph√¢n b·ªë theo lo·∫°i ho·∫°t ƒë·ªông',
                           hole=0.4)
            fig_pie.update_layout(height=400)
            st.plotly_chart(fig_pie, use_container_width=True)
        
        # Ph√¢n t√≠ch chi ti·∫øt
        st.markdown('<div class="section-header">üìà Ph√¢n t√≠ch chi ti·∫øt</div>', unsafe_allow_html=True)
        
        # Tabs con cho ph√¢n t√≠ch
        subtab1, subtab2, subtab3 = st.tabs(["üìÖ Theo th·ªùi gian", "üìä Theo lo·∫°i", "üìà Top ng√†y"])
        
        with subtab1:
            # Ph√¢n t√≠ch theo th√°ng li√™n t·ª•c
            df_summary['year_month'] = df_summary['year'].astype(str) + '-' + df_summary['month'].astype(str).str.zfill(2)
            df_summary['month_year_vi'] = df_summary['month'].astype(str) + '/' + df_summary['year'].astype(str)
            
            monthly_data = df_summary.groupby(['year_month', 'month_year_vi', 'category_vi'])['count'].sum().reset_index()
            
            fig_monthly = px.bar(monthly_data, x='month_year_vi', y='count', color='category_vi',
                               title='Ho·∫°t ƒë·ªông theo th·ªùi gian (th√°ng/nƒÉm)', barmode='group',
                               labels={'count': 'S·ªë l∆∞·ª£ng', 'month_year_vi': 'Th√°ng/NƒÉm', 'category_vi': 'Lo·∫°i'})
            fig_monthly.update_xaxes(tickangle=45)
            st.plotly_chart(fig_monthly, use_container_width=True)
            
            # B·∫£ng th·ªëng k√™ theo th√°ng li√™n t·ª•c
            monthly_stats = df_summary.groupby(['month_year_vi', 'category_vi'])['count'].sum().unstack(fill_value=0)
            monthly_stats = monthly_stats.sort_index(key=lambda x: pd.to_datetime(x, format='%m/%Y'))
            st.dataframe(monthly_stats, use_container_width=True)
        
        with subtab2:
            # Ph√¢n t√≠ch chi ti·∫øt theo t·ª´ng lo·∫°i
            for category in categories_summary.index[:4]:  # Top 4 categories
                category_data = df_summary[df_summary['category_vi'] == category]
                daily_trend = category_data.groupby('datetime')['count'].sum()
                
                st.markdown(f"#### {category}")
                col_a, col_b, col_c = st.columns([2, 1, 1])
                
                with col_a:
                    fig_cat = px.line(x=daily_trend.index, y=daily_trend.values,
                                     title=f'Xu h∆∞·ªõng {category}')
                    fig_cat.update_layout(height=300)
                    st.plotly_chart(fig_cat, use_container_width=True)
                
                with col_b:
                    st.metric("T·ªïng", f"{category_data['count'].sum():,}")
                
                with col_c:
                    st.metric("TB/ng√†y", f"{category_data['count'].mean():.1f}")
        
        with subtab3:
            # Top ng√†y c√≥ ho·∫°t ƒë·ªông cao nh·∫•t
            daily_total = df_summary.groupby('datetime')['count'].sum().sort_values(ascending=False)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üèÜ Top 10 ng√†y ho·∫°t ƒë·ªông m·∫°nh nh·∫•t")
                for i, (date, count) in enumerate(daily_total.head(10).items(), 1):
                    day_detail = df_summary[df_summary['datetime'] == date].groupby('category_vi')['count'].sum()
                    detail_text = " | ".join([f"{cat}: {val}" for cat, val in day_detail.items()])
                    st.success(f"#{i}. {date.strftime('%d/%m/%Y')}: **{count}** ho·∫°t ƒë·ªông\n\n{detail_text}")
            
            with col2:
                st.markdown("#### üìä Ho·∫°t ƒë·ªông theo ng√†y trong tu·∫ßn")
                df_summary['weekday'] = df_summary['datetime'].dt.day_name()
                df_summary['weekday_vi'] = df_summary['weekday'].map({
                    'Monday': 'Th·ª© 2', 'Tuesday': 'Th·ª© 3', 'Wednesday': 'Th·ª© 4',
                    'Thursday': 'Th·ª© 5', 'Friday': 'Th·ª© 6', 'Saturday': 'Th·ª© 7', 'Sunday': 'CN'
                })
                
                weekday_stats = df_summary.groupby('weekday_vi')['count'].agg(['sum', 'mean']).round(2)
                weekday_stats.columns = ['T·ªïng', 'TB/ng√†y']
                
                fig_weekday = px.bar(x=weekday_stats.index, y=weekday_stats['T·ªïng'],
                                   title='T·ªïng ho·∫°t ƒë·ªông theo ng√†y trong tu·∫ßn')
                st.plotly_chart(fig_weekday, use_container_width=True)
                
                st.dataframe(weekday_stats, use_container_width=True)
    
    else:
        st.error("‚ùå Kh√¥ng th·ªÉ load d·ªØ li·ªáu t·ªïng h·ª£p t·ª´ file tonghop.json")
        st.info("üìÅ ƒê·∫£m b·∫£o file tonghop.json t·ªìn t·∫°i trong th∆∞ m·ª•c g·ªëc")

# Tab 2: VƒÉn b·∫£n ƒë·∫øn
with tab2:
    st.markdown('<div class="tab-header">üì• Qu·∫£n l√Ω VƒÉn b·∫£n ƒê·∫øn</div>', unsafe_allow_html=True)
    
    # Upload file
    uploaded_file = st.file_uploader(
        "üìÅ Upload d·ªØ li·ªáu vƒÉn b·∫£n ƒë·∫øn", 
        type=['json', 'csv'],
        key="incoming_docs"
    )
    
    if uploaded_file is not None:
        df = process_incoming_documents_data(uploaded_file)
        
        if df is not None:
            # √Åp d·ª•ng filter to√†n c·ª•c
            df = apply_global_filter(df)
            # Th·ªëng k√™ t·ªïng quan
            st.markdown("### üìä Th·ªëng k√™ t·ªïng quan")
            
            # H√†ng 1: Th·ªëng k√™ ch√≠nh
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                total_docs = df['total_incoming'].sum()
                st.metric("üìë T·ªïng vƒÉn b·∫£n", f"{total_docs:,}")
            
            with col2:
                avg_daily = df['total_incoming'].mean()
                st.metric("üìà Trung b√¨nh/ng√†y", f"{avg_daily:.1f}")
            
            with col3:
                total_on_time = df['processed_on_time'].sum()
                st.metric("‚úÖ X·ª≠ l√Ω ƒë√∫ng h·∫°n", f"{total_on_time:,}")
            
            with col4:
                total_late = df['processed_late'].sum()
                st.metric("‚ö†Ô∏è X·ª≠ l√Ω tr·ªÖ h·∫°n", f"{total_late:,}")
            
            with col5:
                if total_docs > 0:
                    on_time_rate = (total_on_time / total_docs) * 100
                else:
                    on_time_rate = 0
                st.metric("üìä T·ª∑ l·ªá ƒë√∫ng h·∫°n", f"{on_time_rate:.1f}%")
            
            # H√†ng 2: Ph√¢n lo·∫°i ph·∫£n h·ªìi
            st.markdown("#### üìã Ph√¢n lo·∫°i theo y√™u c·∫ßu ph·∫£n h·ªìi")
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                no_response = df['no_response_required'].sum()
                st.metric("üîï Kh√¥ng c·∫ßn ph·∫£n h·ªìi", f"{no_response:,}")
            
            with col2:
                need_response = df['response_required'].sum()
                st.metric("üì¢ C·∫ßn ph·∫£n h·ªìi", f"{need_response:,}")
            
            with col3:
                vanban_response = df['response_required_VanBan'].sum()
                st.metric("üìÑ PH VƒÉn b·∫£n", f"{vanban_response:,}")
            
            with col4:
                email_response = df['response_required_Email'].sum()
                st.metric("üìß PH Email", f"{email_response:,}")
            
            with col5:
                phone_response = df['response_required_DienThoai'].sum()
                st.metric("üìû PH ƒêi·ªán tho·∫°i", f"{phone_response:,}")
            
            st.markdown("---")
            
            # Pivot Table
            selected_period_type = create_pivot_table(df)

            st.markdown("---")

            # Bi·ªÉu ƒë·ªì
            create_incoming_docs_charts(df, selected_period_type)
            
            # B·∫£ng d·ªØ li·ªáu chi ti·∫øt
            st.markdown("### üìã Chi ti·∫øt d·ªØ li·ªáu")
            
            # L·ªçc d·ªØ li·ªáu
            col1, col2 = st.columns(2)
            with col1:
                date_range = st.date_input(
                    "üìÖ Ch·ªçn kho·∫£ng th·ªùi gian",
                    value=(df['datetime'].min(), df['datetime'].max()),
                    min_value=df['datetime'].min(),
                    max_value=df['datetime'].max()
                )
            
            with col2:
                min_docs = st.number_input("üìä S·ªë vƒÉn b·∫£n t·ªëi thi·ªÉu", min_value=0, value=0)
            
            # √Åp d·ª•ng filter
            if len(date_range) == 2:
                filtered_df = df[
                    (df['datetime'] >= pd.to_datetime(date_range[0])) & 
                    (df['datetime'] <= pd.to_datetime(date_range[1])) &
                    (df['total_incoming'] >= min_docs)
                ]
            else:
                filtered_df = df[df['total_incoming'] >= min_docs]
            
            display_cols = ['datetime', 'total_incoming', 'no_response_required', 'response_required',
                           'processed_on_time', 'processed_late']
            
            # Th√™m c√°c c·ªôt ph·∫£n h·ªìi n·∫øu c√≥
            response_cols = ['response_required_VanBan', 'response_required_Email', 
                           'response_required_DienThoai', 'response_required_PhanMem']
            for col in response_cols:
                if col in filtered_df.columns:
                    display_cols.append(col)
            
            # Th√™m c·ªôt detail n·∫øu c√≥
            if 'total_incoming_detail' in filtered_df.columns:
                display_cols.append('total_incoming_detail')
            
            st.dataframe(filtered_df[display_cols], use_container_width=True)
    else:
        st.info("üìÅ Vui l√≤ng upload file d·ªØ li·ªáu ƒë·ªÉ xem th·ªëng k√™ chi ti·∫øt")

# Tab 3: VƒÉn b·∫£n ƒëi
with tab3:
    st.markdown('<div class="tab-header">üì§ Qu·∫£n l√Ω VƒÉn b·∫£n ƒêi</div>', unsafe_allow_html=True)
    
    # Upload file
    uploaded_file_out = st.file_uploader(
        "üìÅ Upload d·ªØ li·ªáu vƒÉn b·∫£n ƒëi", 
        type=['json', 'csv'],
        key="outgoing_docs"
    )
    
    if uploaded_file_out is not None:
        df_out = process_outgoing_documents_data(uploaded_file_out)
        
        if df_out is not None:
            # √Åp d·ª•ng filter to√†n c·ª•c
            df_out = apply_global_filter(df_out)
            # Th·ªëng k√™ t·ªïng quan
            st.markdown("### üìä Th·ªëng k√™ t·ªïng quan vƒÉn b·∫£n ƒëi")
            
            # H√†ng 1: Th·ªëng k√™ ch√≠nh
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                if 'total_outgoing' in df_out.columns:
                    total_outgoing = df_out['total_outgoing'].sum()
                    st.metric("üìÑ T·ªïng vƒÉn b·∫£n ƒëi", f"{total_outgoing:,}")
                else:
                    st.metric("üìÑ T·ªïng vƒÉn b·∫£n ƒëi", "0")
            
            with col2:
                total_docs = df_out['documents'].sum()
                st.metric("üìù VƒÉn b·∫£n ph√°t h√†nh", f"{total_docs:,}")
            
            with col3:
                total_contracts = df_out['contracts_total'].sum()
                st.metric("üìÅ H·ª£p ƒë·ªìng", f"{total_contracts:,}")
            
            with col4:
                total_decisions = df_out['decisions_total'].sum()
                st.metric("‚öñÔ∏è Quy·∫øt ƒë·ªãnh", f"{total_decisions:,}")
            
            with col5:
                avg_daily = df_out['total_outgoing'].mean() if 'total_outgoing' in df_out.columns else 0
                st.metric("üìà TB/ng√†y", f"{avg_daily:.1f}")
            
            # H√†ng 2: Th·ªëng k√™ quy ch·∫ø v√† quy ƒë·ªãnh
            st.markdown("#### üìã Th·ªëng k√™ quy ch·∫ø v√† quy ƒë·ªãnh")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_regulations = df_out['regulations_total'].sum()
                st.metric("üìú Quy ƒë·ªãnh", f"{total_regulations:,}")
            
            with col2:
                total_rules = df_out['rules_total'].sum()
                st.metric("üìã Quy ch·∫ø", f"{total_rules:,}")
            
            with col3:
                total_procedures = df_out['procedures_total'].sum()
                st.metric("üîÑ Th·ªß t·ª•c", f"{total_procedures:,}")
            
            with col4:
                total_instruct = df_out['instruct_total'].sum()
                st.metric("üìö H∆∞·ªõng d·∫´n", f"{total_instruct:,}")
            
            st.markdown("---")
            
            # Pivot Table
            create_outgoing_pivot_table(df_out)
            
            st.markdown("---")
            
            # Bi·ªÉu ƒë·ªì
            create_outgoing_docs_charts(df_out)
            
            # B·∫£ng d·ªØ li·ªáu chi ti·∫øt
            st.markdown("### üìã Chi ti·∫øt d·ªØ li·ªáu")
            
            # L·ªçc d·ªØ li·ªáu
            col1, col2 = st.columns(2)
            with col1:
                date_range_out = st.date_input(
                    "üìÖ Ch·ªçn kho·∫£ng th·ªùi gian",
                    value=(df_out['datetime'].min(), df_out['datetime'].max()),
                    min_value=df_out['datetime'].min(),
                    max_value=df_out['datetime'].max(),
                    key="outgoing_date_range"
                )
            
            with col2:
                min_docs_out = st.number_input("üìä S·ªë vƒÉn b·∫£n t·ªëi thi·ªÉu", min_value=0, value=0, key="outgoing_min_docs")
            
            # √Åp d·ª•ng filter
            if len(date_range_out) == 2:
                filtered_df_out = df_out[
                    (df_out['datetime'] >= pd.to_datetime(date_range_out[0])) & 
                    (df_out['datetime'] <= pd.to_datetime(date_range_out[1])) &
                    (df_out['documents'] >= min_docs_out)
                ]
            else:
                filtered_df_out = df_out[df_out['documents'] >= min_docs_out]
            
            display_cols_out = ['datetime', 'total_outgoing', 'documents', 'contracts_total', 'decisions_total', 
                               'regulations_total', 'rules_total', 'procedures_total', 'instruct_total']
            
            # Ch·ªâ hi·ªÉn th·ªã c√°c c·ªôt c√≥ trong DataFrame
            display_cols_out = [col for col in display_cols_out if col in filtered_df_out.columns]
            
            # Th√™m c·ªôt contracts, decisions detail n·∫øu c√≥
            detail_cols = ['contracts', 'decisions']
            for col in detail_cols:
                if col in filtered_df_out.columns:
                    display_cols_out.append(col)
            
            st.dataframe(filtered_df_out[display_cols_out], use_container_width=True)
    else:
        st.info("üìÅ Vui l√≤ng upload file d·ªØ li·ªáu ƒë·ªÉ xem th·ªëng k√™ chi ti·∫øt")

# Tab 4: Qu·∫£n l√Ω c√¥ng vi·ªác
with tab4:
    st.markdown('<div class="tab-header">üìã Qu·∫£n l√Ω C√¥ng Vi·ªác</div>', unsafe_allow_html=True)
    
    # Upload file
    uploaded_file_tasks = st.file_uploader(
        "üìÅ Upload d·ªØ li·ªáu c√¥ng vi·ªác", 
        type=['json', 'csv'],
        key="tasks"
    )
    
    if uploaded_file_tasks is not None:
        df_all_tasks, df_detail_tasks = process_task_management_data(uploaded_file_tasks)
        
        if df_all_tasks is not None and df_detail_tasks is not None:
            # √Åp d·ª•ng filter to√†n c·ª•c
            df_all_tasks_filtered = apply_global_filter(df_all_tasks)
            df_detail_tasks_filtered = apply_global_filter(df_detail_tasks)
            # Th·ªëng k√™ t·ªïng quan
            st.markdown("### üìä Th·ªëng k√™ t·ªïng quan c√¥ng vi·ªác")
            
            # H√†ng 1: Th·ªëng k√™ ch√≠nh
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                total_assigned = df_all_tasks_filtered['tasks_assigned'].sum()
                st.metric("üìã T·ªïng giao vi·ªác", f"{total_assigned:,}")
            
            with col2:
                total_completed = df_all_tasks_filtered['tasks_completed_on_time'].sum()
                st.metric("‚úÖ Ho√†n th√†nh", f"{total_completed:,}")
            
            with col3:
                total_processing = df_all_tasks_filtered['tasks_processing'].sum()
                st.metric("üîÑ ƒêang x·ª≠ l√Ω", f"{total_processing:,}")
            
            with col4:
                total_new = df_all_tasks_filtered['tasks_new'].sum()
                st.metric("üÜï Vi·ªác m·ªõi", f"{total_new:,}")
            
            with col5:
                avg_completion = df_all_tasks_filtered['completion_rate'].mean()
                st.metric("üìä T·ª∑ l·ªá ho√†n th√†nh", f"{avg_completion:.1f}%")
            
            # H√†ng 2: Th·ªëng k√™ ph√≤ng ban
            st.markdown("#### üìã Th·ªëng k√™ theo ph√≤ng ban")
            if len(df_detail_tasks_filtered) > 0:
                dept_summary = df_detail_tasks_filtered.groupby('department').agg({
                    'tasks_assigned': 'sum',
                    'tasks_completed_on_time': 'sum',
                    'tasks_processing': 'sum',
                    'tasks_new': 'sum'
                }).reset_index()
                dept_summary['completion_rate'] = (dept_summary['tasks_completed_on_time'] / dept_summary['tasks_assigned'] * 100).fillna(0)
                
                # Top 3 ph√≤ng ban
                top_depts = dept_summary.nlargest(3, 'completion_rate')
                
                col1, col2, col3 = st.columns(3)
                for i, (idx, dept) in enumerate(top_depts.iterrows()):
                    with [col1, col2, col3][i]:
                        st.metric(f"üèÜ {dept['department']}", f"{dept['completion_rate']:.1f}%", 
                                f"{dept['tasks_completed_on_time']}/{dept['tasks_assigned']} vi·ªác")
            
            st.markdown("---")
            
            # Pivot Table
            create_task_pivot_table(df_all_tasks_filtered, df_detail_tasks_filtered)
            
            st.markdown("---")
            
            # Bi·ªÉu ƒë·ªì
            create_task_management_charts(df_all_tasks_filtered, df_detail_tasks_filtered)
            
            # B·∫£ng d·ªØ li·ªáu chi ti·∫øt
            st.markdown("### üìã Chi ti·∫øt d·ªØ li·ªáu")
            
            # Ch·ªçn lo·∫°i d·ªØ li·ªáu hi·ªÉn th·ªã
            detail_type = st.selectbox(
                "üìä Hi·ªÉn th·ªã d·ªØ li·ªáu:",
                options=['T·ªïng h·ª£p t·∫•t c·∫£ ph√≤ng ban', 'Chi ti·∫øt t·ª´ng ph√≤ng ban'],
                key="task_detail_type"
            )
            
            # Ch·ªçn DataFrame ƒë√£ ƒë∆∞·ª£c filter to√†n c·ª•c
            display_df = df_all_tasks_filtered if detail_type == 'T·ªïng h·ª£p t·∫•t c·∫£ ph√≤ng ban' else df_detail_tasks_filtered
            
            # L·ªçc th√™m theo s·ªë vi·ªác t·ªëi thi·ªÉu
            min_tasks = st.number_input("üìä S·ªë vi·ªác t·ªëi thi·ªÉu", min_value=0, value=0, key="tasks_min")
            filtered_df_tasks = display_df[display_df['tasks_assigned'] >= min_tasks]
            
            # C√°c c·ªôt hi·ªÉn th·ªã
            display_cols_tasks = ['datetime', 'tasks_assigned', 'tasks_completed_on_time', 
                                 'tasks_processing', 'tasks_new', 'completion_rate']
            
            if detail_type == 'Chi ti·∫øt t·ª´ng ph√≤ng ban':
                display_cols_tasks.insert(1, 'department')
            
            # Format completion_rate
            filtered_df_display = filtered_df_tasks[display_cols_tasks].copy()
            filtered_df_display['completion_rate'] = filtered_df_display['completion_rate'].round(1)
            
            st.dataframe(
                filtered_df_display.rename(columns={
                    'datetime': 'Ng√†y',
                    'department': 'Ph√≤ng ban',
                    'tasks_assigned': 'Giao vi·ªác',
                    'tasks_completed_on_time': 'Ho√†n th√†nh',
                    'tasks_processing': 'ƒêang x·ª≠ l√Ω',
                    'tasks_new': 'Vi·ªác m·ªõi',
                    'completion_rate': 'T·ª∑ l·ªá ho√†n th√†nh (%)'
                }), 
                use_container_width=True
            )
    else:
        st.info("üìÅ Vui l√≤ng upload file d·ªØ li·ªáu ƒë·ªÉ xem th·ªëng k√™ chi ti·∫øt")

# Tab 5: Qu·∫£n l√Ω l·ªãch h·ªçp
with tab5:
    st.markdown('<div class="tab-header">üìÖ Qu·∫£n l√Ω L·ªãch H·ªçp</div>', unsafe_allow_html=True)
    
    uploaded_file_meetings = st.file_uploader(
        "üìÅ Upload d·ªØ li·ªáu l·ªãch h·ªçp", 
        type=['json', 'csv'],
        key="meetings"
    )
    
    if uploaded_file_meetings is not None:
        df_meetings = process_meeting_data(uploaded_file_meetings)
        
        if df_meetings is not None:
            # √Åp d·ª•ng filter to√†n c·ª•c
            df_meetings = apply_global_filter(df_meetings)
            
            # Th·ªëng k√™ t·ªïng quan
            st.markdown("### üìä Th·ªëng k√™ t·ªïng quan l·ªãch h·ªçp")
            
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                total_meetings = df_meetings['meeting_schedules'].sum()
                st.metric("üìÖ T·ªïng cu·ªôc h·ªçp", f"{total_meetings:,}")
            
            with col2:
                avg_daily = df_meetings['meeting_schedules'].mean()
                st.metric("üìà TB/ng√†y", f"{avg_daily:.1f}")
            
            with col3:
                max_day = df_meetings['meeting_schedules'].max()
                st.metric("üî• Nhi·ªÅu nh·∫•t", f"{max_day} cu·ªôc")
            
            with col4:
                min_day = df_meetings['meeting_schedules'].min()
                st.metric("üîª √çt nh·∫•t", f"{min_day} cu·ªôc")
            
            with col5:
                total_days = len(df_meetings)
                st.metric("üìÜ T·ªïng ng√†y", f"{total_days} ng√†y")
            
            # H√†ng 2: Th·ªëng k√™ theo lo·∫°i ng√†y
            st.markdown("#### üìã Ph√¢n t√≠ch theo lo·∫°i ng√†y")
            col1, col2, col3 = st.columns(3)
            
            workday_data = df_meetings[df_meetings['day_type'] == 'Ng√†y l√†m vi·ªác']
            weekend_data = df_meetings[df_meetings['day_type'] == 'Cu·ªëi tu·∫ßn']
            
            with col1:
                workday_total = workday_data['meeting_schedules'].sum()
                workday_count = len(workday_data)
                st.metric("üíº Ng√†y l√†m vi·ªác", f"{workday_total} cu·ªôc", f"{workday_count} ng√†y")
            
            with col2:
                weekend_total = weekend_data['meeting_schedules'].sum()
                weekend_count = len(weekend_data)
                st.metric("üè° Cu·ªëi tu·∫ßn", f"{weekend_total} cu·ªôc", f"{weekend_count} ng√†y")
            
            with col3:
                busy_days = len(df_meetings[df_meetings['meeting_schedules'] > 10])
                st.metric("üî• Ng√†y b·∫≠n r·ªôn", f"{busy_days} ng√†y", ">10 cu·ªôc")
            
            st.markdown("---")
            
            # Bi·ªÉu ƒë·ªì
            create_meeting_charts(df_meetings)
            
            st.markdown("---")
            
            # B·∫£ng d·ªØ li·ªáu chi ti·∫øt
            st.markdown("### üìã Chi ti·∫øt d·ªØ li·ªáu l·ªãch h·ªçp")
            
            # L·ªçc d·ªØ li·ªáu
            col1, col2 = st.columns(2)
            with col1:
                min_meetings = st.number_input("üìä S·ªë cu·ªôc h·ªçp t·ªëi thi·ªÉu", min_value=0, value=0, key="meetings_min")
            with col2:
                selected_level = st.selectbox(
                    "üìÖ M·ª©c ƒë·ªô b·∫≠n r·ªôn",
                    options=['T·∫•t c·∫£'] + list(df_meetings['meeting_level'].unique()),
                    key="meeting_level_filter"
                )
            
            # √Åp d·ª•ng filter
            filtered_meetings = df_meetings[df_meetings['meeting_schedules'] >= min_meetings]
            if selected_level != 'T·∫•t c·∫£':
                filtered_meetings = filtered_meetings[filtered_meetings['meeting_level'] == selected_level]
            
            # Hi·ªÉn th·ªã b·∫£ng
            display_cols_meetings = ['datetime', 'weekday_vi', 'meeting_schedules', 'meeting_level', 'day_type']
            
            st.dataframe(
                filtered_meetings[display_cols_meetings].rename(columns={
                    'datetime': 'Ng√†y',
                    'weekday_vi': 'Ng√†y trong tu·∫ßn', 
                    'meeting_schedules': 'S·ªë cu·ªôc h·ªçp',
                    'meeting_level': 'M·ª©c ƒë·ªô b·∫≠n r·ªôn',
                    'day_type': 'Lo·∫°i ng√†y'
                }),
                use_container_width=True
            )
            
            # Th·ªëng k√™ cu·ªëi
            st.markdown("**üìä Insights ch√≠nh:**")
            insights = []
            
            if len(df_meetings) > 0:
                busiest_day = df_meetings.loc[df_meetings['meeting_schedules'].idxmax()]
                insights.append(f"üî• Ng√†y b·∫≠n r·ªôn nh·∫•t: {busiest_day['datetime'].strftime('%d/%m/%Y')} ({busiest_day['weekday_vi']}) v·ªõi {busiest_day['meeting_schedules']} cu·ªôc h·ªçp")
                
                quietest_day = df_meetings.loc[df_meetings['meeting_schedules'].idxmin()]
                insights.append(f"üîª Ng√†y √≠t h·ªçp nh·∫•t: {quietest_day['datetime'].strftime('%d/%m/%Y')} ({quietest_day['weekday_vi']}) v·ªõi {quietest_day['meeting_schedules']} cu·ªôc h·ªçp")
                
                most_common_level = df_meetings['meeting_level'].mode()[0] if len(df_meetings['meeting_level'].mode()) > 0 else 'Kh√¥ng x√°c ƒë·ªãnh'
                insights.append(f"üìä M·ª©c ƒë·ªô ph·ªï bi·∫øn nh·∫•t: {most_common_level}")
                
                for insight in insights:
                    st.write(f"- {insight}")
    else:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu l·ªãch h·ªçp")
        st.info("üìÅ Upload d·ªØ li·ªáu ƒë·ªÉ qu·∫£n l√Ω l·ªãch h·ªçp chi ti·∫øt")

# Tab 6: Qu·∫£n l√Ω ph√≤ng h·ªçp
with tab6:
    st.markdown('<div class="tab-header">üè¢ Qu·∫£n l√Ω Ph√≤ng H·ªçp</div>', unsafe_allow_html=True)
    
    def load_room_data_from_file():
        """Load d·ªØ li·ªáu ph√≤ng h·ªçp t·ª´ file c√≥ s·∫µn"""
        try:
            with open('meeting_rooms_data.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                df = pd.DataFrame(data['data'])
                
                # T·∫°o c·ªôt datetime
                df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Date']].rename(columns={'Date': 'day'}))
                df['weekday'] = df['datetime'].dt.day_name()
                df['weekday_vi'] = df['weekday'].map({
                    'Monday': 'Th·ª© 2', 'Tuesday': 'Th·ª© 3', 'Wednesday': 'Th·ª© 4',
                    'Thursday': 'Th·ª© 5', 'Friday': 'Th·ª© 6', 'Saturday': 'Th·ª© 7', 'Sunday': 'Ch·ªß nh·∫≠t'
                })
                df['month_vi'] = df['Month'].map({
                    1: 'Th√°ng 1', 2: 'Th√°ng 2', 3: 'Th√°ng 3', 4: 'Th√°ng 4',
                    5: 'Th√°ng 5', 6: 'Th√°ng 6', 7: 'Th√°ng 7', 8: 'Th√°ng 8',
                    9: 'Th√°ng 9', 10: 'Th√°ng 10', 11: 'Th√°ng 11', 12: 'Th√°ng 12'
                })
                
                # T√≠nh to√°n c√°c ch·ªâ s·ªë
                df['cancel_rate'] = (df['register_room_cancel'] / df['register_room'] * 100).fillna(0).round(1)
                df['net_bookings'] = df['register_room'] - df['register_room_cancel']
                df['is_weekend'] = df['weekday'].isin(['Saturday', 'Sunday'])
                df['day_type'] = df['is_weekend'].map({False: 'Ng√†y l√†m vi·ªác', True: 'Cu·ªëi tu·∫ßn'})
                
                return df
        except Exception as e:
            st.error(f"L·ªói khi load d·ªØ li·ªáu: {e}")
            return None
    
    # Upload file ho·∫∑c load t·ª´ file c√≥ s·∫µn
    uploaded_file_rooms = st.file_uploader(
        "üìÅ Upload d·ªØ li·ªáu ph√≤ng h·ªçp m·ªõi", 
        type=['json', 'csv'],
        key="rooms"
    )
    
    # Load d·ªØ li·ªáu
    if uploaded_file_rooms is not None:
        if uploaded_file_rooms.type == "application/json":
            data = json.load(uploaded_file_rooms)
            if isinstance(data, dict) and "data" in data:
                df_rooms = pd.DataFrame(data["data"])
            else:
                df_rooms = pd.DataFrame(data)
        else:
            df_rooms = pd.read_csv(uploaded_file_rooms)
        
        # X·ª≠ l√Ω d·ªØ li·ªáu upload
        df_rooms['datetime'] = pd.to_datetime(df_rooms[['Year', 'Month', 'Date']].rename(columns={'Date': 'day'}))
        df_rooms['weekday'] = df_rooms['datetime'].dt.day_name()
        df_rooms['weekday_vi'] = df_rooms['weekday'].map({
            'Monday': 'Th·ª© 2', 'Tuesday': 'Th·ª© 3', 'Wednesday': 'Th·ª© 4',
            'Thursday': 'Th·ª© 5', 'Friday': 'Th·ª© 6', 'Saturday': 'Th·ª© 7', 'Sunday': 'Ch·ªß nh·∫≠t'
        })
        df_rooms['month_vi'] = df_rooms['Month'].map({
            1: 'Th√°ng 1', 2: 'Th√°ng 2', 3: 'Th√°ng 3', 4: 'Th√°ng 4',
            5: 'Th√°ng 5', 6: 'Th√°ng 6', 7: 'Th√°ng 7', 8: 'Th√°ng 8',
            9: 'Th√°ng 9', 10: 'Th√°ng 10', 11: 'Th√°ng 11', 12: 'Th√°ng 12'
        })
        df_rooms['cancel_rate'] = (df_rooms['register_room_cancel'] / df_rooms['register_room'] * 100).fillna(0).round(1)
        df_rooms['net_bookings'] = df_rooms['register_room'] - df_rooms['register_room_cancel']
        df_rooms['is_weekend'] = df_rooms['weekday'].isin(['Saturday', 'Sunday'])
        df_rooms['day_type'] = df_rooms['is_weekend'].map({False: 'Ng√†y l√†m vi·ªác', True: 'Cu·ªëi tu·∫ßn'})
        df_rooms = apply_global_filter(df_rooms)
        
    else:
        # Load t·ª´ file c√≥ s·∫µn
        df_rooms = load_room_data_from_file()
        if df_rooms is not None:
            df_rooms = apply_global_filter(df_rooms)
    
    if df_rooms is not None and not df_rooms.empty:
        # Metrics t·ªïng quan
        col1, col2, col3, col4 = st.columns(4)
        
        total_bookings = df_rooms['register_room'].sum()
        total_cancels = df_rooms['register_room_cancel'].sum()
        avg_daily = df_rooms['register_room'].mean()
        cancel_rate_avg = (total_cancels / total_bookings * 100) if total_bookings > 0 else 0
        
        with col1:
            st.metric("üìÖ T·ªïng ƒëƒÉng k√Ω", f"{total_bookings:,}")
        with col2:
            st.metric("‚ùå T·ªïng h·ªßy", f"{total_cancels:,}")
        with col3:
            st.metric("üìä TB/ng√†y", f"{avg_daily:.1f}")
        with col4:
            st.metric("üìâ T·ª∑ l·ªá h·ªßy", f"{cancel_rate_avg:.1f}%")
        
        # Sub-tabs cho ph√≤ng h·ªçp
        subtab1, subtab2, subtab3 = st.tabs(["üìà Xu h∆∞·ªõng", "üìä Ph√¢n t√≠ch", "üèÜ Top ng√†y"])
        
        with subtab1:
            # Bi·ªÉu ƒë·ªì xu h∆∞·ªõng
            fig_trend = make_subplots(
                rows=2, cols=1,
                subplot_titles=('Xu h∆∞·ªõng ƒëƒÉng k√Ω ph√≤ng h·ªçp', 'T·ª∑ l·ªá h·ªßy theo th·ªùi gian'),
                vertical_spacing=0.1
            )
            
            fig_trend.add_trace(
                go.Scatter(x=df_rooms['datetime'], y=df_rooms['register_room'],
                          mode='lines+markers', name='ƒêƒÉng k√Ω', line=dict(color='#2E86AB')),
                row=1, col=1
            )
            
            fig_trend.add_trace(
                go.Scatter(x=df_rooms['datetime'], y=df_rooms['register_room_cancel'],
                          mode='lines+markers', name='H·ªßy b·ªè', line=dict(color='#F18F01')),
                row=1, col=1
            )
            
            fig_trend.add_trace(
                go.Scatter(x=df_rooms['datetime'], y=df_rooms['cancel_rate'],
                          mode='lines+markers', name='T·ª∑ l·ªá h·ªßy (%)', line=dict(color='#C73E1D')),
                row=2, col=1
            )
            
            fig_trend.update_layout(height=600, hovermode='x unified')
            st.plotly_chart(fig_trend, use_container_width=True)
            
            # Th·ªëng k√™ nhanh
            col1, col2, col3 = st.columns(3)
            with col1:
                max_booking = df_rooms['register_room'].max()
                max_date = df_rooms[df_rooms['register_room'] == max_booking]['datetime'].iloc[0]
                st.success(f"üèÜ Ng√†y ƒëƒÉng k√Ω cao nh·∫•t\n{max_date.strftime('%d/%m/%Y')}: {max_booking} ƒëƒÉng k√Ω")
            
            with col2:
                max_cancel = df_rooms['register_room_cancel'].max()
                max_cancel_date = df_rooms[df_rooms['register_room_cancel'] == max_cancel]['datetime'].iloc[0]
                st.warning(f"‚ö†Ô∏è Ng√†y h·ªßy cao nh·∫•t\n{max_cancel_date.strftime('%d/%m/%Y')}: {max_cancel} h·ªßy")
            
            with col3:
                max_rate = df_rooms['cancel_rate'].max()
                max_rate_date = df_rooms[df_rooms['cancel_rate'] == max_rate]['datetime'].iloc[0]
                st.info(f"üìâ T·ª∑ l·ªá h·ªßy cao nh·∫•t\n{max_rate_date.strftime('%d/%m/%Y')}: {max_rate}%")
        
        with subtab2:
            # Ph√¢n t√≠ch theo th√°ng
            monthly_stats = df_rooms.groupby('month_vi').agg({
                'register_room': ['sum', 'mean'],
                'register_room_cancel': ['sum', 'mean'],
                'cancel_rate': 'mean'
            }).round(2)
            monthly_stats.columns = ['T·ªïng ƒëƒÉng k√Ω', 'TB/ng√†y', 'T·ªïng h·ªßy', 'TB h·ªßy/ng√†y', 'TB t·ª∑ l·ªá h·ªßy (%)']
            
            # Bi·ªÉu ƒë·ªì th√°ng
            fig_monthly = go.Figure()
            months = monthly_stats.index
            
            fig_monthly.add_trace(go.Bar(name='T·ªïng ƒëƒÉng k√Ω', x=months, y=monthly_stats['T·ªïng ƒëƒÉng k√Ω'], 
                                        marker_color='#2E86AB', yaxis='y'))
            fig_monthly.add_trace(go.Bar(name='T·ªïng h·ªßy', x=months, y=monthly_stats['T·ªïng h·ªßy'], 
                                        marker_color='#F18F01', yaxis='y'))
            fig_monthly.add_trace(go.Scatter(name='T·ª∑ l·ªá h·ªßy (%)', x=months, y=monthly_stats['TB t·ª∑ l·ªá h·ªßy (%)'],
                                           mode='lines+markers', line=dict(color='#C73E1D', width=3), yaxis='y2'))
            
            fig_monthly.update_layout(
                title='Ph√¢n t√≠ch theo th√°ng',
                xaxis_title='Th√°ng',
                yaxis=dict(title='S·ªë l∆∞·ª£ng', side='left'),
                yaxis2=dict(title='T·ª∑ l·ªá h·ªßy (%)', side='right', overlaying='y'),
                height=400
            )
            st.plotly_chart(fig_monthly, use_container_width=True)
            
            # B·∫£ng th·ªëng k√™
            st.dataframe(monthly_stats, use_container_width=True)
            
            # Ph√¢n t√≠ch theo ng√†y trong tu·∫ßn
            weekday_order = ['Th·ª© 2', 'Th·ª© 3', 'Th·ª© 4', 'Th·ª© 5', 'Th·ª© 6', 'Th·ª© 7', 'Ch·ªß nh·∫≠t']
            weekday_stats = df_rooms.groupby('weekday_vi').agg({
                'register_room': ['sum', 'mean'],
                'register_room_cancel': ['sum', 'mean']
            }).round(2)
            weekday_stats = weekday_stats.reindex(weekday_order)
            weekday_stats.columns = ['T·ªïng ƒëƒÉng k√Ω', 'TB ƒëƒÉng k√Ω', 'T·ªïng h·ªßy', 'TB h·ªßy']
            
            # Bi·ªÉu ƒë·ªì radar
            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=weekday_stats['TB ƒëƒÉng k√Ω'].values,
                theta=weekday_stats.index,
                fill='toself', name='TB ƒëƒÉng k√Ω/ng√†y',
                line_color='#2E86AB'
            ))
            fig_radar.add_trace(go.Scatterpolar(
                r=weekday_stats['TB h·ªßy'].values,
                theta=weekday_stats.index,
                fill='toself', name='TB h·ªßy/ng√†y',
                line_color='#F18F01'
            ))
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, weekday_stats['TB ƒëƒÉng k√Ω'].max() * 1.1])),
                title='Ph√¢n t√≠ch theo ng√†y trong tu·∫ßn', height=400
            )
            st.plotly_chart(fig_radar, use_container_width=True)
            
            st.dataframe(weekday_stats, use_container_width=True)
        
        with subtab3:
            # Top ng√†y c√≥ nhi·ªÅu ƒëƒÉng k√Ω
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üìà Top 10 ng√†y ƒëƒÉng k√Ω cao nh·∫•t")
                top_bookings = df_rooms.nlargest(10, 'register_room')[['datetime', 'register_room', 'register_room_cancel', 'cancel_rate', 'weekday_vi']]
                
                for idx, row in top_bookings.iterrows():
                    st.success(f"""
                    üìÖ {row['datetime'].strftime('%d/%m/%Y')} ({row['weekday_vi']})
                    üè¢ ƒêƒÉng k√Ω: {row['register_room']} | ‚ùå H·ªßy: {row['register_room_cancel']} | üìä T·ª∑ l·ªá: {row['cancel_rate']}%
                    """)
            
            with col2:
                st.markdown("#### üìâ Top 10 ng√†y h·ªßy cao nh·∫•t")
                top_cancels = df_rooms.nlargest(10, 'register_room_cancel')[['datetime', 'register_room', 'register_room_cancel', 'cancel_rate', 'weekday_vi']]
                
                for idx, row in top_cancels.iterrows():
                    st.warning(f"""
                    üìÖ {row['datetime'].strftime('%d/%m/%Y')} ({row['weekday_vi']})
                    üè¢ ƒêƒÉng k√Ω: {row['register_room']} | ‚ùå H·ªßy: {row['register_room_cancel']} | üìä T·ª∑ l·ªá: {row['cancel_rate']}%
                    """)
        
    else:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ph√≤ng h·ªçp")
        st.info("üìÅ Upload d·ªØ li·ªáu ho·∫∑c ƒë·∫£m b·∫£o file meeting_rooms_data.json t·ªìn t·∫°i ƒë·ªÉ xem chi ti·∫øt")

# Footer
st.markdown("---")
st.markdown("### üîß H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")
with st.expander("üí° Xem h∆∞·ªõng d·∫´n chi ti·∫øt"):
    st.markdown("""
    **C√°ch s·ª≠ d·ª•ng Dashboard:**
    
    1. **üìÅ Upload d·ªØ li·ªáu**: M·ªói tab c√≥ m·ª•c upload ri√™ng, h·ªó tr·ª£ file JSON v√† CSV
    2. **üìä Xem th·ªëng k√™**: Sau khi upload, h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông t√≠nh to√°n v√† hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    3. **üîç L·ªçc d·ªØ li·ªáu**: S·ª≠ d·ª•ng c√°c b·ªô l·ªçc ƒë·ªÉ xem d·ªØ li·ªáu theo ƒëi·ªÅu ki·ªán c·ª• th·ªÉ
    4. **üìà Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c**: Click v√†o bi·ªÉu ƒë·ªì ƒë·ªÉ xem chi ti·∫øt
    
    **üìã C·∫•u tr√∫c d·ªØ li·ªáu:**
    - VƒÉn b·∫£n ƒë·∫øn: C·∫ßn c√≥ c√°c tr∆∞·ªùng date, month, year, total_incoming, processed_on_time, processed_late
    - C√°c module kh√°c s·∫Ω c√≥ c·∫•u tr√∫c t∆∞∆°ng t·ª± t√πy theo y√™u c·∫ßu nghi·ªáp v·ª•
    """)

st.markdown("""
<div style='text-align: center; padding: 2rem; color: #7f8c8d;'>
    <p>üìä Dashboard Ph√≤ng H√†nh Ch√≠nh - Phi√™n b·∫£n 1.0</p>
    <p>üîÑ D·ªØ li·ªáu c·∫≠p nh·∫≠t t·ª´ GitHub Repository</p>
</div>
""", unsafe_allow_html=True)